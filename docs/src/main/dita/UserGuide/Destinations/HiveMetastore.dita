<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_gcr_z2t_zv">
 <title>Hive Metastore</title>
 <shortdesc>The Hive Metastore destination works with the Hive Metadata processor and the Hadoop FS
        or MapR FS destination as part of the Drift Synchronization Solution for Hive. </shortdesc>
 <conbody>
        <p><indexterm>destinations<indexterm>Hive Metastore </indexterm></indexterm><indexterm>Hive
                Metastore destination<indexterm>overview</indexterm></indexterm>The Hive Metastore
            destination uses metadata records generated by the Hive Metadata processor to create and
            update Hive tables. This enables the Hadoop FS and MapR FS destinations to write
            drifting Avro or Parquet data to HDFS or MapR FS.</p>
        <p>The Hive Metastore destination compares information in metadata records with Hive tables,
            and then creates or updates the tables as needed. For example, when the Hive Metadata
            processor encounters a record that requires a new Hive table, it passes a metadata
            record to the Hive Metastore destination and the destination creates the table.</p>
        <p><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HM-HiveNames"/>
            Names that include uppercase letters become lowercase in Hive.</p>
        <p>Note that the Hive Metastore destination does not process data. It processes only
            metadata records generated by the Hive Metadata processor and must be downstream from
            the processor's metadata output stream.</p>
        <p>When you configure Hive Metastore, you define the connection information for Hive, the
            location of the Hive and Hadoop configuration files and optionally specify additional
            required properties. You can also enable Kerberos authentication. You can also set a
            maximum cache size for the destination, determine how new tables are created and stored,
            and configure custom record header attributes.</p>
        <p>The destination can also generate events for an event stream. For more information about
            the event framework, see <xref
                href="../Event_Handling/EventFramework-Overview.dita#concept_cph_5h4_lx"/>.</p>
        <note type="important">When using the destination in multiple pipelines, take care to avoid
            concurrent or conflicting writes to the same tables. </note>
        <p>For more information about the Drift Synchronization Solution for Hive and case studies
            for processing Avro and Parquet data, see <xref
                href="../Hive_Drift_Solution/HiveDrift-Overview.dita#concept_phk_bdf_2w"/>. For a
            tutorial, check out our <xref
                href="https://github.com/streamsets/tutorials/blob/master/tutorial-hivedrift/readme.md"
                format="html" scope="external">tutorial on Github</xref>.</p>
    </conbody>
    <related-links>
        <link href="../Hive_Drift_Solution/HiveDataTypes.dita#concept_ry2_qkm_hw"/>
    </related-links>
</concept>
