<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA General Task//EN" "generalTask.dtd">
<task id="task_hgl_vgn_vs">
    <title>Configuring a Hadoop FS Origin</title>
    <taskbody>
        <context><indexterm>Hadoop FS origins<indexterm>configuring</indexterm></indexterm>Configure
            a Hadoop FS origin to read data from HDFS.</context>
        <steps id="steps_v51_1hn_vs">
            <step
                conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/1stStep-ClusterOrigin">
                <cmd/>
            </step>
            <step>
                <cmd>On the <wintitle>Hadoop FS</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_b55_mkn_vs">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.25*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.25*"/>
                            <thead>
                                <row>
                                    <entry>Hadoop FS Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Data Format <xref href="HadoopFS-DataFormat.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_mfn_hwx_5r"
                                        /></xref></entry>
                                    <entry>
                                        <p>Type of data to be read. Use one of the following
                                            options: <ul id="ul_czf_y14_vs">
                                                <li>Avro</li>
                                                <li>Delimited</li>
                                                <li>Text</li>
                                            </ul></p>
                                    </entry>
                                </row>
                                <row>
                                    <entry>Hadoop FS URI</entry>
                                    <entry>HDFS URI. Include the HDFS scheme and authority as
                                        follows:
                                        <codeph>&lt;scheme>://&lt;authority></codeph>.</entry>
                                </row>
                                <row>
                                    <entry>Directory Path</entry>
                                    <entry>Directory for the data to be read. Include the HDFS
                                        scheme and authority in the path as follows:
                                            <codeph>&lt;scheme>://&lt;authority>/path</codeph>.</entry>
                                </row>
                                <row>
                                    <entry>Include All Subdirectories</entry>
                                    <entry>Reads from all directories within the specified directory
                                        path.</entry>
                                </row>
                                <row>
                                    <entry>Produce Single Record</entry>
                                    <entry>Generates a single record when a record includes multiple
                                        objects. </entry>
                                </row>
                                <row>
                                    <entry>Kerberos Authentication <xref
                                            href="HadoopFS-Kerberos.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_a5x_jzn_vs"
                                        /></xref></entry>
                                    <entry>Uses Kerberos credentials to connect to HDFS. <p>When
                                            selected, uses the Kerberos principal and keytab defined
                                            in the <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> configuration file,
                                                <codeph>$SDC_CONF/sdc.properties</codeph>.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Hadoop FS Configuration Directory  <xref
                                        href="HadoopFS-HadoopProperties-origin.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_ocv_4qg_xs"
                                        /></xref></entry>
                                    <entry>
                                        <p>Location of the HDFS configuration files. Use a directory
                                            or symlink within the Data Collector resources
                                            directory.</p>
                                        <p>You can use the following files with the Hadoop FS
                                                origin:<ul
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/ul-HDFSfiles_HDFSorigin"
                                                id="ul_o22_m4r_bt">
                                                <li/>
                                            </ul></p>
                                        <p>
                                            <note>Properties in the configuration files are
                                                overridden by individual properties defined in the
                                                stage. </note>
                                        </p>
                                    </entry>
                                </row>
                                <row>
                                    <entry>HDFS User  <xref href="HadoopFS-HDFSUser-origin.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_t3x_4qg_xs"
                                        /></xref></entry>
                                    <entry>The HDFS user to use to connect to HDFS. When using this
                                        property, make sure HDFS is configured appropriately.<p>By
                                            default, the pipeline uses the <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> user to connect to HDFS.</p></entry>
                                </row>
                                <row>
                                    <entry>Hadoop FS Configuration  <xref
                                            href="HadoopFS-HadoopProperties-origin.dita">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                placement="inline" id="image_if3_4hl_xs"
                                        /></xref></entry>
                                    <entry>
                                        <p>Additional Hadoop configuration properties to use. To add
                                            properties, click <uicontrol>Add</uicontrol> and define
                                            the property name and value. </p>
                                        <p>Use the property names and values as expected by Hadoop.
                                        </p>
                                    </entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/MaxBatchSize">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
                                    <entry/>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/O-AVROHadoopFS">
                <cmd/>
            </step>
            <step conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/DelimFILE">
                <cmd/>
            </step>
            <step conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/Text">
                <cmd/>
            </step>
        </steps>
    </taskbody>
</task>
