<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_hpr_twm_jq">
 <title>Origins</title>
 <shortdesc>An origin stage represents the source for the pipeline. You can use a single origin
    stage in a pipeline.</shortdesc>
 <conbody>
  <p><indexterm>origins<indexterm>overview</indexterm></indexterm>You can use different origins
      based on the execution mode of the pipeline. </p>
    <p>In standalone pipelines, you can use the following origins: <ul id="ul_mxz_jxm_jq">
        <li><xref href="AmazonS3.dita#concept_kvs_3hh_ht">Amazon S3</xref> - Reads objects from
          Amazon S3.</li>
        <li><xref href="AmazonSQS.dita#concept_xsh_knm_5bb">Amazon SQS Consumer</xref> - Reads data
          from queues in Amazon Simple Queue Services (SQS). </li>
        <li><xref href="AzureEventHub.dita#concept_c1z_15q_1bb">Azure IoT/Event Hub Consumer</xref> -
          Reads data from Microsoft Azure Event Hub. Creates multiple threads to enable parallel
          processing in a multithreaded pipeline.</li>
        <li><xref href="CoAPServer.dita#concept_wfy_ghn_sz">CoAP Server</xref> - Listens on a CoAP
          endpoint and processes the contents of all authorized CoAP requests. Creates multiple
          threads to enable parallel processing in a multithreaded pipeline.</li>
        <li><xref href="Directory.dita#concept_qcq_54n_jq">Directory</xref> - Reads fully-written
          files from a directory. Creates multiple threads to enable parallel processing in a
          multithreaded pipeline.</li>
        <li><xref href="Elasticsearch.dita#concept_f1q_vpm_2z">Elasticsearch</xref> - Reads data
          from an Elasticsearch cluster. Creates multiple threads to enable parallel processing in a
          multithreaded pipeline.</li>
        <li><xref href="FileTail.dita#concept_n1y_qyp_5q">File Tail</xref> - Reads lines of data
          from an active file after reading related archived files in the directory. </li>
        <li><xref href="BigQuery.dita#concept_cg3_y3v_q1b">Google BigQuery</xref> - Executes a query
          job and reads the result from Google BigQuery. </li>
        <li><xref href="GCS.dita#concept_iyd_wql_nbb">Google Cloud Storage</xref> - Reads fully
          written objects from Google Cloud Storage.</li>
        <li><xref href="PubSub.dita#concept_pjw_qtl_r1b">Google Pub/Sub Subscriber</xref> - Consumes
          messages from a Google Pub/Sub subscription. Creates multiple threads to enable parallel
          processing in a multithreaded pipeline.</li>
        <li><xref href="HTTPClient.dita#concept_wk4_bjz_5r">HTTP Client</xref> - Reads data from a
          streaming HTTP resource URL.</li>
        <li><xref href="HTTPServer.dita#concept_s2p_5hb_4y">HTTP Server</xref> - Listens on an HTTP
          endpoint and processes the contents of all authorized HTTP POST requests. Creates multiple
          threads to enable parallel processing in a multithreaded pipeline.</li>
        <li><xref href="HTTPtoKafka.dita#concept_izh_mqd_dy">HTTP to Kafka</xref> - Listens on a
          HTTP endpoint and writes the contents of all authorized HTTP POST requests directly to
          Kafka.</li>
        <li><xref href="MultiTableJDBCConsumer.dita#concept_zp3_wnw_4y">JDBC Multitable
            Consumer</xref> - Reads database data from multiple tables through a JDBC connection.
          Creates multiple threads to enable parallel processing in a multithreaded pipeline.</li>
        <li><xref href="JDBCConsumer.dita#concept_qhf_hjr_bs">JDBC Query Consumer</xref> - Reads
          database data using a user-defined SQL query through a JDBC connection. </li>
        <li><xref href="JMS.dita#concept_rhh_4nj_dt">JMS Consumer</xref> - Reads messages from JMS. </li>
        <li><xref href="KConsumer.dita#concept_msz_wnr_5q">Kafka Consumer</xref> - Reads messages
          from a single Kafka topic.</li>
        <li><xref href="KafkaMultiConsumer.dita#concept_ccs_fn4_x1b">Kafka Multitopic
            Consumer</xref> - Reads messages from multiple Kafka topics. Creates multiple threads to
          enable parallel processing in a multithreaded pipeline.</li>
        <li><xref href="KinConsumer.dita#concept_anh_4y3_yr">Kinesis Consumer</xref> - Reads data
          from Kinesis Streams. Creates multiple threads to enable parallel processing in a
          multithreaded pipeline.</li>
        <li><xref href="MapRdbCDC.dita#concept_qwj_5vm_pbb">MapR DB CDC</xref> - Reads  changed MapR
          DB data that has been written to MapR Streams. Creates multiple threads to enable parallel
          processing in a multithreaded pipeline.</li>
        <li><xref href="MapRDBJSON.dita#concept_ywh_k15_3y"/> - Reads JSON documents from MapR DB
          JSON tables.</li>
        <li><xref href="MapRFS.dita#concept_psz_db4_lx">MapR FS</xref> - Reads files from MapR
          FS.</li>
        <li><xref href="MapRStreamsMultiConsumer.dita#concept_hvd_hww_lbb">MapR Multitopic Streams
            Consumer</xref> - Reads messages from multiple MapR Streams topics. Creates multiple
          threads to enable parallel processing in a multithreaded pipeline.</li>
        <li><xref href="MapRStreamsCons.dita#concept_cvy_xsf_2v">MapR Streams Consumer</xref> -
          Reads messages from MapR Streams.</li>
        <li><xref href="MongoDB.dita#concept_bk4_2rs_ns">MongoDB</xref> - Reads documents from
          MongoDB.</li>
        <li><xref href="MongoDBOplog.dita#concept_mjn_yqw_4y">MongoDB Oplog</xref> - Reads entries
          from a MongoDB Oplog.</li>
        <li><xref href="MQTTSubscriber.dita#concept_ukz_3vt_lz">MQTT Subscriber</xref> - Subscribes
          to a topic on an MQTT broker to read messages from the broker.</li>
        <li><xref href="MySQLBinaryLog.dita#concept_kqg_1yh_xx">MySQL Binary Log</xref> - Reads
          MySQL binary logs to generate change data capture records. </li>
        <li><xref href="Omniture.dita#concept_dsr_xmw_1s">Omniture</xref> - Reads web usage reports
          from the Omniture reporting API.</li>
        <li><xref href="OPCUAClient.dita#concept_nmf_1ly_f1b">OPC UA Client</xref> - Reads data from
          a OPC UA server.</li>
        <li><xref href="OracleCDC.dita#concept_rs5_hjj_tw">Oracle CDC Client</xref> - Reads LogMiner
          redo logs to generate change data capture records.</li>
        <li><xref href="RabbitMQ.dita#concept_dyg_lq1_h5">RabbitMQ Consumer</xref> - Reads messages
          from RabbitMQ.</li>
        <li><xref href="Redis.dita#concept_plr_t3v_jw">Redis Consumer</xref> - Reads messages from
          Redis.</li>
        <li><xref href="Salesforce.dita#concept_odf_vr3_rx">Salesforce</xref> - Reads data from
          Salesforce.</li>
        <li><xref href="SDC_RPCorigin.dita#concept_agb_5c1_ct">SDC RPC</xref> - Reads data from an
          SDC RPC destination in an SDC RPC pipeline.</li>
        <li><xref href="SDCRPCtoKafka.dita#concept_tdk_slk_pw">SDC RPC to Kafka</xref> - Reads data
          from an SDC RPC destination in an SDC RPC pipeline and writes it to Kafka.</li>
        <li><xref href="SDCRPCtoKafka.dita#concept_tdk_slk_pw">SFTP/FTP Client</xref> - Reads files
          from an SFTP or FTP server.</li>
        <li><xref href="SQLServerCDC.dita#concept_ut3_ywc_v1b">SQL Server CDC Client</xref> - Reads
          data from Microsoft SQL Server CDC tables. Creates multiple threads to enable parallel
          processing in a multithreaded pipeline.</li>
        <li><xref href="SQLServerChange.dita#concept_ewq_b2s_r1b">SQL Server Change Tracking</xref>
          - Reads data from Microsoft SQL Server change tracking tables and generates the latest
          version of each record. Creates multiple threads to enable parallel processing in a
          multithreaded pipeline.</li>
        <li><xref href="TCPServer.dita#concept_ppm_xb1_4z">TCP Server</xref> - Listens at the
          specified ports and processes incoming data over TCP/IP connections. Creates multiple
          threads to enable parallel processing in a multithreaded pipeline.</li>
        <li><xref href="UDPMulti.dita#concept_wng_g5f_5bb">UDP Multithreaded Source</xref> - Reads
          messages from one or more UDP ports. Creates multiple threads to enable parallel
          processing in a multithreaded pipeline. </li>
        <li><xref href="UDP.dita#concept_rst_2y5_1s">UDP Source</xref> - Reads messages from one or
          more UDP ports. </li>
        <li><xref href="UDPtoKafka.dita#concept_jzq_jcz_pw">UDP to Kafka</xref> - Reads messages
          from one or more UDP ports and writes the data to Kafka.</li>
        <li><xref href="WebSocketClient.dita#concept_unk_nzk_fbb">WebSocket Client</xref> - Reads
          data from a WebSocket server endpoint.</li>
        <li><xref href="WebSocketServer.dita#concept_u2r_gpc_3z">WebSocket Server</xref> - Listens
          on a WebSocket endpoint and processes the contents of all authorized WebSocket client
          requests. Creates multiple threads to enable parallel processing in a multithreaded
          pipeline.</li>
      </ul></p>
    <p>In cluster pipelines, you can use the following origins:<ul id="ul_unr_xhb_ws">
        <li><xref href="HadoopFS-origin.dita#concept_lw2_tnm_vs">Hadoop FS</xref> - Reads data from
          the Hadoop Distributed File System (HDFS). Can read from other file systems using the
          Hadoop FileSystem interface.</li>
        <li><xref href="KConsumer.dita#concept_msz_wnr_5q">Kafka Consumer</xref> - Reads messages
          from Kafka. Use the cluster version of the origin.</li>
        <li><xref href="MapRFS.dita#concept_psz_db4_lx">MapR FS</xref> - Reads data from MapR
          FS.</li>
        <li><xref href="MapRStreamsCons.dita#concept_cvy_xsf_2v">MapR Streams Consumer</xref> -
          Reads messages from MapR Streams.</li>
      </ul></p>
    <p>In edge pipelines, you can use the following origins:<ul id="ul_r4p_zs2_rbb">
        <li><xref href="Directory.dita#concept_qcq_54n_jq">Directory</xref> - Reads fully-written
          files from a directory.</li>
        <li><xref href="FileTail.dita#concept_n1y_qyp_5q">File Tail</xref> - Reads lines of data
          from an active file after reading related archived files in the directory. </li>
        <li><xref href="HTTPServer.dita#concept_s2p_5hb_4y">HTTP Server</xref> - Listens on an HTTP
          endpoint and processes the contents of all authorized HTTP POST requests.</li>
        <li><xref href="MQTTSubscriber.dita#concept_ukz_3vt_lz">MQTT Subscriber</xref> - Subscribes
          to a topic on an MQTT broker to read messages from the broker.</li>
        <li><xref href="WindowsLog.dita#concept_agf_5jv_sbb">Windows Event Log</xref> - Reads data
          from a Microsoft Windows event log located on a Windows machine. </li>
      </ul></p>
    <p>To help create or test pipelines, you can use the following development origins:<ul
        id="ul_nr2_c1p_qv">
        <li>Dev Data Generator </li>
        <li>Dev Random Source</li>
        <li>Dev Raw Data Source </li>
        <li>Dev SDC RPC with Buffering</li>
      </ul></p>
    <p>For more information, see <xref href="../Pipeline_Design/DevStages.dita#concept_czx_ktn_ht"
      />.</p>
 </conbody>
</concept>
