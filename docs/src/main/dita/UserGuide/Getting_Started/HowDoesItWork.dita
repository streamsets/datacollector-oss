<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_bl5_dl4_1r">
 <title>How does this really work?</title>
 <shortdesc>Let's walk through it...</shortdesc>
 <conbody>
  <p>After you install and launch the <ph
    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>, you access
   the <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
   console, log in, and create your first pipeline. </p>
  <p>What do you want it to do? Let's say you want to read XML files from a directory and remove the
   newline characters before moving it into Hive. To do this, you start with a Directory origin
   stage and configure it to point to the source file directory. (You can also have the stage
   archive processed files and write files that were not fully processed to a separate directory for
   review.)</p>
  <p>To remove the newline characters, connect Directory to an Expression Evaluator processor and
   configure it to remove the newline character from the last field in the record.</p>
  <p>To make the data available to Hive, you connect the Expression Evaluator to a Hadoop FS
   destination stage. You configure the stage to write the data as a JSON object (though you can use
   other data formats as well). </p>
  <p>You preview data to see how source data moves through the pipeline and notice that some fields
   have missing data. So you add a Value Replacer to replace null values in those fields. </p>
  <p>Now that the data flow is done, you configure the pipeline error record handling to write error
   records to a file, and you configure an email alert to let you know when the pipeline generates
   more than 100 error records. Then, you start the pipeline and the <ph
    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> goes to work. </p>
  <p>The <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
   console goes into Monitor mode and displays summary and error statistics immediately. To get a
   close look at the activity, you take a snapshot of the pipeline so you can examine how a set of
   data passed through the pipeline. You see some unexpected data in the pipeline, so you create a
   data rule for a link between two stages to gather  information about similar data and set an
   alert to notify you when the numbers get too high.</p>
  <p>And what about those error records being written to file? They're saved with error details, so
   you can create an error pipeline to reprocess that data. Et voila!</p>
  <p>The <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> is a
   powerful tool, but we're making it as simple as possible to use. So give it a try, click the Help
   icon for information, and contact us if you need a hand. </p>
 </conbody>
</concept>
