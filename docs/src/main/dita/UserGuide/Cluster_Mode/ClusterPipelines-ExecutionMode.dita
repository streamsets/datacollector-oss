<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_rjc_4m5_lx">
 <title>Cluster Batch and Streaming Execution Modes</title>
 <shortdesc><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
        can run a cluster pipeline using the cluster batch or the cluster streaming execution
        mode.</shortdesc>
 <conbody>
  <p><indexterm>cluster batch mode<indexterm>description</indexterm></indexterm><indexterm>cluster
                streaming mode<indexterm>description</indexterm></indexterm><indexterm>cluster
                    mode<indexterm>batch</indexterm></indexterm><indexterm>cluster
                    mode<indexterm>streaming</indexterm></indexterm>The execution mode that <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
            can use depends on the origin system that the cluster pipeline reads from:</p>
     <dl>
         <dlentry>
             <dt>Kafka cluster</dt>
             <dd><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> can
                 process data from a Kafka cluster in cluster streaming mode. In cluster streaming mode, <ph
                     conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> processes
                 data continuously until you stop the pipeline. </dd>
             <dd><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> runs as an application within Spark Streaming, an open source
                    cluster-computing application. </dd>
                <dd>Spark Streaming runs on either the Mesos or YARN cluster manager to process data
                    from a Kafka cluster. The cluster manager and Spark Streaming spawn a <ph
                        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> worker for each topic partition in the Kafka cluster. So each partition has a
                        <ph
                        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> worker to process data. When Spark Streaming runs on YARN, you can limit the
                    number of workers spawned by configuring the <xref
                        href="../Pipeline_Configuration/ConfiguringAPipeline.dita#task_xlv_jdw_kq/YarnStreaming-WorkerCount"
                        >Worker Count cluster pipeline property</xref>. And you can use the Extra
                    Spark Configuration property to pass Spark configurations to the spark-submit
                        script.<p>Use the Kafka Consumer origin to process data from a Kafka cluster
                        in cluster streaming mode.</p></dd>
         </dlentry>
     </dl><dl>
         <dlentry>
             <dt>MapR cluster</dt>
             <dd><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> can process data from a MapR cluster in both execution modes: <ul
                        id="ul_ay3_lzt_lx">
                        <li>Cluster batch mode - In cluster batch mode, <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            /> processes all available data and then stops the pipeline. <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            /> runs as an application on top of MapReduce, an open-source
                            cluster-computing framework. MapReduce runs on a YARN cluster manager.
                            YARN and MapReduce generate additional worker nodes as needed. MapReduce
                            creates one map task for each MapR FS block.<p>Use the MapR FS origin to
                                process data from MapR in cluster batch mode.</p></li>
                        <li>Cluster streaming mode - In cluster streaming mode, <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            /> processes data continuously until you stop the pipeline. <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            /> runs as an application within Spark Streaming, an open source
                            cluster-computing application. <p>Spark Streaming runs on a YARN cluster
                                manager to process data from a MapR cluster. The cluster manager and
                                Spark Streaming spawn a <ph
                                    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                /> worker for each topic partition in the MapR cluster. So each
                                partition has a <ph
                                    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                /> worker to process data. You can limit the number of workers
                                spawned by configuring the <xref
                                    href="../Pipeline_Configuration/ConfiguringAPipeline.dita#task_xlv_jdw_kq/YarnStreaming-WorkerCount"
                                    >Worker Count cluster pipeline property</xref>.</p><p>Use the
                                MapR Streams Consumer origin to process data from a MapR cluster in
                                cluster streaming mode.</p></li>
                    </ul></dd>
         </dlentry>
         <dlentry>
             <dt>HDFS</dt>
             <dd><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> can process data from HDFS in cluster batch mode. In cluster batch mode, <ph
                        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> processes all available data and then stops the pipeline. </dd>
             <dd><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> runs
                 as an application on top of MapReduce, an open-source cluster-computing framework. MapReduce
                 runs on a YARN cluster manager. YARN and MapReduce generate additional worker nodes as needed.
                 MapReduce creates one map task for each HDFS block. <p>Use the Hadoop FS origin to process
                     data from HDFS in cluster batch mode.</p></dd>
         </dlentry>
     </dl>
 </conbody>
</concept>
