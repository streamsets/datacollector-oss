<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_isl_w44_kq">
 <title>What is a Pipeline?</title>
 <shortdesc>A pipeline describes the flow of data from the origin system to destination systems and
    defines how to transform the data along the way. </shortdesc>
 <conbody>
  <p><indexterm>pipelines<indexterm>overview</indexterm></indexterm>You can use a single origin
      stage to represent the origin system, multiple processor stages to transform data, and
      multiple destination stages to represent destination systems. </p>
    <p>When you start a pipeline, <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> runs the
      pipeline until you stop the pipeline or shut down <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>. You can
      use <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> to
      run multiple pipelines.</p>
    <p>While the pipeline runs, you can monitor the pipeline to verify that the pipeline performs as
      expected. You can also define metric and data rules and alerts to let you know when certain
      thresholds are reached.</p>
    <p>You can add an event stream to a pipeline to enable event-driven task execution or to save
      event information. For more information, see <xref
        href="../Event_Handling/EventFramework-Overview.dita#concept_cph_5h4_lx"/>.</p>
    <p>To process large volumes of data from a Kafka cluster or HDFS, you can configure a pipeline
      to run in cluster execution mode. For more information, see <xref
        href="../Cluster_Mode/ClusterPipelines_title.dita#concept_fpz_5r4_vs"/>.</p>
 </conbody>
</concept>
