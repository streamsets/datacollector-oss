<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA Task//EN" "task.dtd">
<task id="task_lcd_ng5_xw">
    <title>Configuring a Pipeline to Write Statistics</title>
    <shortdesc>You can configure a pipeline to write statistics<ph product="SDC"> after the <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
            has been registered with <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"
            /></ph>.</shortdesc>
    <taskbody>
        <steps>
            <step>
                <cmd>Open the pipeline. </cmd>
            </step>
            <step>
                <cmd>On the <uicontrol>Statistics</uicontrol> tab, select one of the following
                    options for the statistics aggregator:</cmd>
                <info>
                    <ul id="ul_ljj_brd_dx">
                        <li>Discard - Discard the pipeline statistics. <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"
                            /> cannot display statistics and metrics for the job.</li>
                        <li>Write to SCH Directly - Write the pipeline statistics directly to <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/DPM-short"
                            />. Use when the job runs on a single <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            />.</li>
                        <li>Write to SDC RPC - Write the pipeline statistics to an SDC RPC
                            destination. Use when the job runs on multiple <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            />s and for development purposes only.</li>
                        <li>Write to Kafka - Write the pipeline statistics to a Kafka cluster. Use
                            when the job runs on multiple <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            />s.</li>
                        <li>Write to Kinesis - Write the pipeline statistics to Amazon Kinesis
                            Streams. Use when the job runs on multiple <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            />s.</li>
                        <li>Write to MapR Streams - Write the pipeline statistics to MapR Streams.
                            Use when the job runs on multiple <ph
                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                            />s.</li>
                    </ul>
                </info>
            </step>
            <step>
                <cmd>To write statistics to an SDC RPC destination, on the <uicontrol>Stats
                        Aggregator - Write to SDC RPC</uicontrol> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_jxy_4sq_yy">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>SDC RPC Properties</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>SDC RPC Connection</entry>
                                    <entry>Host and port where the system pipeline runs. The host
                                        must be a machine with a registered <ph
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> that runs a pipeline instance for the job. <p>Use the
                                            following format: <codeph>&lt;host>:&lt;port></codeph>.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Retries per Batch</entry>
                                    <entry>Number of times the SDC RPC destination tries to write a
                                        batch to the Dev SDC RPC with Buffering origin in the system
                                        pipeline. <p>When the SDC RPC destination cannot write the
                                            batch within the configured number of retries, it fails
                                            the batch.</p><p>Default is 3.</p></entry>
                                </row>
                                <row>
                                    <entry>Back off Period</entry>
                                    <entry>Milliseconds to wait before retrying writing a batch to
                                        the Dev SDC RPC with Buffering origin in the system
                                            pipeline.<p>The value that you enter increases
                                            exponentially after each retry. For example, if you set
                                            the back off period to 10, the SDC RPC destination
                                            attempts the first retry after waiting 10 milliseconds,
                                            attempts the second retry after waiting 100
                                            milliseconds, and attempts the third retry after waiting
                                            1,000 milliseconds. Set to 0 to retry
                                            immediately.</p><p>Default is 0.</p></entry>
                                </row>
                                <row>
                                    <entry>SDC RPC ID</entry>
                                    <entry>User-defined ID to allow the SDC RPC destination to pass
                                        statistics to the system pipeline. To avoid mixing
                                        statistics from different jobs, use a unique ID for each
                                            job.<p>You cannot define an expression that evaluates to
                                            the ID. </p></entry>
                                </row>
                                <row>
                                    <entry>Connection Timeout (ms)</entry>
                                    <entry>Milliseconds to establish a connection to the system
                                        pipeline. <p>The SDC RPC destination retries the connection
                                            based on the Retries Per Batch property.</p><p>Default
                                            is 5000 milliseconds.</p></entry>
                                </row>
                                <row>
                                    <entry>TLS Enabled</entry>
                                    <entry>Enables the secure transfer of data using TLS. </entry>
                                </row>
                                <row>
                                    <entry>Truststore File</entry>
                                    <entry>Truststore file for TLS. Required if the keystore file is
                                        a self-signed certificate.<p>Must be stored in the <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> resources directory,
                                                <filepath>$SDC_RESOURCES</filepath>, on each <ph
                                                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                            /> machine that runs a pipeline instance for the job.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Truststore Password</entry>
                                    <entry>Password for the truststore file.<note
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/SDCDPM_Tip_Usernames"
                                        /></entry>
                                </row>
                                <row>
                                    <entry>Read Timeout (ms)</entry>
                                    <entry>Milliseconds to wait for the Dev SDC RPC with Buffering
                                        origin in the system pipeline to read data from a batch.
                                            <p>The SDC RPC destination retries the write based on
                                            the Retries Per Batch property.</p><p>Default is 2000
                                            milliseconds.</p></entry>
                                </row>
                                <row>
                                    <entry>Use Compression</entry>
                                    <entry>Enables the SDC RPC destination to use compression to
                                        pass data to the Dev SDC RPC with Buffering origin in the
                                        system pipeline. Enabled by default. </entry>
                                </row>
                                <row>
                                    <entry>Verify Host in Server Certificate</entry>
                                    <entry>Verifies the host in the keystore file on the <ph
                                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                        /> machine that runs the system pipeline. </entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>To write statistics to Kafka, on the <uicontrol>Stats Aggregator - Write to
                        Kafka</uicontrol> tab, configure the following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_i2g_jwd_dx">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Kafka Properties</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPBrokerURI">
                                    <entry/>
                                </row>
                                <row>
                                    <entry>Runtime Topic Resolution </entry>
                                    <entry>Do not use at this time. </entry>
                                </row>
                                <row>
                                    <entry>Topic</entry>
                                    <entry>Topic to use. To avoid mixing statistics from different
                                        jobs, use a unique topic name for each job.<p>You cannot
                                            define an expression that evaluates to the topic name.
                                        </p></entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPPartStrategy">
                                    <entry/>
                                </row>
                                <row>
                                    <entry>Partition Expression </entry>
                                    <entry>Expression to use when using the expression partition
                                            strategy.<p>Define the expression to evaluate to the
                                            partition where you want statistics written. Partition
                                            numbers start with 0.</p><p>Optionally, click
                                                <uicontrol>Ctrl + Space Bar</uicontrol> for help
                                            with creating the expression.</p></entry>
                                </row>
                                <row>
                                    <entry>Kafka Configuration</entry>
                                    <entry>Additional Kafka properties to use. Using <xref
                                            href="../Pipeline_Configuration/SimpleBulkEdit.dita#concept_alb_b3y_cbb"
                                            >simple or bulk edit mode</xref>, click the
                                            <uicontrol>Add</uicontrol> icon and define the Kafka
                                        property name and value.<p>Use the property names and values
                                            as expected by Kafka. Do not use the broker.list
                                            property.</p></entry>
                                </row>
                                <row>
                                    <entry>ZooKeeper URI</entry>
                                    <entry>Connection string for the ZooKeeper of the Kafka cluster.
                                        Use the following format:
                                            <codeph>&lt;host>:&lt;port></codeph>. <p>To use a
                                            ZooKeeper quorum, enter a comma-separated list.
                                            </p><p>To use a ZooKeeper chroot path, add the path at
                                            the end of the list as
                                            follows:<codeblock>&lt;host>:&lt;port>, &lt;host2>:&lt;port2>, .../&lt;chroot_path></codeblock></p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>To write statistics to Amazon Kinesis Streams, on the <uicontrol>Stats
                        Aggregator - Write to Kinesis</uicontrol> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_kh3_kls_dx">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>Kinesis Properties</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Access Key ID <xref
                                            href="../DPM/AggStatistics_KinesisAWSCredentials.dita"
                                                ><image href="../Graphics/icon_moreInfo.png"
                                                scale="10" id="image_ekt_x9g_cs"/>
                                        </xref></entry>
                                    <entry
                                        conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/AWSDest_AccessKeyID"
                                    />
                                </row>
                                <row>
                                    <entry>Secret Access Key <xref
                                            href="../DPM/AggStatistics_KinesisAWSCredentials.dita"
                                                ><image href="../Graphics/icon_moreInfo.png"
                                                scale="10" id="image_ekt_x6g_cs"/>
                                        </xref></entry>
                                    <entry
                                        conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/AWSDest_SecretAccessKey"
                                    />
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/rowKinesisRegion">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/rowKinesisEndpoint">
                                    <entry/>
                                </row>
                                <row>
                                    <entry>Stream Name</entry>
                                    <entry>Kinesis stream name. To avoid mixing statistics from
                                        different jobs, use a unique stream name for each job.<p>You
                                            cannot define an expression that evaluates to the stream
                                            name. </p></entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/rowKinesisPartitionStrategy">
                                    <entry/>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/rowKinesisPartitionExp">
                                    <entry/>
                                </row>
                                <row>
                                    <entry>Kinesis Producer Configuration</entry>
                                    <entry>Additional Kinesis properties.<p>When you add a
                                            configuration property, enter the exact property name
                                            and the value. The pipeline does not validate the
                                            property names or values.</p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>To write statistics to MapR Streams, on the <uicontrol>Stats Aggregator - Write
                        to MapR Streams</uicontrol> tab, configure the following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_z2j_315_mbb">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1.5*"/>
                            <colspec colname="c2" colnum="2" colwidth="3.5*"/>
                            <thead>
                                <row>
                                    <entry>MapR Streams Properties</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Runtime Topic Resolution </entry>
                                    <entry>Do not use at this time. </entry>
                                </row>
                                <row>
                                    <entry>Topic</entry>
                                    <entry>Topic to use. To avoid mixing statistics from different
                                        jobs, use a unique topic name for each job.<p>You cannot
                                            define an expression that evaluates to the topic name.
                                        </p></entry>
                                </row>
                                <row
                                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/KPPartStrategy">
                                    <entry/>
                                </row>
                                <row>
                                    <entry>Partition Expression </entry>
                                    <entry>Expression to use when using the expression partition
                                            strategy.<p>Define the expression to evaluate to the
                                            partition where you want statistics written. Partition
                                            numbers start with 0.</p><p>Optionally, click
                                                <uicontrol>Ctrl + Space Bar</uicontrol> for help
                                            with creating the expression.</p></entry>
                                </row>
                                <row>
                                    <entry>MapR Streams Configuration</entry>
                                    <entry>Additional configuration properties to use. Using <xref
                                            href="../Pipeline_Configuration/SimpleBulkEdit.dita#concept_alb_b3y_cbb"
                                            >simple or bulk edit mode</xref>, click the
                                            <uicontrol>Add</uicontrol> icon and define the MapR
                                        Streams property name and value.<p>Use the property names
                                            and values as expected by MapR Streams. You can use MapR
                                            Streams properties and the set of Kafka properties
                                            supported by MapR Streams. </p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
        </steps>
    </taskbody>
</task>
