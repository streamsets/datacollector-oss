<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_jzr_ypn_fw">
 <title>The Data-Processing Destination</title>
 <conbody>
        <p conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HD-CStudy-HDFS"/>
        <p>To write data to HDFS, you connect the Hadoop FS destination to the data output stream of
            the Hive Metadata processor. </p>
        <p
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HD-CStudy-HDFSuseatts"/>
        <p>The Output Files tab of the destination might look something like this:</p>
        <p><image href="../Graphics/HiveMeta-Ex-HDFS.png" id="image_sbv_xrn_fw" scale="70"/></p>
        <p>And the Data Format tab looks like this:</p>
        <p><image href="../Graphics/HiveMeta-Ex-HDFS-Avro.png" id="image_wzp_1sn_fw" scale="60"
            /></p>
        <p
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HD-CStudy-HDFSprocessing-p"/>
        <p>Note that the destination can also use Max Records in File, Max Files Size, and Idle
            Timeout to determine when to roll files.</p>
        <p>Also, if you want to compress the Avro files, use the Avro Compression Codec property on
            the Data Formats tab, instead of the general compression option on the Output Files
            tab.</p>
 </conbody>
</concept>
