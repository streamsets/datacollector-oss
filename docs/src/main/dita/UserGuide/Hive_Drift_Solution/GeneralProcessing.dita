<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_qtt_bzw_vz">
 <title>General Processing</title>
 <conbody>
        <p><indexterm>Drift Synchronization Solution for Hive<indexterm>general
                    processing</indexterm></indexterm>The <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HiveDrift-ph"/>
            incorporates the Hive Metadata processor, Hive Metastore destination, and the Hadoop FS
            or MapR FS destination as follows:</p>
        <p>
            <dl>
                <dlentry>
                    <dt>Drift detection</dt>
                    <dd>When processing records, the Hive Metadata processor detects columnar drift
                        and the need for new tables and partitions. It generates metadata records
                        that describe the necessary changes and passes it to the Hive Metastore
                        destination.</dd>
                    <dd>When the Hive Metastore destination receives a metadata record, it compares
                        the proposed changes with the latest Hive metadata, and creates and updates
                        Hive tables as needed.</dd>
                    <dd><ph
                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/D-HM-CreatesAndNot_PH"
                        /></dd>
                </dlentry>
                <dlentry>
                    <dt>Record-based writes</dt>
                    <dd>The Hive Metadata processor also adds information to the header of each
                        record and passes the records to the Hadoop FS destination or the MapR FS
                        destination. The destinations can perform record-based writes to their
                        destination systems based on the following details: <ul id="ul_sn1_bjg_2w">
                            <li>Target directory - Based on user-defined expressions, the Hive
                                Metadata processor assembles the path where each record should be
                                stored. It writes the generated path to a
                                    <term>targetDirectory</term> attribute in each record
                                    header.<p>To write the record to the generated path, configure
                                    the destination to use the targetDirectory header attribute.
                                </p></li>
                            <li>Avro schema - The processor writes the Avro schema to the
                                    <term>avroSchema</term> attribute in each record header. It
                                generates new Avro schemas when necessary based on the record
                                structure. Used for both Avro and Parquet data. <p>To use the
                                    generated Avro schema, configure the destination to use the
                                    avroSchema header attribute.</p></li>
                            <li>Roll files - When a schema change occurs, the processor generates a
                                roll indicator - the <term>roll</term> header attribute. This allows
                                the data with the changed schema to be written to an updated Hive
                                    table.<p>To roll files based on schema changes, configure the
                                    destination use the roll header attribute.</p></li>
                        </ul></dd>
                </dlentry>
            </dl>
        </p>
        <p>For example, say you use this solution to write sales data to MapR FS. A partial upgrade
            of the sales system adds several new fields to a subset of the incoming data. </p>
        <p>With the <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HiveDrift-ph"/>,
            the Hive Metadata processor notes the new fields in a metadata record and passes it to
            the Hive Metastore destination. The Hive Metastore destination adds the new columns to
            the Hive target table. The MapR FS destination then writes the data to the updated
            table. When writing data without the new fields to the updated table, the destination
            inserts null values for the missing fields.</p>
 </conbody>
</concept>
