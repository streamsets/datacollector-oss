<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_np1_pkz_ry">
 <title>Processor Caching</title>
 <conbody>
  <p><indexterm>multithreaded pipelines<indexterm>thread-based
                caching</indexterm></indexterm><indexterm>processor caching<indexterm>multithreaded
                    pipeline</indexterm></indexterm>Since multithreaded pipelines use multiple
            pipeline runners to run multiple sourceless pipeline instances, processor caching in a
            multithreaded pipeline can differ from a pipeline that runs on a single thread.</p>
        <p>Generally, when a processor caches data, each instance of the processor can only cache
            the data that passes through that particular pipeline runner. Be sure to consider this
            behavior when configuring multithreaded pipelines. </p>
        <p>For example, if you configure a lookup processor to create a local cache, each instance
            of the lookup processor creates its own local cache. This should not be a problem since
            the cache is generally used to improve pipeline performance. </p>
        <p>The exception is the Record Deduplicator processor. The Record Deduplicator caches
            records for comparison for up to a specified number of records or amount of time. When
            used in a multithreaded pipeline, the records in the cache are shared across pipeline
            runners. </p>
 </conbody>
</concept>
