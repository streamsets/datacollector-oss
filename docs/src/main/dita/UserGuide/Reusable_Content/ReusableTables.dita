<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_wfr_rnw_yq">
 <title>Reusable Tables of Information</title>
 <shortdesc/>
 <conbody>
  <p>
   <draft-comment author="Loretta">The following IgnoreControlChar-row is used in Configuring a -
    Directory, File Tail, Kafka Consumer, Kinesis Consumer, JSON Parser, Log
    Parser:]</draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table_mxl_xrm_js">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <tbody>
      <row id="IgnoreControlChars-row">
       <entry>Ignore Ctrl Characters <xref href="../Pipeline_Design/ControlCharacters.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" placement="inline"
          id="image_xwx_xrm_js"/></xref></entry>
       <entry>Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta">ORIGIN rows - <uicontrol>ProduceSingleRec</uicontrol> is used by
    Kafka Consumer and MapR Streams Consumer. <uicontrol>MaxBatchSize</uicontrol> and
     <uicontrol>BatchWaitTime</uicontrol> rows are used in Configuring Kafka Consumer, JMS Consumer.
    See if they should go anywhere else.</draft-comment>
   <draft-comment author="Loretta">Charsets are used by message and file origins. But Directory
    Charset is standalone. </draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table_tft_4jk_dt">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <tbody>
      <row>
       <entry/>
       <entry/>
      </row>
      <row id="ProduceSingleRec">
       <entry>Produce Single Record</entry>
       <entry>For each partition, generates a single record for records that include multiple
        objects. <p>When not selected, the origin generates multiple records when a record includes
         multiple objects.</p></entry>
      </row>
      <row id="MaxBatchSize">
       <entry>Max Batch Size (records)</entry>
       <entry>Maximum number of records processed at one time. Honors values up to the <ph
         conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> maximum
        batch size. <p>Default is 1000. The <ph
          conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> default
         is 1000.</p></entry>
      </row>
      <row id="BatchWaitTime">
       <entry>Batch Wait Time (ms) <xref href="../Origins/BatchSizeWaitTime.dita#concept_ypd_vgr_5q">
         <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_mgp_2q3_br"
          placement="inline"/></xref></entry>
       <entry>Number of milliseconds to wait before sending a partial or empty batch. </entry>
      </row>
      <row id="MessagesCharset">
       <entry>Charset</entry>
       <entry>Character encoding of the messages to be processed.<p>Not used for all data
         formats.</p></entry>
      </row>
      <row id="Charset">
       <entry>Charset</entry>
       <entry>Character encoding of the files to be processed.<p>Not used for all data
        formats.</p></entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta">The following rows are used in the Data Collector Console -
    Overview, </draft-comment>
  </p>
  <simpletable>
   <strow id="Icon-Help">
    <stentry><image href="../Graphics/icon_OverCHelp.png" id="image_bkz_wk3_ts"/></stentry>
    <stentry>Help icon</stentry>
    <stentry>Provides context-sensitive help based on the information in the panel. </stentry>
   </strow>
  </simpletable>
  <p>
   <draft-comment author="Loretta">The following row is used in Configuring Hive Streaming and
    Configuring JDBC Producer</draft-comment>
  </p>
  <table frame="all" rowsep="1" colsep="1" id="table_ps1_hln_jt">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="1.5*"/>
    <colspec colname="c2" colnum="2" colwidth="3.5*"/>
    <thead>
     <row>
      <entry/>
      <entry/>
     </row>
    </thead>
    <tbody>
     <row id="FIELD2ColumnMapping">
      <entry>Field to Column Mapping</entry>
      <entry>
       <p>Use to override the default field to column mappings. </p>
       <p>By default, fields are written to columns of the same name. </p>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </table>
  <p>
   <draft-comment author="alisontaylor">The following descriptions are used by the AWS destinations:
    Amazon S3, Kinesis Firehose, Kinesis Producer.</draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table_vnv_ncr_mv">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.5*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <tbody>
      <row>
       <entry>Access Key ID </entry>
       <entry id="AWSDest_AccessKeyID">
        <p>AWS access key ID.</p>
        <p>Required when not using IAM roles with IAM instance profile credentials.</p>
       </entry>
      </row>
      <row>
       <entry>Secret Access Key</entry>
       <entry id="AWSDest_SecretAccessKey">
        <p>AWS secret access key. </p>
        <p>Required when not using IAM roles with IAM instance profile credentials. </p>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <draft-comment author="alisontaylor">The following descriptions are used by the AWS origins:
    Amazon S3 and Kinesis Consumer.</draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table_lnx_51w_mv">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.5*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <tbody>
      <row>
       <entry>Access Key ID</entry>
       <entry id="AWSOrigin_AccessKeyID">
        <p>AWS access key ID.</p>
        <p>Required when not using IAM roles with IAM instance profile credentials.</p>
       </entry>
      </row>
      <row>
       <entry>Secret Access Key</entry>
       <entry id="AWSOrigin_SecretAccessKey">
        <p>AWS secret access key. </p>
        <p>Required when not using IAM roles with IAM instance profile credentials. </p>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <draft-comment author="Loretta">The following rows are used in full for the Amazon S3 origin and
    the Amazon S3 destination reuses individual rows. Data Format and File Compression are also used
    in Directory and SFTP Client.</draft-comment>
  </p>
  <p>
   <table frame="all" rowsep="1" colsep="1" id="AmazonS3-oProps">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.5*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <thead>
      <row>
       <entry>File Property</entry>
       <entry>Description</entry>
      </row>
     </thead>
     <tbody>
      <row id="S3-Region">
       <entry>Region</entry>
       <entry>Amazon S3 region. </entry>
      </row>
      <row id="S3Bucket">
       <entry>Bucket</entry>
       <entry>Bucket that contains the files to be read.</entry>
      </row>
      <row id="S3Folder">
       <entry>Common Prefix <xref href="../Origins/AmazonS3-CommonPrefixPatterns.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_wm3_212_wv"/>
        </xref></entry>
       <entry>Optional common prefix that describes the location of the data. When defined, the
        common prefix acts as a root for the prefix pattern.</entry>
      </row>
      <row id="S3ObjectPathDelimiter">
       <entry>Object Path Delimiter</entry>
       <entry>Delimiter used by Amazon S3 to define the directory structure.<p>Default is slash ( /
         ).</p></entry>
      </row>
      <row id="S3FileNamePattern">
       <entry>Prefix Pattern <xref href="../Origins/AmazonS3-CommonPrefixPatterns.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_tfr_bk5_ht"/>
        </xref></entry>
       <entry>
        <p>Prefix pattern that describes the files to be processed. </p>
        <p>You can include the entire path to the files. You can also use Ant-style path patterns to
         read files recursively. </p>
       </entry>
      </row>
      <row id="S3BufferLimit">
       <entry>Buffer Limit (KB)</entry>
       <entry>Maximum buffer size. The buffer size determines the size of the record that can be
        processed. <p>Decrease when memory on the <ph
          conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> machine
         is limited. Increase to process larger records when memory is available. </p><p>Default is
         128 KB.</p></entry>
      </row>
      <row id="Origin-FileCompression">
       <entry>Compression Format <xref href="../Origins/FileCompressionFormats.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" placement="inline"
          id="image_xqq_yv4_c5"/></xref></entry>
       <entry>The compression format of the files:<ul id="ul_vph_jp2_qs">
         <li>None - Processes only uncompressed files.</li>
         <li>Compressed File - Processes files compressed by the supported compression formats.</li>
         <li>Archive - Processes files archived by the supported archive formats.</li>
         <li>Compressed Archive - Processes files archived and compressed by the supported archive
          and compression formats.</li>
        </ul></entry>
      </row>
      <row id="S3DataFormat">
       <entry>Data Format <xref href="../Origins/AmazonS3-DataFormat.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_w4w_q3p_ht"/>
        </xref></entry>
       <entry id="entryDataFormats">Data format for source files. Use one of the following formats:<ul id="ul_y1t_wql_5q">
         <li>Avro</li>
         <li>Delimited</li>
         <li>JSON</li>
         <li>Log</li>
         <li>Protobuf</li>
         <li>SDC Record <xref href="../Pipeline_Design/SDCRecordFormat.dita#concept_qkk_mwk_br">
           <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_wjh_ycl_br"
            placement="inline"/></xref></li>
         <li>Text</li>
         <li>XML</li>
        </ul></entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta">HTTP Client origin and processor rows:</draft-comment>
  </p>
  <p>
   <table frame="all" rowsep="1" colsep="1" id="table_jf4_g24_jw">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.0*"/>
     <colspec colname="c2" colnum="2" colwidth="1.0*"/>
     <thead>
      <row>
       <entry/>
       <entry/>
      </row>
     </thead>
     <tbody>
      <row>
       <entry/>
       <entry/>
      </row>
      <row id="HTTP-AuthType">
       <entry>Authentication Type</entry>
       <entry>Determines the authentication type used to connect to the server:<ul
         id="ul_icm_h1l_35">
         <li>None - Performs no authentication.</li>
         <li>Basic - Uses basic authentication. Requires a username and password. <p>Use with HTTPS
           to avoid passing unencrypted credentials.</p></li>
         <li>Digest - Uses digest authentication. Requires a username and password.</li>
         <li>Universal - Makes an anonymous connection, then provides authentication credentials
          upon receiving a 401 status and a WWW-Authenticate header request. <p>Requires a username
           and password associated with basic or digest authentication.</p><p>Use only with servers
           that respond to this workflow.</p></li>
         <li>OAuth - Uses OAuth 1.0 authentication. Requires OAuth credentials.</li>
        </ul></entry>
      </row>
      <row id="HTTP-UseProxy">
       <entry>Use Proxy</entry>
       <entry>
        <p>Enables using an HTTP proxy to connect to the system. </p>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta">PROCESSOR rows</draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table_u2r_4x5_lv">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.0*"/>
     <colspec colname="c2" colnum="2" colwidth="1.0*"/>
     <thead>
      <row>
       <entry/>
       <entry/>
      </row>
     </thead>
     <tbody>
      <row id="P-HashType">
       <entry>Hash Type</entry>
       <entry>Algorithm to use to hash field values:<ul id="ul_kmd_rnk_wq">
         <li>MD5 - Produces a 128-bit (16-byte) hash value, typically expressed in text format as a
          32 digit hexadecimal number.</li>
         <li>SHA1 - Produces a 160-bit (20-byte) hash value.</li>
         <li>SHA2 - Based on SHA1, but uses a set of four hash functions: 224, 256, 384, or 512
          bits.</li>
         <li>MURMUR3_128 - Produces a 128-bit (16 byte) hash value.</li>
        </ul></entry>
      </row>
      <row id="P-HashTargetField">
       <entry>Target Field</entry>
       <entry>Field in the record to use for hashed data. If the field does not exist, Field Hasher
        creates the field. </entry>
      </row>
      <row id="P-HashHeaderAtt">
       <entry>Header Attribute</entry>
       <entry>Attribute in the record header to use for hashed data. If the attribute does not
        exist, Field Hasher creates the attribute.</entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <draft-comment author="Loretta">The Hive Metadata processor and the Hive Metastore destination
   configuring topics use these individual rows and the Max entries description:</draft-comment>
  <p>
   <table frame="all" rowsep="1" colsep="1" id="table_w1l_34y_dw">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.5*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <thead>
      <row>
       <entry>Hive Property</entry>
       <entry>Description</entry>
      </row>
     </thead>
     <tbody>
      <row id="P-D_HiveJDBCURL">
       <entry>JDBC URL</entry>
       <entry>JDBC URL for Hive. You can use the default, or replace the expression for the database
        name with a specific database name when appropriate.</entry>
      </row>
      <row id="P-D_HiveJDBCdriver">
       <entry>JDBC Driver Name</entry>
       <entry>The fully-qualified JDBC driver name.</entry>
      </row>
      <row id="P-D_HiveConfigDir">
       <entry>Hadoop Configuration Directory</entry>
       <entry>
        <p>Absolute path to the directory containing the Hive and Hadoop configuration files. For a
         Cloudera Manager installation, enter hive-conf. </p>
        <p>The stage uses the following configuration files: <ul
          conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HiveStreamingFiles"
          id="ul_tqf_lms_dw">
          <li/>
         </ul></p>
        <note>Properties in the configuration files are overridden by individual properties defined
         in this processor. </note>
       </entry>
      </row>
      <row id="P-D-Hive-AddConfig">
       <entry>Additional Hadoop Configuration</entry>
       <entry>
        <p>Additional properties to use. </p>
        <p>To add properties, click <uicontrol>Add</uicontrol> and define the property name and
         value. Use the property names and values as expected by HDFS and Hive.</p>
       </entry>
      </row>
      <row>
       <entry>Max Cache Size (not conrefed)</entry>
       <entry id="P-D_HiveMaxCacheSize">Maximum number of entries in the cache. <p>When the cache
         reaches the maximum size, the oldest cached entries are evicted to allow for new
         data.</p><p>Default is -1, an unlimited cache size.</p></entry>
      </row>
      <row>
       <entry/>
       <entry/>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta">DESTINATION rows</draft-comment>
  </p>
  <p>
   <table frame="all" rowsep="1" colsep="1" id="table_l3k_ksh_r5">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.5*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <thead>
      <row>
       <entry/>
       <entry/>
      </row>
     </thead>
     <tbody>
      <row id="D-CHARSET-file">
       <entry>Charset</entry>
       <entry>Character set to use when writing files. <p>Not used with all data
        formats.</p></entry>
      </row>
      <row id="D-CHARSET-other">
       <entry>Charset</entry>
       <entry>Character set to use when writing data. <p>Not used with all data formats.</p></entry>
      </row>
      <row>
       <entry/>
       <entry/>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta"><b>table-JDBCAdvProps</b> - JDBC Consumer uses the whole table,
    row by row. Producer uses all rows but last.</draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table-JDBCAdvProps">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1.5*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <thead>
      <row>
       <entry>Advanced Property</entry>
       <entry>Description</entry>
      </row>
     </thead>
     <tbody>
      <row id="row-MaxPoolSize">
       <entry>Maximum Pool Size </entry>
       <entry>The maximum number of connections to create. <p>Default is 1. The recommended value is
         1.</p></entry>
      </row>
      <row id="row-MaxIdleConn">
       <entry>Minimum Idle Connections</entry>
       <entry>The minimum number of connections to create and maintain. To define a fixed connection
        pool, set to the same value as Maximum Pool Size. <p>Default is 1. </p></entry>
      </row>
      <row id="row-ConTimeout">
       <entry>Connection Timeout</entry>
       <entry>Maximum time to wait for a connection. Use a time constant in an expression to define
        the time increment. <p>Default is 30 seconds, defined as follows:
         <codeblock>${30 * SECONDS}</codeblock></p></entry>
      </row>
      <row id="row-IdleTimeout">
       <entry>Idle Timeout</entry>
       <entry>Maximum time to allow a connection to idle. Use a time constant in an expression to
        define the time increment. <p>Use 0 to avoid removing any idle connections.</p><p>Default is
         30 minutes, defined as follows: <codeblock>${30 * MINUTES}</codeblock></p></entry>
      </row>
      <row id="row-MaxConLife">
       <entry>Max Connection Lifetime</entry>
       <entry>Maximum lifetime for a connection. Use a time constant in an expression to define the
        time increment. <p>Use 0 to avoid removing any idle connections.</p><p>Default is 30
         seconds, defined as follows: <codeblock>${30 * SECONDS}</codeblock></p></entry>
      </row>
      <row id="row-EnReadOnly">
       <entry>Enforce Read-only Connection</entry>
       <entry>Creates read-only connections to avoid any type of write. <p>Selected by default.
         Clearing this property is not recommended. </p></entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <draft-comment author="alisontaylor"><b>table-S3AdvProps</b> Amazon S3 origin/destination use the
   whole table, Kinesis Consumer uses all rows but the first.</draft-comment>
  <table frame="all" rowsep="1" colsep="1" id="table-S3AdvProps">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="1.5*"/>
    <colspec colname="c2" colnum="2" colwidth="3.5*"/>
    <thead>
     <row>
      <entry>Advanced Property</entry>
      <entry>Description</entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry>Use Proxy</entry>
      <entry>Specifies whether to use a proxy to connect to Amazon S3.</entry>
     </row>
     <row id="row-ProxyHost">
      <entry>Proxy Host</entry>
      <entry>Proxy host.</entry>
     </row>
     <row id="row-ProxyPort">
      <entry>Proxy Port</entry>
      <entry>Proxy port.</entry>
     </row>
     <row id="row-ProxyUser">
      <entry>Proxy User</entry>
      <entry>User name for proxy credentials.</entry>
     </row>
     <row id="row-ProxyPassword">
      <entry>Proxy Password</entry>
      <entry>Password for proxy credentials. </entry>
     </row>
    </tbody>
   </tgroup>
  </table>
  <draft-comment author="alisontaylor">HBase, Redis, and Static Lookup processors use rows in the
   table.</draft-comment>
  <table frame="all" rowsep="1" colsep="1" id="table_ns1_p1s_zv">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="1.5*"/>
    <colspec colname="c2" colnum="2" colwidth="3.0*"/>
    <thead>
     <row>
      <entry>Lookup Property</entry>
      <entry>Description</entry>
     </row>
    </thead>
    <tbody>
     <row id="row-Mode">
      <entry>Mode</entry>
      <entry>Mode used to perform the lookups:<ul id="ul_t11_3fs_zv">
       <li>Per Batch - Performs a bulk lookup of all keys in a
        batch. The processor performs a single lookup for
        each batch.</li>
       <li>Per Key in Each Record - Performs individual lookups
        of each key in each record. If you configure
        multiple key expressions, the processor performs
        multiple lookups for each record.</li>
      </ul><p>Default is Per Batch.</p></entry>
     </row>
     <row>
      <entry>Enable Local Caching </entry>
      <entry id="entry-LocalCaching">Specifies whether to locally cache the returned key-value
       pairs.</entry>
     </row>
     <row id="row-MaxEntriesCache">
      <entry>Maximum Entries to Cache</entry>
      <entry>Maximum number of key-value pairs to cache. When the
       maximum number is reached, the processor evicts the oldest
       key-value pairs from the cache. <p>Default is -1, which
        means unlimited.</p></entry>
     </row>
     <row id="row-EvictionPolicy">
      <entry>Eviction Policy Type</entry>
      <entry>Policy used to evict key-value pairs from the local cache
       when the expiration time has passed:<ul id="ul_jql_yns_zv">
        <li>Expire After Last Access - Measures the expiration
         time since the key-value pair was last accessed by a
         read or a write.</li>
        <li>Expire After Last Write - Measures the expiration
         time since the key-value pair was created, or since
         the value was last replaced.</li>
       </ul></entry>
     </row>
     <row id="row-ExpirationTime">
      <entry>Expiration Time</entry>
      <entry>Amount of time that a key-value pair can remain in the
       local cache without being accessed or written to. <p>Default
        is 1 second.</p></entry>
     </row>
     <row id="row-timeUnit">
      <entry>Time Unit</entry>
      <entry>Unit of time for the expiration time. <p>Default is
       seconds.</p></entry>
     </row>
    </tbody>
   </tgroup>
  </table>
  <draft-comment author="alisontaylor">HBase destination and HBase Lookup use rows and entries in
   this table</draft-comment>
  <table frame="all" rowsep="1" colsep="1" id="table_bgt_kly_bw">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="1.5*"/>
    <colspec colname="c2" colnum="2" colwidth="3.0*"/>
    <thead>
     <row>
      <entry>HBase Property</entry>
      <entry>Description</entry>
     </row>
    </thead>
    <tbody>
     <row id="row-ZooKeeperQuorum">
      <entry>ZooKeeper Quorum</entry>
      <entry>Comma-separated list of servers in the ZooKeeper quorum. Use the following format:
        <codeblock>&lt;host>.&lt;domain>.com</codeblock><p>To ensure a connection, enter additional
        broker URIs.</p></entry>
     </row>
     <row id="row-ZooKeeperClient">
      <entry>ZooKeeper Client Port</entry>
      <entry>Port number clients use to connect to the ZooKeeper servers. </entry>
     </row>
     <row id="row-ZooKeeperParent">
      <entry>ZooKeeper Parent Znode</entry>
      <entry>Root node that contains all znodes used by the HBase cluster.</entry>
     </row>
     <row id="row-TableName">
      <entry>Table Name</entry>
      <entry>Name of the HBase table to use. Enter a table name or a namespace and table name as
       follows: &lt;namespace>.&lt;tablename>. <p>If you do not enter a table name, HBase uses the
        default namespace. </p></entry>
     </row>
     <row>
      <entry>Kerberos Authentication </entry>
      <entry id="entry-Kerberos">Uses Kerberos credentials to connect to HBase.<p>When
       selected, uses the Kerberos principal and keytab defined
       in the <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
       /> configuration file, <codeph>$SDC_CONF/sdc.properties</codeph>. </p></entry>
     </row>
     <row>
      <entry>HBase User </entry>
      <entry id="entry-HBaseUser">The HBase user to use to connect to HBase. When using
       this property, make sure HBase is configured
       appropriately.<p>By default, the pipeline uses the <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
       /> user to connect to HBase.</p></entry>
     </row>
     <row>
      <entry>HBase Configuration Directory</entry>
      <entry id="entry-HBaseConfigDirectory">Location of the HDFS configuration files. <p>For a
       Cloudera Manager installation, enter
       <codeph>hbase-conf</codeph>. For all other
       installations, use a directory or symlink within the <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
       /> resources directory.</p><p>You can use the following
        file with HBase:<ul
         conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HDFSfiles_HBasedest"
         id="ul_ezj_cvr_bt">
         <li/>
        </ul></p><note>Properties in the configuration files are
         overridden by individual properties defined in the
         stage.</note></entry>
     </row>
     <row>
      <entry>HBase Configuration</entry>
      <entry id="entry-HBaseConfig">
       <p>Additional HBase configuration properties to use. </p>
       <p>To add properties, click <uicontrol>Add</uicontrol> and
        define the property name and value. Use the property
        names and values as expected by HBase. </p>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </table>
  <draft-comment author="alisontaylor">Redis origin, destination, and Lookup processor use this
   row</draft-comment>
  <table frame="all" rowsep="1" colsep="1" id="table_i5s_54s_zv">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="1.5*"/>
    <colspec colname="c2" colnum="2" colwidth="3.0*"/>
    <thead>
     <row>
      <entry>Redis Property</entry>
      <entry>Description</entry>
     </row>
    </thead>
    <tbody>
     <row id="row-RedisURI">
      <entry>URI</entry>
      <entry>URI of the Redis server. Use the following
        format:<codeblock>redis://&lt;host name>:&lt;port number>/&lt;database></codeblock><p>You
        can omit the port number or database if the server uses the default port number or default
        database.</p><p>You can optionally include your password to log in to the Redis server. For
        example:<codeblock>redis://:&lt;password>@&lt;host name>:&lt;port number>/&lt;database></codeblock></p></entry>
     </row>
    </tbody>
   </tgroup>
  </table>
 </conbody>
</concept>
