<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_rz5_nft_zv">
 <title>Hive Metadata</title>
 <shortdesc>The Hive Metadata processor works with the Hive Metastore destination, and the Hadoop FS
        or MapR FS destinations as part of the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/HiveDrift-ph"/>. </shortdesc>
 <conbody>
        <p><indexterm>processors<indexterm>Hive Metadata</indexterm></indexterm><indexterm>Hive
                Metadata processor<indexterm>overview</indexterm></indexterm>Use the Hive Metadata
            processor for records to be written to HDFS or MapR FS when you want the Hive Metastore
            destination to create and update tables as needed. The processor also generates record
            header attributes that the Hadoop FS destination and the MapR FS destination can use to
            process the data.</p>
  <p>When you configure the Hive Metadata processor, you define the connection information for Hive
            and the expressions that define the database, table, partitions, and decimal field
            expressions that the records require. You also specify the data format to use: Avro or
            Parquet. </p>
        <p>You define the location of the Hive and Hadoop configuration files and optionally specify
            additional required properties. You can also configure advanced options, such as the
            maximum cache size, time basis, decimal precision and scale expressions, and custom
            record header attributes for the metadata record.</p>
        <p>For more information about the Drift Synchronization Solution for Hive and case studies
            for processing Avro and Parquet data, see <xref
                href="../Hive_Drift_Solution/HiveDrift-Overview.dita#concept_phk_bdf_2w"/>. For a
            tutorial, check out our <xref
                href="https://github.com/streamsets/tutorials/blob/master/tutorial-hivedrift/readme.md"
                format="html" scope="external">tutorial on Github</xref>.</p>
 </conbody>
    <related-links>
        <link href="../Hive_Drift_Solution/HiveDataTypes.dita#concept_ry2_qkm_hw"/>
    </related-links>
</concept>
