
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="Use the following tips for help with destination stages and systems. Why is the pipeline failing entire batches when only a few records have a problem? Due to Cassandra requirements, when you write to ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="concept"></meta><meta name="DC.Title" content="Destinations"></meta><meta name="DC.Relation" scheme="URI" content="../Troubleshooting/Troubleshooting_title.html"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="concept_m4g_qyk_2s"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Destinations</title><!--  Generated with Oxygen version 17.1, build number 2016020417.  --><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script><!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
--></head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Troubleshooting/Troubleshooting_title.html" title="Troubleshooting">Troubleshooting</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Troubleshooting/Troubleshooting_title.html" title="Troubleshooting"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Troubleshooting</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="concept_m4g_qyk_2s">
 <h1 class="title topictitle1">Destinations </h1>

 <div class="body conbody">
  <p class="p">Use
            the following tips for help with destination stages and systems.</p>

  </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_a3w_z3m_js">
 <h2 class="title topictitle2">Cassandra</h2>

 <div class="body conbody">
  <div class="p">
   <dl class="dl">
    
     <dt class="dt dlterm">Why is the pipeline failing entire batches when only a few records have a problem?</dt>

     <dd class="dd">Due to Cassandra requirements, when you write to a Cassandra cluster, batches are atomic.
      This means than an error in a one or more records causes the entire batch to fail.</dd>

    
    
     <dt class="dt dlterm">Why is all of my data being sent to error? Every batch is failing.</dt>

     <dd class="dd">When every batch fails, you might have a data type mismatch. Cassandra requires the data
      type of the data to exactly match the data type of the Cassandra column. </dd>

     <dd class="dd">To determine the issue, check the error messages associated with the error records. If you
      see a message like the following, you have a data type mismatch. The following error message
      indicates that data type mismatch is for Integer data being unsuccessfully written to a Varchar
      column:
      <pre class="pre codeblock">CASSANDRA_06 - Could not prepare record 'sdk:': 
Invalid type for value 0 of CQL type varchar, expecting class java.lang.String but class java.lang. 
Integer provided`</pre>
</dd>

     <dd class="dd">To correct the problem, you might use a Field Type Converter processor to convert field
      data types. In this case, you would convert the integer data to string.</dd>

    
   </dl>

  </div>

 </div>

</div>
<div class="topic concept nested1" id="unique_1420270447">
 <h2 class="title topictitle2">Hadoop FS</h2>

 <div class="body conbody">
  <div class="p">
   <dl class="dl">
    
     <dt class="dt dlterm">I'm writing text data to HDFS. Why are my files all empty? </dt>

     <dd class="dd">You might not have the pipeline or Hadoop FS destination configured correctly. </dd>

     <dd class="dd">The Hadoop FS destination uses a single field to write text data to HDFS. </dd>

     <dd class="dd">The pipeline should collapse all data to a single field. And the Hadoop FS destination must
      be configured to use that field. By default, Hadoop FS uses a field named /text. </dd>

    
   </dl>

  </div>

 </div>

</div>
<div class="topic concept nested1" id="concept_rp1_ghd_zs">
 <h2 class="title topictitle2">HBase</h2>

 <div class="body conbody">
  <div class="p">
   <dl class="dl">
    
     <dt class="dt dlterm">I get the following error when validating or starting a pipeline with an HBase
      destination:</dt>

     <dd class="dd">
      <pre class="pre codeblock">HBASE_06 - Cannot connect to cluster: org.apache.hadoop.hbase.MasterNotRunningException: 
com.google.protobuf.ServiceException: org.apache.hadoop.hbase.exceptions.ConnectionClosingException: 
Call to node00.local/&lt;IP_address&gt;:60000 failed on local exception: 
org.apache.hadoop.hbase.exceptions.ConnectionClosingException: 
Connection to node00.local/&lt;IP_address&gt;:60000 is closing. Call id=0, waitTime=58</pre>

     </dd>

     <dd class="dd">Is your HBase master is running? If so, then you might trying to connect to a secure HBase
      cluster without configuring the HBase destination to use Kerberos authentication. In the HBase
      destination properties, select <span class="ph uicontrol">Kerberos Authentication</span> and try
      again.</dd>

    
   </dl>

  </div>

 </div>

</div>
<div class="topic concept nested1" id="concept_mth_cjm_js">
 <h2 class="title topictitle2">Kafka Producer</h2>

 <div class="body conbody">
  <div class="p">
   <dl class="dl">
    
     <dt class="dt dlterm">Can the Kafka Producer create topics?</dt>

     <dd class="dd">The Kafka Producer can create a topic when all of the following are true:<ul class="ul" id="concept_mth_cjm_js__ul_j4q_25y_3r">
       <li class="li">You configure the Kafka Producer to write to a topic name that does not exist.</li>

       <li class="li">At least one of the Kafka brokers defined for the Kafka Producer has the
        auto.create.topics.enable property enabled.</li>

       <li class="li">The broker with the enabled property is up and available when the Kafka Producer looks
        for the topic.</li>

      </ul>
</dd>

    
    
     <dt class="dt dlterm">How can I reset the offset for a Kafka Consumer?</dt>

     <dd class="dd">Since the offset for a Kafka Consumer is stored with the ZooKeeper for the Kafka cluster,
      you cannot reset the offset through the <span class="ph">Data
                  Collector</span>. For
      information about resetting an offset through Kafka, see the Apache Kafka documentation. </dd>

    
        
          <dt class="dt dlterm">A pipeline that writes to Kafka keeps failing and restarting in an endless cycle.</dt>

          <dd class="dd">This can happen when the pipeline tries to write message to Kafka 0.8 that is longer
            than the Kafka maximum message size. </dd>

          <dd class="dd">Workaround: Reconfigure Kafka brokers to allow larger messages or ensure that incoming
            records are within the configured limit. </dd>

        
   </dl>

  </div>

 </div>

</div>
<div class="topic concept nested1" id="concept_gt1_s41_rt">
 <h2 class="title topictitle2">SDC RPC</h2>

 <div class="body conbody">
  <div class="p">
            <dl class="dl">
                
                    <dt class="dt dlterm">A pipeline fails to start with the following validation error:</dt>

                    <dd class="dd">
                        <pre class="pre codeblock">IPC_DEST_15 Could not connect to any SDC RPC destination : [&lt;host name&gt;: 
java.net.ConnectException: Connection refused]</pre>

                    </dd>

                    <dd class="dd">You configured the pipeline to write error records to a pipeline, but the
                        configuration information for the error records pipeline is invalid. </dd>

                    <dd class="dd">To write error records to a pipeline, you need a valid destination pipeline
                        that includes an RPC origin.</dd>

                
            </dl>

        </div>

 </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Troubleshooting/Troubleshooting_title.html" title="Troubleshooting"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Troubleshooting</span></a></span>  </div><div class="footer"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>