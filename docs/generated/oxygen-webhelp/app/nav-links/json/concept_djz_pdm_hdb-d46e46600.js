define({"topics" : [{"title":"File Directory","shortdesc":"\n               <p class=\"shortdesc\"></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_wcp_zxk_1hb","attributes": {"data-id":"concept_wcp_zxk_1hb",},"menu": {"hasChildren":false,},"tocID":"concept_wcp_zxk_1hb-d46e46954","topics":[]},{"title":"File Name Pattern and Mode","shortdesc":"\n               <p class=\"shortdesc\">Use a file name pattern to define the files that the <span class=\"ph\">Hadoop FS Standalone</span> origin         processes. <span class=\"ph\">You can use either a glob pattern or a regular expression to define                 the file name pattern. </span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_exc_22h_ldb","attributes": {"data-id":"concept_exc_22h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_exc_22h_ldb-d46e46978","topics":[]},{"title":"Read Order","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_ogz_q3h_ldb","attributes": {"data-id":"concept_ogz_q3h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_ogz_q3h_ldb-d46e47030","topics":[]},{"title":"Multithreaded Processing","shortdesc":"\n               <p class=\"shortdesc\">The <span class=\"ph\">Hadoop FS Standalone</span> origin uses multiple concurrent threads to process data         based on the Number of Threads property. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_fgx_1jh_ldb","attributes": {"data-id":"concept_fgx_1jh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_fgx_1jh_ldb-d46e47098","topics":[]},{"title":"Reading from Subdirectories","shortdesc":"\n               <p class=\"shortdesc\">When using the Last Modified Timestamp read order, the <span class=\"ph\">Hadoop FS Standalone</span>         origin can read files in subdirectories of the specified file directory. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_bwq_nyj_mdb","attributes": {"data-id":"concept_bwq_nyj_mdb",},"menu": {"hasChildren":true,},"tocID":"concept_bwq_nyj_mdb-d46e47197","next":"concept_bwq_nyj_mdb-d46e47197",},{"title":"First File for Processing","shortdesc":"\n               <p class=\"shortdesc\">Configure a first file for processing when you want the <span class=\"ph\">Hadoop FS Standalone</span>         origin to ignore one or more existing files in the directory.\n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_a2q_4kh_ldb","attributes": {"data-id":"concept_a2q_4kh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_a2q_4kh_ldb-d46e47449","topics":[]},{"title":"Reading from Azure Data Lake Storage","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin can read data directly from Azure Data Lake Storage         using the ADL protocol provided\n                  by Hadoop. The origin can connect using Azure Active         Directory Service Principal or refresh-token authentication.\n                  \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_hzz_tjr_1gb","attributes": {"data-id":"concept_hzz_tjr_1gb",},"menu": {"hasChildren":false,},"tocID":"concept_hzz_tjr_1gb-d46e47620","topics":[]},{"title":"Reading from Azure HDInsight","shortdesc":"\n               <p class=\"shortdesc\">You can use the HDP stage libraries to access Azure blob storage using the WASB         protocol. This enables the Hadoop\n                  FS Standalone origin to read from Azure HDInsight. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vfk_yrv_ldb","attributes": {"data-id":"concept_vfk_yrv_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vfk_yrv_ldb-d46e47798","topics":[]},{"title":"Record Header Attributes","shortdesc":"\n               <p class=\"shortdesc\">The <span class=\"ph\">Hadoop FS Standalone</span> origin <span class=\"ph\">creates record header                 attributes that include <span class=\"ph\">information about the originating file for                     the record</span>.</span>     \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_asp_lfh_ldb","attributes": {"data-id":"concept_asp_lfh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_asp_lfh_ldb-d46e47986","topics":[]},{"title":"Event Generation","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_zlx_5rh_ldb","attributes": {"data-id":"concept_zlx_5rh_ldb",},"menu": {"hasChildren":true,},"tocID":"concept_zlx_5rh_ldb-d46e48202","next":"concept_zlx_5rh_ldb-d46e48202",},{"title":"Buffer Limit and Error Handling","shortdesc":"\n               <p class=\"shortdesc\">The <span class=\"ph\">Hadoop FS Standalone</span> origin <span class=\"ph\">passes each record to a buffer. The size of the buffer determines                 the maximum size of the record that can\n                     be processed. Decrease the buffer limit when                 memory on the <span class=\"ph\">Data Collector</span>                 machine is limited. Increase the buffer limit to process larger records when memory                 is available.</span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_jbn_md3_ldb","attributes": {"data-id":"concept_jbn_md3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_jbn_md3_ldb-d46e48683","topics":[]},{"title":"Kerberos Authentication","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vvd_4zp_ldb","attributes": {"data-id":"concept_vvd_4zp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vvd_4zp_ldb-d46e48970","topics":[]},{"title":"HDFS Properties and Configuration Files","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_zx5_yzp_ldb","attributes": {"data-id":"concept_zx5_yzp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_zx5_yzp_ldb-d46e49256","topics":[]},{"title":"Impersonation User","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_ub1_zwp_ldb","attributes": {"data-id":"concept_ub1_zwp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_ub1_zwp_ldb-d46e49552","topics":[]},{"title":"Data Formats","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vym_zd3_ldb","attributes": {"data-id":"concept_vym_zd3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vym_zd3_ldb-d46e49858","topics":[]},{"title":"Configuring a Hadoop FS Standalone Origin","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#task_l3t_sdm_hdb","attributes": {"data-id":"task_l3t_sdm_hdb",},"menu": {"hasChildren":false,},"tocID":"task_l3t_sdm_hdb-d46e50186","topics":[]}]});