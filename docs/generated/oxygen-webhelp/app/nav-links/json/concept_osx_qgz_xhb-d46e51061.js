define({"topics" : [{"title":"Prerequisites","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_tjg_ggw_b3b","attributes": {"data-id":"concept_tjg_ggw_b3b",},"menu": {"hasChildren":true,},"tocID":"concept_tjg_ggw_b3b-d46e51382","next":"concept_tjg_ggw_b3b-d46e51382",},{"title":"File Directory","shortdesc":"\n               <p class=\"shortdesc\"></p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_wcp_zxk_1hb","attributes": {"data-id":"concept_wcp_zxk_1hb",},"menu": {"hasChildren":false,},"tocID":"concept_wcp_zxk_1hb-d46e51436","topics":[]},{"title":"File Name Pattern and Mode","shortdesc":"\n               <p class=\"shortdesc\">Use a file name pattern to define the files that the <span class=\"ph\">Azure Data Lake Storage Gen2</span> origin         processes. <span class=\"ph\">You can use either a glob pattern or a regular expression to define                 the file name pattern. </span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_exc_22h_ldb","attributes": {"data-id":"concept_exc_22h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_exc_22h_ldb-d46e51480","topics":[]},{"title":"Read Order","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_ogz_q3h_ldb","attributes": {"data-id":"concept_ogz_q3h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_ogz_q3h_ldb-d46e51553","topics":[]},{"title":"Multithreaded Processing","shortdesc":"\n               <p class=\"shortdesc\">The <span class=\"ph\">Azure Data Lake Storage Gen2</span> origin uses multiple concurrent threads to process data         based on the Number of Threads property. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_fgx_1jh_ldb","attributes": {"data-id":"concept_fgx_1jh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_fgx_1jh_ldb-d46e51642","topics":[]},{"title":"Reading from Subdirectories","shortdesc":"\n               <p class=\"shortdesc\">When using the Last Modified Timestamp read order, the <span class=\"ph\">Azure Data Lake Storage Gen2</span>         origin can read files in subdirectories of the specified file directory. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_bwq_nyj_mdb","attributes": {"data-id":"concept_bwq_nyj_mdb",},"menu": {"hasChildren":true,},"tocID":"concept_bwq_nyj_mdb-d46e51761","next":"concept_bwq_nyj_mdb-d46e51761",},{"title":"First File for Processing","shortdesc":"\n               <p class=\"shortdesc\">Configure a first file for processing when you want the <span class=\"ph\">Azure Data Lake Storage Gen2</span>         origin to ignore one or more existing files in the directory.\n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_a2q_4kh_ldb","attributes": {"data-id":"concept_a2q_4kh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_a2q_4kh_ldb-d46e52053","topics":[]},{"title":"Record Header Attributes","shortdesc":"\n               <p class=\"shortdesc\">The <span class=\"ph\">Azure Data Lake Storage Gen2</span> origin <span class=\"ph\">creates record header                 attributes that include <span class=\"ph\">information about the originating file for                     the record</span>.</span>     \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_asp_lfh_ldb","attributes": {"data-id":"concept_asp_lfh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_asp_lfh_ldb-d46e52244","topics":[]},{"title":"Event Generation","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_zlx_5rh_ldb","attributes": {"data-id":"concept_zlx_5rh_ldb",},"menu": {"hasChildren":true,},"tocID":"concept_zlx_5rh_ldb-d46e52460","next":"concept_zlx_5rh_ldb-d46e52460",},{"title":"Buffer Limit and Error Handling","shortdesc":"\n               <p class=\"shortdesc\">The <span class=\"ph\">Azure Data Lake Storage Gen2</span> origin <span class=\"ph\">passes each record to a buffer. The size of the buffer determines                 the maximum size of the record that can\n                     be processed. Decrease the buffer limit when                 memory on the <span class=\"ph\">Data Collector</span>                 machine is limited. Increase the buffer limit to process larger records when memory                 is available.</span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_jbn_md3_ldb","attributes": {"data-id":"concept_jbn_md3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_jbn_md3_ldb-d46e52940","topics":[]},{"title":"Data Formats","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#concept_vym_zd3_ldb","attributes": {"data-id":"concept_vym_zd3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vym_zd3_ldb-d46e53228","topics":[]},{"title":"Configuring an Azure Data Lake Storage Gen2 Origin","shortdesc":"\n               <p class=\"shortdesc\"></p>\n            ","href":"datacollector\/UserGuide\/Origins\/ADLS-G2.html#task_sh1_d45_rhb","attributes": {"data-id":"task_sh1_d45_rhb",},"menu": {"hasChildren":false,},"tocID":"task_sh1_d45_rhb-d46e53526","topics":[]}]});