
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS). You can read log, JSON, or text data with the Hadoop FS origin. Use this origin only in pipelines configured for cluster ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="concept"></meta><meta name="DC.Title" content="Hadoop FS"></meta><meta name="abstract" content="The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS). You can read log, JSON, or text data with the Hadoop FS origin. Use this origin only in pipelines configured for cluster execution mode."></meta><meta name="description" content="The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS). You can read log, JSON, or text data with the Hadoop FS origin. Use this origin only in pipelines configured for cluster execution mode."></meta><meta name="DC.Relation" scheme="URI" content="../Origins/Origins_title.html"></meta><meta name="DC.Relation" scheme="URI" content="../Cluster_Mode/ClusterPipelines.html#concept_hmh_kfn_1s"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="concept_lw2_tnm_vs"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Hadoop FS</title><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script></head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Origins/Origins_title.html" title="Origins">Origins</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="concept_lw2_tnm_vs">
 <h1 class="title topictitle1">Hadoop FS</h1>

 
 <div class="body conbody"><p class="shortdesc">The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS). You can
    read log, JSON, or text data with the Hadoop FS origin. Use this origin only in pipelines
    configured for cluster execution mode.</p>

  <p class="p">When you configure the Hadoop FS origin, you specify the
      directory path and data format for the data. You can configure the origin to read from all
      subdirectories and to generate a single record for records that include multiple objects. </p>

    <p class="p">When necessary, you can enable Kerberos authentication or use an
                  HDFS user to connect to HDFS. You can also use HDFS configuration files and add
                  other HDFS configuration properties as needed. </p>

 </div>

  <div class="related-links"><div class="relinfo relconcepts"><strong>Related concepts</strong><br></br>
<div class="related_link"><a class="navheader_parent_path" href="../Cluster_Mode/ClusterPipelines.html#concept_hmh_kfn_1s" title="A cluster pipeline is a pipeline that runs in cluster execution mode. You can run a pipeline in standalone execution mode or cluster execution mode.">Cluster Pipelines</a></div>
</div>
</div>
<div class="topic concept nested1" id="concept_xy5_4tm_vs">
 <h2 class="title topictitle2">Kerberos Authentication</h2>

 
 <div class="body conbody"><p class="shortdesc">You can use Kerberos authentication to connect to HDFS. When you use Kerberos
  authentication the <span class="ph">Data
                  Collector</span> uses the
  Kerberos principal and keytab to connect to HDFS.  </p>

  <p class="p">The Kerberos principal and keytab are defined in the
    <span class="ph">Data
                  Collector</span>
   configuration file. To use Kerberos authentication, configure all Kerberos properties in the <span class="ph">Data
                  Collector</span> configuration
   file. </p>

 </div>

 <div class="related-links"><div class="relinfo relconcepts"><strong>Related concepts</strong><br></br>
<div class="related_link"><a class="navheader_parent_path" href="../Install_Config/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to origin and destination systems, as well as YARN clusters.">Enabling Kerberos Authentication</a></div>
</div>
</div>
</div>
<div class="topic concept nested1" id="concept_u4h_lwt_ls">
 <h2 class="title topictitle2">Using an HDFS User</h2>

 
 <div class="body conbody"><p class="shortdesc">You can configure the Hadoop FS origin to use an HDFS user to read data from HDFS. </p>

  <p class="p">By default, the <span class="ph">Data
                  Collector</span> uses the
      user account who started it to connect to external systems. When using Kerberos, the <span class="ph">Data
                  Collector</span> uses the
      Kerberos principal. </p>

  <div class="p">To use an HDFS user to connect to HDFS, perform the following tasks:<ol class="ol" id="concept_u4h_lwt_ls__ul_mb1_xpt_ls">
        <li class="li">On HDFS, configure the <span class="ph">Data
                  Collector</span> user
          as a proxy user and authorize the <span class="ph">Data
                  Collector</span> user
          to impersonate the HDFS user. <p class="p">For more information, see the HDFS documentation.
          </p>
</li>

        <li class="li">In the Hadoop FS origin, enter the HDFS user name.</li>

      </ol>
</div>

 </div>

</div>
<div class="topic concept nested1" id="concept_xh5_y4d_br">
 <h2 class="title topictitle2">HDFS Properties and Configuration Files</h2>

    <div class="body conbody">
        <div class="p">You can configure the Hadoop FS origin to use
            individual HDFS properties or HDFS configuration files:<dl class="dl">
                
                    <dt class="dt dlterm">HDFS configuration files</dt>

                    <dd class="dd">You can use the following HDFS configuration files with the Hadoop FS
                            origin:<ul class="ul" id="concept_xh5_y4d_br__ul_hq2_l4r_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                        <li class="li">yarn-site.xml</li>

                        <li class="li">mapred-site.xml</li>

                  </ul>
</dd>

                    <dd class="dd">To use HDFS configuration files:  <ol class="ol" id="concept_xh5_y4d_br__ol_rb2_2nr_bt">
                            <li class="li">Store the files or a symlink to the files in the <span class="ph">Data
                  Collector</span> resources directory. </li>

                            <li class="li">In the Hadoop FS origin, specify the location of the files. </li>

                        </ol>
</dd>

                
                
                    <dt class="dt dlterm">Individual properties</dt>

                    <dd class="dd">You can configure individual HDFS properties in the origin. To add an HDFS
                        property, you specify the exact property name and the value. The Hadoop FS
                        origin does not validate the property names or values.<div class="note note"><span class="notetitle">Note:</span> Individual
                            properties override properties defined in the HDFS configuration file.
                        </div>
</dd>

                
            </dl>
</div>

    </div>

</div>
<div class="topic concept nested1" id="concept_jx4_zym_vs">
 <h2 class="title topictitle2">Data Formats</h2>

 <div class="body conbody">
  <div class="p">The Hadoop FS origin processes data
   differently based on the data format that you select. The origin processes the following types of
    data:<dl class="dl">
    
     <dt class="dt dlterm">Text</dt>

     <dd class="dd">Generates a record for each line in the file. </dd>

     <dd class="dd">When a line exceeds the maximum line length defined for the origin, Hadoop FS truncates the
      line.</dd>

    
    
     <dt class="dt dlterm">JSON</dt>

     <dd class="dd">Generates a record for each JSON object. You can use JSON files that include multiple JSON
      objects or a single JSON array.</dd>

     <dd class="dd">When an object exceeds the maximum object length defined for the origin, Hadoop FS
      processes the object based on the error handling configured for the origin. </dd>

    
    
     <dt class="dt dlterm">Log</dt>

     <dd class="dd">Generates a record for every log line. </dd>

     <dd class="dd">When a line exceeds the maximum line length defined for the origin, Hadoop FS truncates
      longer lines. </dd>

     <dd class="dd">You can include the processed log line as a field in the record. If the log line is
      truncated, and you request the log line in the record, Hadoop FS includes the truncated
      line.</dd>

     <dd class="dd">You can define the log format or type to be read.</dd>

    
   </dl>
</div>

 </div>

<div class="topic concept nested2" id="concept_tr1_spd_sr">
 <h3 class="title topictitle3">Log Formats</h3>

 
 <div class="body conbody"><p class="shortdesc">When you use an origin to read log data, you define the format of the log files to be
  read. </p>

  <p class="p">You can
   read log files that use the following log formats:</p>

  <div class="p">
   <dl class="dl">
    
     <dt class="dt dlterm">Common Log Format</dt>

     <dd class="dd">A standardized text format used by web servers to generate log files. Also known as the
      NCSA (National Center for Supercomputing Applications) Common Log format.</dd>

    
    
     <dt class="dt dlterm">Combined Log Format</dt>

     <dd class="dd">A standardized text format based on the common log format that includes additional
      information. Also known as the Apache/NCSA Combined Log Format.</dd>

    
    
     <dt class="dt dlterm">Apache Error Log Format</dt>

     <dd class="dd">The standardized error log format generated by the Apache HTTP Server 2.2.</dd>

    
    
     <dt class="dt dlterm">Apache Access Log Custom Format</dt>

     <dd class="dd">A customizable access log generated by the Apache HTTP Server 2.2. Use the Apache HTTP
      Server version 2.2 syntax to define the format of the log file. </dd>

    
    
     <dt class="dt dlterm">Regular Expression</dt>

     <dd class="dd">Use a regular expression to define the structure of log data, and then assign the field or
      fields represented by each group.  </dd>

     <dd class="dd">Use any valid regular expression.</dd>

    
    
     <dt class="dt dlterm">Grok Pattern</dt>

     <dd class="dd">Use a grok pattern to define the structure of log data. You can use the grok patterns
      supported by the <span class="ph">Data
                  Collector</span>. You can
      also define a custom grok pattern and then use it as part of the log format. </dd>

     <dd class="dd">For more information about supported grok patterns, see <a class="xref" href="../Apx-GrokPatterns/GrokPatterns.html#concept_vdk_xjb_wr" title="You can use the grok patterns in this appendix to define the structure of log data. You can use a single pattern or use several patterns to define a larger pattern. You can also use valid sections of patterns to define a custom pattern.">Grok Patterns</a>.</dd>

    
    
     <dt class="dt dlterm">log4j</dt>

     <dd class="dd">A customizable format generated by the Apache Log4j 1.2 logging utility. You can use the
      default format or specify a custom format. Use the Apache Log4j version 1.2 syntax to define
      the format of the log file.</dd>

     <dd class="dd">
      <div class="note note"><span class="notetitle">Note:</span> Unlike other origins that read log data, the Hadoop FS origin does not support log lines
       with stack traces. Log lines with stack traces are treated as error records.</div>

     </dd>

    
   </dl>

  </div>

 </div>

</div>
</div>
<div class="topic task nested1" id="task_hgl_vgn_vs">
    <h2 class="title topictitle2">Configuring a Hadoop FS Origin</h2>

    
    <div class="body taskbody"><p class="shortdesc">Configure a Hadoop FS origin to read data from HDFS.</p>

        <div class="section context"></div>

        <ol class="ol steps" id="task_hgl_vgn_vs__steps_v51_1hn_vs"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__d2911e386" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr class="row">
                                    <th class="entry" valign="top" width="22.22222222222222%" id="d28367e440">General Property</th>

                                    <th class="entry" valign="top" width="77.77777777777779%" id="d28367e443">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d28367e440 ">Name</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d28367e443 ">Stage name.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d28367e440 ">Description</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d28367e443 ">Optional description.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d28367e440 ">On Record Error</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d28367e443 ">Error record handling for the stage: <ul class="ul" id="task_hgl_vgn_vs__d2911e433">
                                            <li class="li">Discard - Discards the record.</li>

                                            <li class="li">Send to Error - Sends the record to the pipeline for
                                                error handling.</li>

                                            <li class="li">Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Hadoop FS</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__table_b55_mkn_vs" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr class="row">
                                    <th class="entry" valign="top" width="27.77777777777778%" id="d28367e515">Hadoop FS Property</th>

                                    <th class="entry" valign="top" width="72.22222222222221%" id="d28367e518">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Hadoop FS URI</td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">HDFS URI. Include the HDFS scheme and authority as
                                        follows:
                                        <samp class="ph codeph">&lt;scheme&gt;://&lt;authority&gt;</samp>.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Directory Path</td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">Directory for the data to be read. Include the HDFS
                                        scheme and authority in the path as follows:
                                            <samp class="ph codeph">&lt;scheme&gt;://&lt;authority&gt;/path</samp>.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Include All Subdirectories</td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">Reads from all directories within the specified directory
                                        path.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Data Format <a class="xref" href="HadoopFS-origin.html#concept_jx4_zym_vs" title="When you use an origin to read log data, you define the format of the log files to be read.">
                                            <img class="image" id="task_hgl_vgn_vs__image_mfn_hwx_5r" src="../Graphics/icon_moreInfo.png" height="12" width="12"></img></a></td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">
                                        <div class="p">Type of data to be read. Use one of the following
                                            options: <ul class="ul" id="task_hgl_vgn_vs__ul_czf_y14_vs">
                                                <li class="li">Text</li>

                                                <li class="li">JSON</li>

                                                <li class="li">Log</li>

                                            </ul>
</div>

                                    </td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Produce Single Record</td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">Generates a single record when a record includes multiple
                                        objects. </td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Kerberos Authentication <a class="xref" href="HadoopFS-origin.html#concept_xy5_4tm_vs" title="You can use Kerberos authentication to connect to HDFS. When you use Kerberos authentication the Data Collector uses the Kerberos principal and keytab to connect to HDFS.">
                                            <img class="image" id="task_hgl_vgn_vs__image_a5x_jzn_vs" src="../Graphics/icon_moreInfo.png" height="12" width="12"></img></a></td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">Uses Kerberos credentials to connect to HDFS. <p class="p">When
                                            selected, uses the Kerberos principal and keytab defined
                                            in the <span class="ph">Data
                  Collector</span> configuration file. </p>
</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Hadoop FS Configuration Directory  <a class="xref" href="HadoopFS-origin.html#concept_xh5_y4d_br">
                                            <img class="image" id="task_hgl_vgn_vs__image_ocv_4qg_xs" src="../Graphics/icon_moreInfo.png" height="12" width="12"></img></a></td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">
                                        <p class="p">Location of the HDFS configuration files. Use a directory
                                            or symlink within the Data Collector resources
                                            directory.</p>

                                        <div class="p">You can use the following files with the Hadoop FS
                                                origin:<ul class="ul" id="task_hgl_vgn_vs__ul_o22_m4r_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                        <li class="li">yarn-site.xml</li>

                        <li class="li">mapred-site.xml</li>

                  </ul>
</div>

                                        <div class="p">
                                            <div class="note note"><span class="notetitle">Note:</span> Properties in the configuration files are
                                                overridden by individual properties defined in the
                                                stage. </div>

                                        </div>

                                    </td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">HDFS User  <a class="xref" href="HadoopFS-origin.html#concept_u4h_lwt_ls" title="You can configure the Hadoop FS origin to use an HDFS user to read data from HDFS.">
                                            <img class="image" id="task_hgl_vgn_vs__image_t3x_4qg_xs" src="../Graphics/icon_moreInfo.png" height="12" width="12"></img></a></td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">The HDFS user to use to connect to HDFS. When using this
                                        property, make sure HDFS is configured appropriately.<p class="p">By
                                            default, the pipeline uses the <span class="ph">Data
                  Collector</span> user to connect to HDFS.</p>
</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="27.77777777777778%" headers="d28367e515 ">Hadoop FS Configuration  <a class="xref" href="HadoopFS-origin.html#concept_xh5_y4d_br">
                                            <img class="image" id="task_hgl_vgn_vs__image_if3_4hl_xs" src="../Graphics/icon_moreInfo.png" height="12" width="12"></img></a></td>

                                    <td class="entry" valign="top" width="72.22222222222221%" headers="d28367e518 ">
                                        <p class="p">Additional Hadoop configuration properties to use. To add
                                            properties, click <span class="ph uicontrol">Add</span> and define
                                            the property name and value. </p>

                                        <p class="p">Use the property names and values as expected by Hadoop.
                                        </p>

                                    </td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
</ol>

    </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </div><div class="footer"><div> </div><!-- Â© <a href="http://creativecommons.org/licenses/by-nc/4.0/legalcode">CC BY-NC 4.0.</a> StreamSets, 2015. --></div>
</body>
</html>