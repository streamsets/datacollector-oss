
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="An origin stage represents the source for the pipeline. You can use a single origin stage in a pipeline. You can use different origins based on the execution mode of the pipeline. In standalone ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="concept"></meta><meta name="DC.Title" content="Origins"></meta><meta name="abstract" content="An origin stage represents the source for the pipeline. You can use a single origin stage in a pipeline."></meta><meta name="description" content="An origin stage represents the source for the pipeline. You can use a single origin stage in a pipeline."></meta><meta name="DC.Relation" scheme="URI" content="../Origins/Origins_title.html"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="concept_hpr_twm_jq"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Origins</title><!--  Generated with Oxygen version 17.1, build number 2016020417.  --><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script><!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
--></head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Origins/Origins_title.html" title="Origins">Origins</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="concept_hpr_twm_jq">
 <h1 class="title topictitle1">Origins</h1>

 
 <div class="body conbody"><p class="shortdesc">An origin stage represents the source for the pipeline. You can use a single origin
    stage in a pipeline.</p>

  <p class="p">You can use different origins
      based on the execution mode of the pipeline. </p>

    <div class="p">In standalone pipelines, you can use the following origins: <ul class="ul" id="concept_hpr_twm_jq__ul_mxz_jxm_jq">
        <li class="li">Amazon S3 - Reads objects from Amazon S3.</li>

        <li class="li">Directory - Reads fully-written files from a directory. </li>

        <li class="li">File Tail - Reads lines of data from an active file after reading related archived files
          in the directory. </li>

        <li class="li">HTTP Client - Reads data from a streaming HTTP resource URL.</li>

        <li class="li">JDBC Consumer - Reads database data through a JDBC connection.</li>

        <li class="li">JMS Consumer - Reads messages from JMS. </li>

        <li class="li">Kafka Consumer - Reads messages from Kafka.</li>

        <li class="li">Kinesis Consumer - Reads data from Kinesis Streams.</li>

        <li class="li">MapR Streams Consumer - Reads messages from MapR Streams.</li>

        <li class="li">MongoDB - Reads documents from MongoDB.</li>

        <li class="li">Omniture - Reads web usage reports from the Omniture reporting API.</li>

        <li class="li">Oracle CDC Client - Reads LogMiner redo logs to generate change data capture
          records.</li>

        <li class="li">RabbitMQ Consumer - Reads messages from RabbitMQ.</li>

        <li class="li">Redis Consumer - Reads messages from Redis.</li>

        <li class="li">SDC RPC - Reads data from an SDC RPC destination in an SDC RPC pipeline.</li>

        <li class="li">SDC RPC to Kafka - Reads data from an SDC RPC destination in an SDC RPC pipeline and
          writes it to Kafka.</li>

        <li class="li">SFTP/FTP Client - Reads files from an SFTP or FTP server.</li>

        <li class="li">UDP Source - Reads messages from one or more UDP ports. </li>

        <li class="li">UDP to Kafka - Reads messages from one or more UDP ports and writes the data to
          Kafka.</li>

      </ul>
</div>

    <div class="p">In cluster pipelines, you can use the following origins:<ul class="ul" id="concept_hpr_twm_jq__ul_unr_xhb_ws">
        <li class="li">Hadoop FS - Reads data from the Hadoop Distributed File System (HDFS). </li>

        <li class="li">Kafka Consumer - Reads messages from Kafka. Use the cluster version of the origin.</li>

      </ul>
</div>

    <div class="p">To help create or test pipelines, you can use the following development origins:<ul class="ul" id="concept_hpr_twm_jq__ul_nr2_c1p_qv">
        <li class="li">Dev Data Generator </li>

        <li class="li">Dev Random Source</li>

        <li class="li">Dev Raw Data Source </li>

      </ul>
</div>

    <p class="p">For more information, see <a class="xref" href="../Pipeline_Design/DevStages.html#concept_czx_ktn_ht">Development Stages</a>.</p>

 </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_ypd_vgr_5q">
 <h2 class="title topictitle2">Batch Size and Wait Time</h2>

 
 <div class="body conbody"><p class="shortdesc">For origin stages, the batch size determines the maximum number of records sent through
        the pipeline at one time. The batch wait time determines the time that the origin waits for
        data before sending a batch. At the end of the wait time, it sends the batch regardless of
        how many records the batch contains. </p>

  <p class="p">For example, a File Tail origin is configured
            for a batch size of 20 records and a batch wait time of 240 seconds. When data arrives
            quickly, File Tail fills a batch with 20 records and sends it through the pipeline
            immediately, creating a new batch and sending it again as soon as it is full. As
            incoming data slows, a remaining batch contains a few records, gaining an extra record
            periodically. 240 seconds after creating the batch, File Tail sends the partially-full
            batch through the pipeline. It immediately creates a new batch and starts a new
            countdown.</p>

  <p class="p">Configure the batch wait time based on your processing needs. You might reduce the batch wait
   time to ensure all data is processed within a specified time frame or to make regular contact
   with pipeline destinations. Use the default or increase the wait time if you prefer not to
   process partial or empty batches.</p>

 </div>

</div>
<div class="topic concept nested1" id="concept_uxr_g52_qs">
 <h2 class="title topictitle2">File Compression Formats</h2>

 
 <div class="body conbody"><p class="shortdesc">Origins that read files can read uncompressed, compressed files, archives, and
    compressed archives. </p>

  <p class="p">Hadoop
      FS reads compressed files automatically. For all other file-based origins, you indicate the
      compression format in the origin. </p>

    <div class="p">The following table lists the supported file types by extension:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_uxr_g52_qs__table_fwr_k3s_b5" class="table" frame="border" border="1" rules="all">
          
          
          <thead class="thead" align="left">
            <tr class="row">
              <th class="entry" valign="top" width="30%" id="d137553e206">Compression Format</th>

              <th class="entry" valign="top" width="70%" id="d137553e209">Description</th>

            </tr>

          </thead>

          <tbody class="tbody">
            <tr class="row">
              <td class="entry" valign="top" width="30%" headers="d137553e206 ">Uncompressed</td>

              <td class="entry" valign="top" width="70%" headers="d137553e209 ">Processes uncompressed files of the configured data format.</td>

            </tr>

            <tr class="row">
              <td class="entry" valign="top" width="30%" headers="d137553e206 ">Compressed</td>

              <td class="entry" valign="top" width="70%" headers="d137553e209 ">Processes files compressed by the following compression formats: <ul class="ul" id="concept_uxr_g52_qs__ul_ctx_3ss_b5">
                  <li class="li">gzip</li>

                  <li class="li">bgzip2</li>

                  <li class="li">xz</li>

                  <li class="li">lzma</li>

                  <li class="li">Pack200</li>

                  <li class="li">DEFLATE</li>

                  <li class="li">Z</li>

                </ul>
</td>

            </tr>

            <tr class="row">
              <td class="entry" valign="top" width="30%" headers="d137553e206 ">Archive</td>

              <td class="entry" valign="top" width="70%" headers="d137553e209 ">Processes files archived by the following archive formats: <ul class="ul" id="concept_uxr_g52_qs__ul_l1q_gsm_c5">
                  <li class="li">7z</li>

                  <li class="li">ar</li>

                  <li class="li">arj</li>

                  <li class="li">cpio</li>

                  <li class="li">dump</li>

                  <li class="li">tar</li>

                  <li class="li">zip</li>

                </ul>
</td>

            </tr>

            <tr class="row">
              <td class="entry" valign="top" width="30%" headers="d137553e206 ">Compressed Archive</td>

              <td class="entry" valign="top" width="70%" headers="d137553e209 ">Processes files in compressed archives created by supported compression and
                archive formats.</td>

            </tr>

          </tbody>

        </table>
</div>
</div>

 </div>

</div>
<div class="topic concept nested1" id="concept_ljn_2h3_yv">
 <h2 class="title topictitle2">Record Header Attributes</h2>

    
 <div class="body conbody"><p class="shortdesc">The Directory, File Tail, and Kafka Consumer origins include record header attributes
        for each record. To track the provenance of each record, you can use a function to include
        this information in the records.</p>

  <p class="p">The following table lists the additional record
            header attributes that each origin includes:</p>

        <div class="p">
            
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_ljn_2h3_yv__table_oww_wpv_jw" class="table" frame="border" border="1" rules="all">
                    
                    
                    <thead class="thead" align="left">
                        <tr class="row">
                            <th class="entry" valign="top" width="33.33333333333333%" id="d137553e362">Origins</th>

                            <th class="entry" valign="top" width="66.66666666666666%" id="d137553e365">Record Header Attributes</th>

                        </tr>

                    </thead>

                    <tbody class="tbody">
                        <tr class="row">
                            <td class="entry" valign="top" width="33.33333333333333%" headers="d137553e362 ">Directory and File Tail</td>

                            <td class="entry" valign="top" width="66.66666666666666%" headers="d137553e365 ">
                                <ul class="ul" id="concept_ljn_2h3_yv__ul_ebj_1l3_yv">
                                    <li class="li">filename - Provides the file name.</li>

                                    <li class="li">file - Provides the file path and name. </li>

                                    <li class="li">offset - Provides the offset in bytes.</li>

                                </ul>

                            </td>

                        </tr>

                        <tr class="row">
                            <td class="entry" valign="top" width="33.33333333333333%" headers="d137553e362 ">Kafka Consumer</td>

                            <td class="entry" valign="top" width="66.66666666666666%" headers="d137553e365 ">
                                <ul class="ul" id="concept_ljn_2h3_yv__ul_i4q_2qv_jw">
                                    <li class="li">offset - Provides the offset in bytes.</li>

                                    <li class="li">partition - Provides the partition name.</li>

                                    <li class="li">topic - Provides the topic name.</li>

                                </ul>

                            </td>

                        </tr>

                    </tbody>

                </table>
</div>

        </div>

        <div class="p">To include these attributes in a record, you can use the following expressions in the
            Expression
            Evaluator:<pre class="pre codeblock">${record:attribute('filename')}
${record:attribute('file')}
${record:attribute('offset')}
${record:attribute('partition')}
${record:attribute('topic')}</pre>
</div>

        <p class="p">The following image shows an Expression Evaluator that adds the file and offset record
            header attribute information to the record read by a Directory origin: </p>

        <p class="p"><img class="image" id="concept_ljn_2h3_yv__image_prx_fn3_yv" src="../Graphics/Origins-EEval-headerattributes.png" height="289" width="588"></img></p>

 </div>

</div>
<div class="topic task nested1" id="task_jp5_ql1_tq">
    <h2 class="title topictitle2">Previewing Raw Source Data</h2>

    
    <div class="body taskbody"><p class="shortdesc">You can preview raw source data for Directory, File Tail, and Kafka Consumer origins.
        Preview raw source data when reviewing the data might help with origin
        configuration.</p>

        <div class="section context">
            <p class="p">When you preview file data, you can
                use the real directory and actual source file. Or when appropriate, you might use a
                different file that is similar to the source. </p>

            <p class="p">When you preview Kafka data, you enter the connection information for the Kafka
                cluster.</p>

            <p class="p">The data used for the raw source preview in an origin stage is not used when
                previewing data for the pipeline.</p>

        </div>

        <ol class="ol steps" id="task_jp5_ql1_tq__steps_k14_k41_tq"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel for the origin stage, click the <span class="keyword wintitle">Raw
                        Preview</span> tab.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For a Directory or File Tail origin, enter a directory and file name.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For a Kafka Consumer, enter the following information:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_jp5_ql1_tq__table_eh1_q2f_xq" class="table" frame="border" border="1" rules="all">
                            
                            
                            <thead class="thead" align="left">
                                <tr class="row">
                                    <th class="entry" valign="top" width="22.22222222222222%" id="d137553e512">Kafka Raw Preview Property</th>

                                    <th class="entry" valign="top" width="77.77777777777779%" id="d137553e515">Description</th>

                                </tr>

                            </thead>

                            <tbody class="tbody">
                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d137553e512 ">Topic</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d137553e515 ">Kafka topic to read.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d137553e512 ">Partition</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d137553e515 ">Partition to read.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d137553e512 ">Broker Host</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d137553e515 ">Broker host name. Use any broker associated with the
                                        partition.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d137553e512 ">Broker Port</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d137553e515 ">Broker port number.</td>

                                </tr>

                                <tr class="row">
                                    <td class="entry" valign="top" width="22.22222222222222%" headers="d137553e512 ">Max Wait Time (secs)</td>

                                    <td class="entry" valign="top" width="77.77777777777779%" headers="d137553e515 ">Maximum amount of time the preview waits to receive data
                                        from Kafka.</td>

                                </tr>

                            </tbody>

                        </table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Click <span class="ph uicontrol">Preview</span>.</span>
            </li>
</ol>

        <div class="section result">The Raw Source Preview area displays the preview.</div>

    </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Origins/Origins_title.html" title="Origins"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Origins</span></a></span>  </div><div class="footer"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>