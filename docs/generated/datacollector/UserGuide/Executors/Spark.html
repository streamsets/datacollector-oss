
<!DOCTYPE html
  PUBLIC "" "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:whc="http://www.oxygenxml.com/webhelp/components" xml:lang="en-us" lang="en-us">
    <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="shortcut icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><link rel="icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><meta name="description" content="The Spark executor starts a Spark application each time it receives an event. You can use the Spark executor with Spark on YARN or Spark on Databricks. The executor is not compatible with Spark on ..." /><meta name="copyright" content="(C) Copyright 2018" /><meta name="DC.rights.owner" content="(C) Copyright 2018" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Spark Executor" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Executors/Executors-title.html" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Executors/Shell.html#concept_jsr_zpw_tz" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/DPM/DPM_title.html" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="DC.Date.Created" content="2014-10-31" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_cvy_vxb_1z" /><title>Spark Executor</title><!--  Generated with Oxygen version 20.0-SNAPSHOT, build number 2018042310.  --><meta name="wh-path2root" content="../../../" /><meta name="wh-toc-id" content="concept_cvy_vxb_1z-d46e97545" />         
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- Latest compiled and minified Bootstrap CSS -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap.min.css" />

        <!-- Bootstrap Optional theme -->
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap-theme.min.css" />
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/jquery-ui/jquery-ui.min.css" />

        <!-- Template default styles  -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/app/topic-page.css?buildId=2018042310" />
        

        <script type="text/javascript" src="../../../oxygen-webhelp/lib/jquery/jquery-3.1.1.min.js"><!----></script>

        <script data-main="../../../oxygen-webhelp/app/topic-page.js" src="../../../oxygen-webhelp/lib/requirejs/require.js"></script>
        
        <!-- Skin resources -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/template/light.css?buildId=2018042310" />
        <!-- EXM-36950 - Expand the args.hdf parameter here -->
        
        
    <link rel="stylesheet" type="text/css" href="../../../skin.css" /></head>

    <body class="wh_topic_page frmBody">
        <!-- EXM-36950 - Expand the args.hdr parameter here -->
        
        
        
<nav class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div class="wh_header_flex_container">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <!--
                            This component will be generated when the next parameters are specified in the transformation scenario:
                            'webhelp.logo.image' and 'webhelp.logo.image.target.url'.
                            See: http://oxygenxml.com/doc/versions/17.1/ug-editor/#topics/dita_webhelp_output.html.
                    -->
                    <a href="../../../index.html" class=" wh_logo hidden-xs "></a>
                    <div class=" wh_publication_title "><a href="../../../index.html"><span class="booktitle">  <span class="ph mainbooktitle"><span class="ph">Data Collector</span> User Guide</span>  </span></a></div>
                    
                </div>
                
                <!-- The menu button for mobile devices is copied in the output only when the 'webhelp.show.top.menu' parameter is set to 'yes' -->
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse">
                
                
                <div class=" wh_indexterms_link "><a href="../../../indexTerms.html" title="Index"><span>Index</span></a></div>
                
            </div>
        </div>
    </div>
</nav>

        <div class=" wh_search_input "><form id="searchForm" method="get" action="../../../search.html"><div><input type="search" placeholder="Search " class="wh_search_textfield" id="textToSearch" name="searchQuery" /><button type="submit" class="wh_search_button"><span>Search</span></button></div><script><!--
                                    $(document).ready(function () {
                                        $('#searchForm').submit(function (e) {
                                            if ($('.wh_search_textfield').val().length < 1) {
                                                e.preventDefault();
                                            }
                                        });
                                    });
                                --></script></form></div>
        
        <div class="container-fluid">
            <div class="row">

                <nav class="wh_tools hidden-print">
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol xmlns:html="http://www.w3.org/1999/xhtml" class="hidden-print"><li><span class="home"><a href="../../../index.html"><span>Home</span></a></span></li>
   <li><span class="topicref" data-id="concept_umc_1lk_fx"><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-title.html">Executors</a></span></span></li>
   <li class="active"><span class="topicref" data-id="concept_cvy_vxb_1z"><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#concept_cvy_vxb_1z">Spark Executor</a></span></span></li>
</ol></div>

                    <div class="wh_right_tools hidden-sm hidden-xs">
                        <div class=" wh_navigation_links "><span id="topic_navigation_links" class="navheader">
  
<span class="navprev"><a class="link" href="../../../datacollector/UserGuide/Executors/Shell.html#concept_jsr_zpw_tz" title="Shell Executor"></a></span>  
<span class="navnext"><a class="link" href="../../../datacollector/UserGuide/DPM/DPM_title.html" title="StreamSets Control Hub"></a></span>  </span></div>
                        <button class="wh_hide_highlight" title="Toggle search highlights"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" title="Collapse sections"></button>
                        <div class=" wh_print_link print "><a href="javascript:window.print();" title="Print this page"></a></div>
                    </div>
                </nav>
            </div>

            <div class="wh_content_area">
                <div class="row">
                    
                        <nav role="navigation" id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-3 hidden-xs navbar hidden-print">
                            <div class=" wh_publication_toc " data-tooltip-position="right"><ul>
   <li><span data-tocid="concept_htw_ghg_jq-d46e54" class="topicref" data-id="concept_htw_ghg_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Getting_Started/GettingStarted_Title.html#concept_htw_ghg_jq">Getting Started</a></span></span></li>
   <li><span data-tocid="concept_hz3_5fk_fy-d46e557" class="topicref" data-id="concept_hz3_5fk_fy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/WhatsNew/WhatsNew_Title.html#concept_hz3_5fk_fy">What's New</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_l4q_flb_kr-d46e4414" class="topicref" data-id="concept_l4q_flb_kr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Installation/Install_title.html">Installation</a></span></span></li>
   <li><span data-tocid="concept_ylh_yyz_ky-d46e6481" class="topicref" data-id="concept_ylh_yyz_ky" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Configuration/Config_title.html">Configuration</a></span></span></li>
   <li><span data-tocid="concept_ejk_f1f_5v-d46e13895" class="topicref" data-id="concept_ejk_f1f_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Upgrade/Upgrade_title.html">Upgrade</a></span></span></li>
   <li><span data-tocid="concept_qsw_cjy_bt-d46e18499" class="topicref" data-id="concept_qsw_cjy_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Design/PipelineDesign_title.html">Pipeline Concepts and Design</a></span></span></li>
   <li><span data-tocid="concept_qn1_wn4_kq-d46e20154" class="topicref" data-id="concept_qn1_wn4_kq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Configuration/PipelineConfiguration_title.html">Pipeline Configuration</a></span></span></li>
   <li><span data-tocid="concept_hdr_gyw_41b-d46e22651" class="topicref" data-id="concept_hdr_gyw_41b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Formats/DataFormats-Title.html">Data Formats</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e24466" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e64169" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Processors/Processors_title.html">Processors</a></span></span></li>
   <li><span data-tocid="concept_agj_cfj_br-d46e77391" class="topicref" data-id="concept_agj_cfj_br" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations-title.html">Destinations</a></span></span></li>
   <li><span data-tocid="concept_umc_1lk_fx-d46e92871" class="topicref" data-id="concept_umc_1lk_fx" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-title.html">Executors</a></span></span><ul class="nav nav-list">
         <li><span data-tocid="concept_stt_2lk_fx-d46e92893" class="topicref" data-id="concept_stt_2lk_fx" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-overview.html#concept_stt_2lk_fx">Executors</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_mvh_bnm_f1b-d46e92917" class="topicref" data-id="concept_mvh_bnm_f1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/AmazonS3.html#concept_mvh_bnm_f1b">Amazon S3 Executor</a></span></span></li>
         <li><span data-tocid="concept_sjs_sfp_qz-d46e93211" class="topicref" data-id="concept_sjs_sfp_qz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Email.html#concept_sjs_sfp_qz">Email Executor</a></span></span></li>
         <li><span data-tocid="concept_wgj_slk_fx-d46e93421" class="topicref" data-id="concept_wgj_slk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/HDFSMetadata.html#concept_wgj_slk_fx">HDFS File Metadata Executor</a></span></span></li>
         <li><span data-tocid="concept_kjw_llk_fx-d46e94647" class="topicref" data-id="concept_kjw_llk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/HiveQuery.html#concept_kjw_llk_fx">Hive Query Executor</a></span></span></li>
         <li><span data-tocid="concept_j3r_gcv_sx-d46e95105" class="topicref" data-id="concept_j3r_gcv_sx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/JDBCQuery.html#concept_j3r_gcv_sx">JDBC Query Executor</a></span></span></li>
         <li><span data-tocid="concept_ohx_r5h_z1b-d46e95201" class="topicref" data-id="concept_ohx_r5h_z1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/MapRFSFileMeta.html#concept_ohx_r5h_z1b">MapR FS File Metadata Executor</a></span></span></li>
         <li><span data-tocid="concept_bj2_zlk_fx-d46e96427" class="topicref" data-id="concept_bj2_zlk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/MapReduce.html#concept_bj2_zlk_fx">MapReduce Executor</a></span></span></li>
         <li><span data-tocid="concept_qzm_l4r_kz-d46e97104" class="topicref" data-id="concept_qzm_l4r_kz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/PipelineFinisher.html#concept_qzm_l4r_kz">Pipeline Finisher Executor</a></span></span></li>
         <li><span data-tocid="concept_jsr_zpw_tz-d46e97314" class="topicref" data-id="concept_jsr_zpw_tz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Shell.html#concept_jsr_zpw_tz">Shell Executor</a></span></span></li>
         <li class="active"><span data-tocid="concept_cvy_vxb_1z-d46e97545" class="topicref" data-id="concept_cvy_vxb_1z" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#concept_cvy_vxb_1z">Spark Executor</a></span></span><ul class="nav nav-list">
               <li><span data-tocid="concept_vbm_ywb_c1b-d46e97698" class="topicref" data-id="concept_vbm_ywb_c1b" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#concept_vbm_ywb_c1b">Spark Versions and Stage Libraries</a></span></span></li>
               <li><span data-tocid="concept_ckt_vcv_jz-d46e97720" class="topicref" data-id="concept_ckt_vcv_jz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#concept_ckt_vcv_jz">Spark on YARN</a></span></span></li>
               <li><span data-tocid="concept_fdc_qrx_jz-d46e98063" class="topicref" data-id="concept_fdc_qrx_jz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#concept_fdc_qrx_jz">Spark on Databricks</a></span></span></li>
               <li><span data-tocid="concept_xmx_1wg_gz-d46e98259" class="topicref" data-id="concept_xmx_1wg_gz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#concept_xmx_1wg_gz">Event Generation</a></span></span></li>
               <li><span data-tocid="concept_ibt_1tx_jz-d46e98495" class="topicref" data-id="concept_ibt_1tx_jz" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#concept_ibt_1tx_jz">Monitoring</a></span></span></li>
               <li><span data-tocid="task_cdw_wxb_1z-d46e98628" class="topicref" data-id="task_cdw_wxb_1z" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Spark.html#task_cdw_wxb_1z">Configuring a Spark Executor</a></span></span></li>
            </ul>
         </li>
      </ul>
   </li>
   <li><span data-tocid="concept_ugp_kwf_xw-d46e98772" class="topicref" data-id="concept_ugp_kwf_xw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM_title.html">StreamSets Control Hub</a></span></span></li>
   <li><span data-tocid="concept_xxd_f5r_kx-d46e102096" class="topicref" data-id="concept_xxd_f5r_kx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Event_Handling/EventFramework-Title.html#concept_xxd_f5r_kx">Dataflow Triggers</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fjj_zcf_2w-d46e106011" class="topicref" data-id="concept_fjj_zcf_2w" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w">Drift Synchronization Solution for Hive</a></span></span></li>
   <li><span data-tocid="concept_kgt_pnr_4cb-d46e108837" class="topicref" data-id="concept_kgt_pnr_4cb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/JDBC_DriftSolution/JDBC_DriftSyncSolution_title.html#concept_kgt_pnr_4cb">Drift Synchronization Solution for PostgreSQL</a></span></span></li>
   <li><span data-tocid="concept_wwq_gxc_py-d46e109636" class="topicref" data-id="concept_wwq_gxc_py" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wwq_gxc_py">Multithreaded Pipelines</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fyf_gkq_4bb-d46e110218" class="topicref" data-id="concept_fyf_gkq_4bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Edge_Mode/EdgePipelines_title.html">Edge Pipelines</a></span></span></li>
   <li><span data-tocid="concept_wr1_ktz_bt-d46e111818" class="topicref" data-id="concept_wr1_ktz_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/RPC_Pipelines/SDC_RPCpipelines_title.html#concept_wr1_ktz_bt">SDC RPC Pipelines</a></span></span></li>
   <li><span data-tocid="concept_fpz_5r4_vs-d46e112299" class="topicref" data-id="concept_fpz_5r4_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Cluster_Mode/ClusterPipelines_title.html">Cluster Pipelines</a></span></span></li>
   <li><span data-tocid="concept_jjk_23z_sq-d46e113641" class="topicref" data-id="concept_jjk_23z_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Preview/DataPreview_Title.html#concept_jjk_23z_sq">Data Preview</a></span></span></li>
   <li><span data-tocid="concept_pgk_brx_rr-d46e114610" class="topicref" data-id="concept_pgk_brx_rr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Alerts/RulesAlerts_title.html#concept_pgk_brx_rr">Rules and Alerts</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_asx_fdz_sq-d46e117238" class="topicref" data-id="concept_asx_fdz_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Monitoring/PipelineMonitoring_title.html#concept_asx_fdz_sq">Pipeline Monitoring</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_o3l_dtr_5q-d46e118495" class="topicref" data-id="concept_o3l_dtr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Maintenance/PipelineMaintenance_title.html#concept_o3l_dtr_5q">Pipeline Maintenance</a></span></span></li>
   <li><span data-tocid="concept_yms_ftm_sq-d46e120286" class="topicref" data-id="concept_yms_ftm_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Administration/Administration_title.html#concept_yms_ftm_sq">Administration</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_nls_w1r_ks-d46e124782" class="topicref" data-id="concept_nls_w1r_ks" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Tutorial/Tutorial-title.html">Tutorial</a></span></span></li>
   <li><span data-tocid="concept_sh3_frm_tq-d46e125996" class="topicref" data-id="concept_sh3_frm_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Troubleshooting/Troubleshooting_title.html#concept_sh3_frm_tq">Troubleshooting</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_xbx_rs1_tq-d46e129904" class="topicref" data-id="concept_xbx_rs1_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Glossary/Glossary_title.html#concept_xbx_rs1_tq">Glossary</a></span></span></li>
   <li><span data-tocid="concept_jn1_nzb_kv-d46e129959" class="topicref" data-id="concept_jn1_nzb_kv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-DataFormats/DataFormat_Title.html#concept_jn1_nzb_kv">Data Formats by Stage</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_pvm_yt3_wq-d46e130119" class="topicref" data-id="concept_pvm_yt3_wq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Expression_Language/ExpressionLanguage_title.html">Expression Language</a></span></span></li>
   <li><span data-tocid="concept_vcj_1ws_js-d46e131600" class="topicref" data-id="concept_vcj_1ws_js" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-RegEx/RegEx-Title.html#concept_vcj_1ws_js">Regular Expressions</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_chv_vmj_wr-d46e131822" class="topicref" data-id="concept_chv_vmj_wr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-GrokPatterns/GrokPatterns_title.html#concept_chv_vmj_wr">Grok Patterns</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
</ul></div>
                        </nav>
                    
                    
                    <div class="col-lg-9 col-md-9 col-sm-9 col-xs-12" id="wh_topic_body">
                        <div class=" wh_topic_content body "><main role="main"><article role="article" aria-labelledby="ariaid-title1"><article class="nested0" aria-labelledby="ariaid-title1" id="concept_cvy_vxb_1z">
 <h1 class="title topictitle1" id="ariaid-title1">Spark Executor</h1>

 <div class="body conbody">
        <p class="p">The
            Spark executor starts a Spark application each time it receives an event. You can use
            the Spark executor with Spark on YARN or Spark on Databricks. The executor is not
            compatible with Spark on Mesos at this time. </p>

        <p class="p">Use the Spark executor to start a Spark application as part of an event stream. <span class="ph">You can use the executor in any logical way, such as running Spark
                        applications after the Hadoop FS, MapR FS, or Amazon S3 destination closes
                        files.</span> For
            example, you might use the executor to start a Spark application that converts Avro
            files to Parquet each time the Hadoop FS destination closes a file. </p>

        <p class="p">Note that the Spark executor starts an application in an external system. It does not
            monitor the application or wait for it to complete. The executor becomes available for
            additional processing as soon as it successfully submits an application. </p>

        <p class="p">When you configure the Spark executor, you specify the cluster manager used with Spark:
            YARN or Databricks. The cluster manager that you select determines the additional
            cluster manager properties, application details, and security options that you can
            configure. </p>

        <p class="p">Regardless of the cluster manager type, you can configure the executor to generate events
            for another event stream. <span class="ph">For more information about dataflow
                        triggers and the event framework, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">Dataflow Triggers Overview</a>.</span></p>

 </div>

<article class="topic concept nested1" aria-labelledby="ariaid-title2" id="concept_vbm_ywb_c1b">
 <h2 class="title topictitle2" id="ariaid-title2">Spark Versions and Stage Libraries</h2>

 <div class="body conbody">
  <p class="p">The Spark executor supports only <span class="ph">Spark version 2.1 or later</span>.</p>

        <p class="p">When you use the Spark executor, make sure the Spark version is the same across all
            related components, as follows:</p>

        <ul class="ul" id="concept_vbm_ywb_c1b__ul_ebs_qxb_c1b">
            <li class="li">When using the executor to run an application on Spark on YARN, make sure <span class="ph">the Spark version used in the selected stage
                        library matches the Spark version used to build the application.</span>
                <p class="p">For example, if you use Spark 2.1 to build the application, use a Spark executor
                    provided in one of the Spark 2.1 stage libraries. </p>
<div class="p">
                    <div class="note note"><span class="notetitle">Note:</span> This requirement does not apply to applications built by Spark on
                        Databricks.</div>

                </div>
</li>

            <li class="li"><p class="p">When using the executor <span class="ph">in a cluster streaming pipeline, the Spark version in
                        the selected stage library must also match the Spark version used by the
                        cluster.</span></p>
<span class="ph">For example, if your cluster uses Spark 2.2, use a
                        stage library that includes Spark 2.2.</span></li>

        </ul>

        <p class="p">The Spark executor is <span class="ph">available in several CDH and MapR stage libraries. To verify the
                        Spark version that a stage library includes, see the CDH or MapR
                        documentation. For more information about the stage libraries that include
                        the Spark Evaluator, see <a class="xref" href="../Installation/AddtionalStageLibs.html#concept_evs_xkm_s5">Available Stage Libraries</a>.</span></p>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title3" id="concept_ckt_vcv_jz">
 <h2 class="title topictitle2" id="ariaid-title3">Spark on YARN</h2>

 <div class="body conbody">
  <p class="p">When using the
            Spark executor with YARN, the executor can run the application in client or cluster
            mode. Run the application in client mode only when resource use is not a concern.</p>

        <p class="p">When you configure the Spark executor, you can specify the number of worker nodes Spark
            should use, or you can enable dynamic allocation and specify the minimum and maximum
            number of worker nodes. Dynamic allocation allows Spark to use additional worker nodes as
            needed, within the specified range.</p>

        <p class="p">You can specify additional cluster manager properties to pass to Spark, such as the
            maximum amount of memory that the application driver and executor can use.</p>

        <p class="p">You can also configure additional Spark arguments and environment variables. Any
            arguments and variables that you enter override any previous definitions, including
            those in the Spark application, elsewhere in the Spark executor, and the <span class="ph">Data Collector</span>
            machine.</p>

        <p class="p">You can specify custom Spark and Java home directories, and a Hadoop proxy user. You can
            also enter Kerberos credentials if needed.</p>

        <p class="p">When you configure the application details, you specify the language used to write the
            application and then define language-specific properties. </p>

        <p class="p">Before you use the Spark executor, make sure to perform the prerequisite task.</p>

 </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title4" id="concept_pyb_gsg_gz">
 <h3 class="title topictitle3" id="ariaid-title4">YARN Prerequisite</h3>

    <div class="body conbody">
        <p class="p">Before you run a Spark executor pipeline that
            starts applications on YARN, you must enable the Spark executor to submit an
            application. </p>

        <div class="p">You can enable the Spark executor to submit an application in several different ways.
            Perform <u class="ph u">one</u> of the following tasks to enable the executor to submit applications: <dl class="dl">
                
                              <dt class="dt dlterm">Configure the YARN Minimum User ID property, min.user.id</dt>

                              <dd class="dd">The min.user.id property is set to 1000 by default. To allow job
                                          submission:<ol class="ol" id="concept_pyb_gsg_gz__d9e5075">
                                          <li class="li">Verify the user ID being used by the <span class="ph">Data Collector</span> user, typically named "sdc".</li>

                                          <li class="li">In Hadoop, configure the YARN min.user.id property.
                                                  <p class="p"> Set the property to equal to or lower than the
                                                  <span class="ph">Data Collector</span> user ID.</p>
</li>

                                    </ol>
</dd>

                        
                
                              <dt class="dt dlterm">Configure the YARN Allowed System Users property,
                                    allowed.system.users</dt>

                              <dd class="dd">The allowed.system.users property lists allowed user names. To
                                    allow job submission: <ol class="ol" id="concept_pyb_gsg_gz__d9e5098">
                                          <li class="li"> In Hadoop, configure the YARN allowed.system.users
                                                property. <p class="p">Add the <span class="ph">Data Collector</span> user name, typically "sdc", to the list of
                                                  allowed users.</p>
</li>

                                    </ol>
</dd>

                        
                
                    <dt class="dt dlterm">Configure the Spark executor Proxy User property</dt>

                    <dd class="dd">In the Spark executor, the Proxy User property allows you to enter a user
                        name for the stage to use when submitting applications. To allow application
                            submission:<ol class="ol" id="concept_pyb_gsg_gz__ol_f3h_f2w_cy">
                            <li class="li">In the Spark executor stage, on the <span class="keyword wintitle">Spark</span> tab,
                                configure the <span class="ph uicontrol">Proxy User</span> property. <p class="p">Enter a
                                    user with an ID that is higher than the min.user.id property, or
                                    with a user name that is listed in the allowed.system.users
                                    property. </p>
</li>

                        </ol>
</dd>

                    <dd class="dd ddexpand">For information about using a Hadoop User, see <a class="xref" href="Spark.html#concept_twh_wsg_gz">Using a Proxy Hadoop User</a>.</dd>

                
            </dl>
</div>

    </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title5" id="concept_aht_p4h_c1b">
 <h3 class="title topictitle3" id="ariaid-title5">Spark Home Requirement</h3>

 <div class="body conbody">
  <p class="p">When running
            an application on YARN, the Spark executor requires access to the spark-submit script
            located in the Spark installation directory. </p>

        <div class="p">By default, the Spark executor uses the directory defined in the SPARK_HOME environment
            variable on the <span class="ph">Data Collector</span>
            machine. The SPARK_HOME environment variable must be set before you start <span class="ph">Data Collector</span>.
                <div class="note note"><span class="notetitle">Note:</span> When Spark 2 is installed on a Cloudera CDH cluster, set the SPARK_HOME
                environment variable for <span class="ph">Data Collector</span>
                as
                follows:<pre class="pre codeblock"><code>export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2</code></pre></div>
</div>

        <p class="p">You can override the environment variable as needed by configuring the Custom Spark Home
            property in the executor stage properties. Use the Custom Spark Home property when the
            SPARK_HOME environment variable is not set, or when it points to a conflicting version
            of Spark. </p>

        <p class="p">For example, if you are using a Spark 2.1 stage library for the Spark executor and
            SPARK_HOME points to an earlier version of Spark, use the Custom Spark Home property to
            specify the location of the Spark 2.1 spark-submit script. </p>

 </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title6" id="concept_lkk_rwx_jz">
 <h3 class="title topictitle3" id="ariaid-title6">Application Properties</h3>

 <div class="body conbody">
  <p class="p">When using the Spark executor with
            YARN, you specify an application name. The application name displays in the cluster
            manager and Spark server logs, so use a distinctive name to enable distinguishing the
            Spark application from others. For example, <span class="ph">SDC_&lt;pipeline name&gt;_&lt;app_type&gt;</span>. </p>

        <p class="p">In the executor, you can enable verbose logging to help test the pipeline and debug the
            application. </p>

        <div class="p">Configure additional application details based on the language used to write the application:<dl class="dl">
                
                    <dt class="dt dlterm">Java or Scala</dt>

                    <dd class="dd">For applications written in Java or Scala, you specify the main class and
                        application resource - the full path to the primary JAR or file.</dd>

                    <dd class="dd ddexpand">You can specify additional arguments and JARs to use. You can also pass
                        additional files to the application using the <code class="ph codeph">--files</code>
                        protocol. </dd>

                
                
                    <dt class="dt dlterm">Python</dt>

                    <dd class="dd">For applications written in Python, you specify the application resource -
                        the full path to the primary Python file - and any required dependencies.
                        You can define application arguments and pass additional files to the
                        application using the <code class="ph codeph">--files</code> protocol. </dd>

                
            </dl>
</div>

        <div class="p">
            <div class="note note"><span class="notetitle">Note:</span> Make sure the user that runs <span class="ph">Data Collector</span> - or the Hadoop proxy user, if configured - has read permission on all required
                paths.</div>

        </div>

 </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title7" id="concept_twh_wsg_gz">
 <h3 class="title topictitle3" id="ariaid-title7">Using a Proxy Hadoop User</h3>

    <div class="body conbody">
        <p class="p">You can configure the Spark executor to use a Hadoop user as
            a proxy user to submit applications to Spark on YARN. </p>

        <p class="p">By default, the <span class="ph">Data Collector</span>
            uses the user account who started it to connect to external systems. When using
            Kerberos, the <span class="ph">Data Collector</span>
            can use the Kerberos principal specified in the executor.</p>

        <div class="p">To use a Hadoop user, perform the following tasks:<ol class="ol" id="concept_twh_wsg_gz__ol_vmj_jtg_gz">
                <li class="li">On the external system, configure the <span class="ph">Data Collector</span> user as a proxy user and authorize the <span class="ph">Data Collector</span> user to impersonate the Hadoop user. <p class="p">For more information, see the Hadoop
                        documentation. </p>
</li>

                <li class="li">In the Spark executor, on the <span class="ph uicontrol">Spark</span> tab, configure the
                        <span class="ph uicontrol">Proxy User</span> property to use the Hadoop user name.</li>

            </ol>
</div>

    </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title8" id="concept_bhk_fhg_gz">
 <h3 class="title topictitle3" id="ariaid-title8">Kerberos Authentication</h3>

    <div class="body conbody">
        <p class="p">You can use Kerberos authentication to
            connect to the destination system where output files are written. To enable this, on the
            Credentials tab of the Spark executor, enter the Kerberos principal and keytab for the
            YARN cluster where the application runs. </p>

    </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title9" id="concept_fdc_qrx_jz">
 <h2 class="title topictitle2" id="ariaid-title9">Spark on Databricks</h2>

 <div class="body conbody">
  <p class="p">When using
            the Spark executor with Databricks, you can run jobs based on notebooks or JARs.</p>

        <p class="p">Before you use the Spark executor, perform the necessary prerequisites. </p>

        <div class="p">When you configure the executor, you specify the cluster base URL, job type, job ID, and
            user credentials. You can optionally configure job parameters and you can use the
            expression language in job parameters. For example, when performing post-processing on
            an Amazon S3 object, you could use the following expression to retrieve the object key
            name from the event record:
            <pre class="pre codeblock"><code><code class="ph codeph">${record:field('/objectKey')}</code></code></pre></div>

        <p class="p">You also can configure an HTTP proxy and SSL/TLS details.</p>

 </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title10" id="concept_esz_x3d_kz">
    <h3 class="title topictitle3" id="ariaid-title10">Databricks Prerequisites</h3>

    <div class="body conbody">
        <div class="p">Before you run a
            Spark executor pipeline that starts jobs on Databricks, perform the following tasks:<ol class="ol" id="concept_esz_x3d_kz__ol_rxc_rld_kz">
                <li class="li">Create the job. <p class="p">The Spark executor can start jobs based on notebooks or
                        JARs.</p>
</li>

                <li class="li"> Optionally configure the job to allow concurrent runs.<p class="p">By default, Databricks
                        does not allow running multiple instances of a job at the same time. With
                        the default, if the Spark executor receives multiple events in quick
                        succession, it starts multiple instances of the job but Databricks queues
                        those instances and runs them one by one. </p>
<p class="p">To enable parallel
                        processing, in Databricks, configure the job to allow concurrent runs. You
                        can configure the maximum number of concurrent runs through the Databricks
                        API with the max_concurrent_runs parameter, or through the UI using the Jobs
                        &gt; Advanced menu and the Maximum Concurrent Runs property.</p>
</li>

                <li class="li">Submit the job and note the job ID.<p class="p">When you submit the job, Databricks
                        generates a job ID. Use the job ID when you configure the Spark
                        executor.</p>
</li>

            </ol>
</div>

    </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title11" id="concept_xmx_1wg_gz">
 <h2 class="title topictitle2" id="ariaid-title11">Event Generation</h2>

    <div class="body conbody">
        <p class="p">The Spark executor can generate events that you
            can use in an event stream. When you enable event generation, the executor generates
            events each time it starts a Spark application. </p>

        <div class="p">Spark executor events can be used in any logical way. For example: <ul class="ul" id="concept_xmx_1wg_gz__ul_dzf_tpg_zx">
                <li class="li">With the Email executor to send a custom email
                              after receiving an event.<p class="p">For an example, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_t2t_lp5_xz">Case Study: Sending Email</a>.</p>
</li>

                <li class="li">With a destination to store event information.
                                    <p class="p">For an example, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_ocb_nnl_px">Case Study: Event Storage</a>.</p>
</li>

            </ul>
</div>

        <p class="p">Since Spark executor events include the application ID for each application that it
            starts, you might generate events to keep a log of the application IDs.</p>

        <p class="p"><span class="ph">For more information about dataflow
                        triggers and the event framework, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">Dataflow Triggers Overview</a>.</span></p>

    </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title12" id="concept_qk2_3wg_gz">
 <h3 class="title topictitle3" id="ariaid-title12">Event Records</h3>

    <div class="body conbody">
        <div class="p">Event records generated
            by the Spark executor have the following event-related record header attributes. Record
            header attributes are stored as String values:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_qk2_3wg_gz__table_smk_gp5_sx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                        <tr>
                            <th class="entry cellrowborder" id="d182358e792">Record Header Attribute</th>

                            <th class="entry cellrowborder" id="d182358e795">Description</th>

                        </tr>

                    </thead>
<tbody class="tbody">
                        <tr>
                            <td class="entry cellrowborder" headers="d182358e792 ">sdc.event.type</td>

                            <td class="entry cellrowborder" headers="d182358e795 ">Event type. Uses one of the following types:<ul class="ul" id="concept_qk2_3wg_gz__ul_tmk_gp5_sx">
                                    <li class="li">AppSubmittedEvent - Generated when the executor starts a
                                        Spark application.</li>

                                </ul>
</td>

                        </tr>

                        <tr>
       <td class="entry cellrowborder" headers="d182358e792 ">sdc.event.version</td>

       <td class="entry cellrowborder" headers="d182358e795 ">An integer that indicates the version of the event record type.</td>

      </tr>

                        <tr>
       <td class="entry cellrowborder" headers="d182358e792 ">sdc.event.creation_timestamp</td>

       <td class="entry cellrowborder" id="concept_qk2_3wg_gz__d196e2243" headers="d182358e795 ">Epoch timestamp when the stage created the event.
       </td>

      </tr>

                    </tbody>
</table>
</div>
</div>

        <div class="p">Event records generated by the Spark executor have the following fields:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_qk2_3wg_gz__table_umk_gp5_sx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                        <tr>
                            <th class="entry cellrowborder" id="d182358e851">Event Field Name</th>

                            <th class="entry cellrowborder" id="d182358e854">Description</th>

                        </tr>

                    </thead>
<tbody class="tbody">
                        <tr>
                            <td class="entry cellrowborder" headers="d182358e851 ">APP_ID</td>

                            <td class="entry cellrowborder" headers="d182358e854 ">Application ID for the Spark application:<ul class="ul" id="concept_qk2_3wg_gz__ul_g53_4wg_gz">
                                    <li class="li">For Databricks, returns the run ID of the job.</li>

                                    <li class="li">For YARN, returns the YARN application ID.</li>

                                </ul>
</td>

                        </tr>

                    </tbody>
</table>
</div>
</div>

    </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title13" id="concept_ibt_1tx_jz">
 <h2 class="title topictitle2" id="ariaid-title13">Monitoring</h2>

 <div class="body conbody">
        <p class="p"><span class="ph">Data Collector</span>
            does not monitor Spark applications. Use your regular cluster monitor application to
            view the status of applications. </p>

        <p class="p">Applications started by the Spark executor display using the application name specified
            in the stage. The application name is the same for all instances of the application. You
            can find the application ID for a particular instance in the <span class="ph">Data Collector</span>
            log.</p>

        <p class="p">The Spark executor also writes the application ID to the event record. To keep a record
            of all application IDs, enable event generation for the stage. </p>

    </div>

</article>
<article class="topic task nested1" aria-labelledby="ariaid-title14" id="task_cdw_wxb_1z">
    <h2 class="title topictitle2" id="ariaid-title14">Configuring a Spark Executor</h2>

    <div class="body taskbody">
        <section class="section context">
            <p class="p">Configure a
                Spark executor to start Spark applications each time the executor receives an event
                record. </p>

        </section>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_yxz_pvs_5x" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e960">General Property</th>

                                    <th class="entry cellrowborder" id="d182358e963">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
       <td class="entry cellrowborder" headers="d182358e960 ">Name</td>

       <td class="entry cellrowborder" headers="d182358e963 ">Stage name.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d182358e960 ">Description</td>

       <td class="entry cellrowborder" headers="d182358e963 ">Optional description.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d182358e960 ">Stage Library</td>

       <td class="entry cellrowborder" headers="d182358e963 ">Library version that you want to use. </td>

      </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e960 ">Produce Events <a class="xref" href="Spark.html#concept_xmx_1wg_gz">
                                            <img class="image" id="task_cdw_wxb_1z__image_qqz_cxs_5x" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d182358e963 ">Generates event records when events occur. Use for event
        handling. <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">
         <img class="image" id="task_cdw_wxb_1z__d196e2111" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d182358e960 ">Required Fields <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_dnj_bkm_vq">
         <img class="image" id="task_cdw_wxb_1z__d196e2120" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d182358e963 ">Fields that must include data for the record to be passed into the stage. <div class="note tip"><span class="tiptitle">Tip:</span> You might include fields that the stage uses.</div>
<p class="p">Records
         that do not include all required fields are processed based on the error handling
         configured for the pipeline.</p>
</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d182358e960 ">Preconditions <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_msl_yd4_fs">
         <img class="image" id="task_cdw_wxb_1z__d196e2137" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d182358e963 ">Conditions that must evaluate to TRUE to allow a record to enter the stage for
        processing. Click <span class="ph uicontrol">Add</span> to create additional preconditions. <p class="p">Records
         that do not meet all preconditions are processed based on the error handling configured for
         the stage.</p>
</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand" id="task_cdw_wxb_1z__step-Sparktab">
                <span class="ph cmd">On the <span class="keyword wintitle">Spark</span> tab, configure the <span class="ph uicontrol">Cluster
                        Manager</span> property.</span>
                <div class="itemgroup info">Then, when using a <span class="ph uicontrol">Databricks</span> cluster manager,
                    configure the following property and continue to the next step.
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_p1f_ytl_gz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1083">Databricks Property</th>

                                    <th class="entry cellrowborder" id="d182358e1086">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1083 ">Cluster Base URL</td>

                                    <td class="entry cellrowborder" headers="d182358e1086 ">The Databricks URL for your company. The URL uses the
                                        following format:
                                        <pre class="pre codeblock"><code>https://&lt;your domain&gt;.cloud.databricks.com</code></pre></td>

                                </tr>

                            </tbody>
</table>
</div>
</div>
                <div class="itemgroup info">Then, when using a <span class="ph uicontrol">YARN</span> cluster manager, configure the
                    following properties:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_f4s_j5l_gz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1124">YARN Property</th>

                                    <th class="entry cellrowborder" id="d182358e1127">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Deploy Mode</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Deploy mode for the application:<ul class="ul" id="task_cdw_wxb_1z__ul_swj_n5l_gz">
                                            <li class="li">Client - Runs the application in Spark client mode.
                                                Use only when resources are not a concern.</li>

                                            <li class="li">Cluster - Runs the application in Spark cluster
                                                mode. Cluster mode deploys the application on the
                                                YARN cluster.</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Driver Memory</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Maximum amount of memory the driver can use for the
                                            application.<p class="p">Enter the number and a standard Java unit
                                            of measure without additional spaces. For example, 10m.
                                            </p>
<p class="p">You can use k or K, m or M, or g or G.
                                        </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Executor Memory</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Maximum amount of memory the executor can use. <p class="p">Enter
                                            the number and a standard Java unit of measure without
                                            additional spaces. For example, 100k. </p>
<p class="p">You can use
                                            k or K, m or M, or g or G. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Dynamic Allocation</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Enables the dynamic allocation of executors to start an
                                        applications.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Number of Worker Nodes</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">The exact number of worker nodes for Spark to use.
                                        Configure when not using dynamic allocation.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Minimum Number of Worker Nodes</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">The minimum number of worker nodes for Spark to use.
                                        Configure when using dynamic allocation.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Maximum Number of Worker Nodes</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">The maximum number of worker nodes for Spark to use.
                                        Configure when using dynamic allocation.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Proxy User <a class="xref" href="Spark.html#concept_twh_wsg_gz">
                                            <img class="image" id="task_cdw_wxb_1z__image_xqm_fjm_zx" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Hadoop user to connect to the external system and run the
                                        application. When using this property, make sure the
                                        external system is configured appropriately. <p class="p">By default,
                                            the pipeline uses the Data Collector user. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Custom Spark Home <a class="xref" href="Spark.html#concept_aht_p4h_c1b">
                                            <img class="image" id="task_cdw_wxb_1z__image_crp_srh_c1b" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Use to enter a custom Spark home directory. By default,
                                        the origin uses the directory specified in the SPARK_HOME
                                        environment variable on the <span class="ph">Data Collector</span> machine. <p class="p">This property overrides the SPARK_HOME
                                            environment variable.</p>
<p class="p">Required if the environment
                                            variable is not set for the <span class="ph">Data Collector</span> machine or if the variable is set for an incorrect
                                            version of Spark.</p>
<p class="p">For example, to run a job
                                            against Spark 2.1, point this property to the Spark 2.1
                                            directory if the SPARK_HOME environment variable points
                                            to an earlier version of Spark.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Custom Java Home</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Use to enter a custom Java home directory. By default,
                                        the origin uses the directory specified in the JAVA_HOME
                                        environment variable on the <span class="ph">Data Collector</span> machine. <p class="p">This property overrides the <span class="ph">Data Collector</span> environment variable.</p>
<p class="p">Required if the
                                            environment variable is not set for the <span class="ph">Data Collector</span> machine.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Additional Spark Arguments</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Additional arguments to pass to Spark. Overrides any
                                        previous configuration for the specified arguments. For a
                                        list of available arguments, see the Spark documentation.
                                    </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Additional Spark Arguments and Values</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Additional arguments with values to pass to Spark.
                                        Overrides any previous configuration for the specified
                                        arguments. For a list of available arguments, see the Spark
                                        documentation.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1124 ">Environment Variables</td>

                                    <td class="entry cellrowborder" headers="d182358e1127 ">Additional environment variables to use. Overrides any
                                        previous configuration for the specified arguments. For a
                                        list of valid environment variables, see the Spark
                                        documentation.</td>

                                </tr>

                            </tbody>
</table>
</div>
</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">When using a Databricks cluster manager, click the
                        <span class="keyword wintitle">Application</span> tab and configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_uvj_jxm_gz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1330">Databricks Application Details Property</th>

                                    <th class="entry cellrowborder" id="d182358e1333">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1330 ">Job Type</td>

                                    <td class="entry cellrowborder" headers="d182358e1333 ">Job type to run: Notebook or JAR.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1330 ">Job ID <a class="xref" href="Spark.html#concept_esz_x3d_kz">
                                            <img class="image" id="task_cdw_wxb_1z__image_tw4_jn2_kz" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d182358e1333 ">Job ID generated by Databricks after the job was
                                        submitted.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1330 ">Parameters</td>

                                    <td class="entry cellrowborder" headers="d182358e1333 ">Parameters to pass to the job. Enter the parameters
                                        exactly as expected, and in the expected order. The executor
                                        does not validate the parameters.<div class="p">You can use the
                                            expression language in job parameters. For example, when
                                            performing post-processing on an Amazon S3 object, you
                                            can use the following expression to retrieve the object
                                            key name from the event record:
                                            <pre class="pre codeblock"><code><code class="ph codeph">${record:field('/objectKey')}</code></code></pre></div>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">When using a YARN cluster manager, click the <span class="keyword wintitle">Application
                        Details</span> tab, select the <span class="ph uicontrol">Language</span> used to
                    write the application, and then configure the following properties:</span>
                <div class="itemgroup info">For applications written in Java or Scala, configure the following
                        properties:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_udj_yyx_jz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1408">Java/Scala Application Properties</th>

                                    <th class="entry cellrowborder" id="d182358e1411">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1408 ">Application Name</td>

                                    <td class="entry cellrowborder" headers="d182358e1411 ">Name to display in YARN resource manager and logs. Also
                                        displays in Spark server history pages.<div class="p">
                  <div class="note tip"><span class="tiptitle">Tip:</span> Use a name that distinguishes the application from those started
                        by other processes and other pipelines, such as <span class="ph" id="task_cdw_wxb_1z__d9e5143">SDC_&lt;pipeline name&gt;_&lt;app_type&gt;</span>.</div>

            </div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1408 ">Application Resource</td>

                                    <td class="entry cellrowborder" headers="d182358e1411 ">The full path to the JAR that contains the main
                                        class.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1408 ">Main Class</td>

                                    <td class="entry cellrowborder" headers="d182358e1411 ">The full path to the main class for the Spark
                                        application. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1408 ">Application Arguments</td>

                                    <td class="entry cellrowborder" headers="d182358e1411 ">You can add additional arguments to pass to the
                                        application. <p class="p">Enter the arguments exactly as expected, and
                                            in the expected order. The executor does not validate
                                            the arguments.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1408 ">Additional JARs</td>

                                    <td class="entry cellrowborder" headers="d182358e1411 ">You can specify additional JARs to use. Enter the full
                                        path to the JAR.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1408 ">Additional Files</td>

                                    <td class="entry cellrowborder" headers="d182358e1411 ">Additional files to pass to the application using the
                                            <code class="ph codeph">--files</code> protocol. Enter the full path
                                        to the files. <p class="p">For information about the protocol, see the
                                            Spark documentation.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1408 ">Enable Verbose Logging</td>

                                    <td class="entry cellrowborder" headers="d182358e1411 ">Enables logging additional information to the <span class="ph">Data Collector</span> log. <p class="p">To avoid filling the log with unnecessary
                                            information, enable this property only when testing the
                                            pipeline. </p>
</td>

                                </tr>

                            </tbody>
</table>
</div>
</div>
                <div class="itemgroup info">For applications written in Python, configure the following
                        properties:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_uzz_qr2_kz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1521">Python Application Properties </th>

                                    <th class="entry cellrowborder" id="d182358e1524">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1521 ">Application Name</td>

                                    <td class="entry cellrowborder" headers="d182358e1524 ">Name to display in YARN resource manager and logs. Also
                                        displays in Spark server history pages.<div class="p">
                  <div class="note tip"><span class="tiptitle">Tip:</span> Use a name that distinguishes the application from those started
                        by other processes and other pipelines, such as <span class="ph" id="task_cdw_wxb_1z__d9e5143">SDC_&lt;pipeline name&gt;_&lt;app_type&gt;</span>.</div>

            </div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1521 ">Application Resource</td>

                                    <td class="entry cellrowborder" headers="d182358e1524 ">The full path to the Python file to run. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1521 ">Application Arguments</td>

                                    <td class="entry cellrowborder" headers="d182358e1524 ">You can add additional arguments to pass to the
                                        application. <p class="p">Enter the arguments exactly as expected, and
                                            in the expected order. The executor does not validate
                                            the arguments.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1521 ">Dependencies</td>

                                    <td class="entry cellrowborder" headers="d182358e1524 ">Full path to any files the Python application resource
                                        requires. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1521 ">Additional Files</td>

                                    <td class="entry cellrowborder" headers="d182358e1524 ">Additional files to pass to the application using the
                                            <code class="ph codeph">--files</code> protocol. Enter the full path
                                        to the files. <p class="p">For information about the protocol, see the
                                            Spark documentation.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1521 ">Enable Verbose Logging</td>

                                    <td class="entry cellrowborder" headers="d182358e1524 ">Enables logging additional information to the <span class="ph">Data Collector</span> log. <p class="p">To avoid filling the log with unnecessary
                                            information, enable this property only when testing the
                                            pipeline. </p>
</td>

                                </tr>

                            </tbody>
</table>
</div>
</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Optionally, click the <span class="keyword wintitle">Credentials</span> tab and configure the
                    following properties:</span>
                <div class="itemgroup info">To enter Databricks credentials, configure the following properties:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_e4n_jyj_kz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1632">Databricks Credentials</th>

                                    <th class="entry cellrowborder" id="d182358e1635">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1632 ">Username</td>

                                    <td class="entry cellrowborder" headers="d182358e1635 ">Databricks user name.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1632 ">Password</td>

                                    <td class="entry cellrowborder" headers="d182358e1635 ">Password for the account.</td>

                                </tr>

                            </tbody>
</table>
</div>
</div>
                <div class="itemgroup info">To use Kerberos authentication to access a destination system from YARN,
                    configure the following properties:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_hxn_syj_kz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1677">YARN Kerberos Properties <a class="xref" href="Spark.html#concept_bhk_fhg_gz">
                                            <img class="image" id="task_cdw_wxb_1z__image_hlh_jzj_kz" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></th>

                                    <th class="entry cellrowborder" id="d182358e1684">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1677 ">Kerberos Principal</td>

                                    <td class="entry cellrowborder" headers="d182358e1684 ">Kerberos principal for the YARN cluster where the
                                        application runs. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1677 ">Kerberos Keytab</td>

                                    <td class="entry cellrowborder" headers="d182358e1684 ">Kerberos keytab for the YARN cluster where the
                                        application runs. </td>

                                </tr>

                            </tbody>
</table>
</div>
</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To use SSL/TLS with Databricks, click the <span class="keyword wintitle">SSL</span> tab and
                    configure the following properties:</span>
                <div class="itemgroup info">
                    <div class="note tip"><span class="tiptitle">Tip:</span> To secure sensitive information such as
                  passwords, you can use <a class="xref" href="../Pipeline_Configuration/RuntimeValues.html#concept_bs4_5nm_2s" title="Similar to runtime properties, runtime resources are values that you define in a file local to the Data Collector and call from within a pipeline. But with runtime resources, you can restrict the permissions for the files to secure sensitive information. Use runtime resources to load sensitive information from files at runtime.">runtime resources</a> or <span class="ph"><a class="xref" href="../Configuration/CredentialStores.html#concept_bt1_bpj_r1b" title="Data Collector pipeline stages communicate with external systems to read and write data. Many of these external systems require credentials - user names or passwords - to access the data. When you configure pipeline stages for these external systems, you define the credentials that the stage uses to connect to the system.">credential stores.</a></span></div>

                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_b5p_p1k_kz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1758">SSL/TLS Property</th>

                                    <th class="entry cellrowborder" id="d182358e1761">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1758 ">Path to Truststore</td>

                                    <td class="entry cellrowborder" headers="d182358e1761 ">Absolute path to the truststore. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1758 ">Password</td>

                                    <td class="entry cellrowborder" headers="d182358e1761 ">Truststore password.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1758 ">Path to Keystore</td>

                                    <td class="entry cellrowborder" headers="d182358e1761 ">Absolute path to the keystore. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1758 ">Password</td>

                                    <td class="entry cellrowborder" headers="d182358e1761 ">Keystore password.</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To use an HTTP proxy, on the <span class="keyword wintitle">Proxy</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_cdw_wxb_1z__table_vy5_dbk_kz" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d182358e1831">HTTP Proxy Property</th>

                                    <th class="entry cellrowborder" id="d182358e1834">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1831 ">Proxy URI</td>

                                    <td class="entry cellrowborder" headers="d182358e1834 ">Proxy URI.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1831 ">Username</td>

                                    <td class="entry cellrowborder" headers="d182358e1834 ">Proxy user name.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d182358e1831 ">Password</td>

                                    <td class="entry cellrowborder" headers="d182358e1834 ">Proxy password.<div class="note tip"><span class="tiptitle">Tip:</span> <span class="ph" id="task_cdw_wxb_1z__d9e4830">To
                        secure sensitive information such as usernames and passwords, you can use
                              <a class="xref" href="../Pipeline_Configuration/RuntimeValues.html#concept_bs4_5nm_2s" title="Similar to runtime properties, runtime resources are values that you define in a file local to the Data Collector and call from within a pipeline. But with runtime resources, you can restrict the permissions for the files to secure sensitive information. Use runtime resources to load sensitive information from files at runtime.">runtime resources</a> or <span class="ph"><a class="xref" href="../Configuration/CredentialStores.html#concept_bt1_bpj_r1b" title="Data Collector pipeline stages communicate with external systems to read and write data. Many of these external systems require credentials - user names or passwords - to access the data. When you configure pipeline stages for these external systems, you define the credentials that the stage uses to connect to the system.">credential stores.</a></span></span></div>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
</ol>

    </div>

</article>
</article>
</article></main></div>
                        
                        
                        
                    </div>
                    
                </div>
            </div>
        </div> <nav class="navbar navbar-default wh_footer">
  <div class=" footer-container text-center ">
    <!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script>
  </div>
</nav>

        
        <div id="go2top">
            <span class="glyphicon glyphicon-chevron-up"></span>
        </div>
        
        <!-- The modal container for images -->
        <div id="modal_img_large" class="modal">
            <span class="close glyphicon glyphicon-remove"></span>
            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="modal-img" />
            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>
        
        <script src="../../../oxygen-webhelp/lib/bootstrap/js/bootstrap.min.js" type="text/javascript"></script>
         Apache License, Version 2.0.
    </body>
</html>