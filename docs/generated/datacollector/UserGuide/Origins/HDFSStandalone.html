
<!DOCTYPE html
  PUBLIC "" "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:whc="http://www.oxygenxml.com/webhelp/components" xml:lang="en-us" lang="en-us">
    <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="shortcut icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><link rel="icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><meta name="description" content="Supported pipeline types: Data Collector The Hadoop FS Standalone origin reads files from HDFS. You can also use the origin to read from Azure Blob storage. The files to be processed must all share a ..." /><meta name="copyright" content="(C) Copyright 2020" /><meta name="DC.rights.owner" content="(C) Copyright 2020" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Hadoop FS Standalone" /><meta name="indexterms" content="data formats, Hadoop FS Standalone origin, Hadoop FS Standalone origin, data formats, Hadoop FS Standalone origin, buffer limit and error handling, buffer limit and error handling, for the Hadoop FS Standalone origin, Hadoop FS Standalone origin, event generation, the event framework, Hadoop FS Standalone origin event generation, Hadoop FS Standalone origin, event records, event records, Hadoop FS Standalone origin, Hadoop FS Standalone origin, record header attributes, file processing, for the Hadoop FS Standalone origin, Hadoop FS Standalone origin, file processing, first file to process, Hadoop FS Standalone origin, file name pattern, for Hadoop FS Standalone origin, Hadoop FS Standalone origin, reading from subdirectories, Hadoop FS Standalone origin, subdirectories in post-processing, Hadoop FS Standalone origin, multithreaded processing, Number of Threads, Hadoop FS Standalone origin, read order, Hadoop FS Standalone origin, Hadoop FS Standalone origin, read order, Hadoop FS Standalone origin, file name pattern and mode, file name pattern and mode, Hadoop FS Standalone origin" /><meta name="DC.subject" content="Hadoop FS Standalone, data formats, Hadoop FS Standalone origin, Hadoop FS Standalone origin, buffer limit and error handling, buffer limit and error handling, for the Hadoop FS Standalone origin, event generation, the event framework, Hadoop FS Standalone origin event generation, event records, event records, record header attributes, file processing, for the Hadoop FS Standalone origin, file processing, first file to process, file name pattern, for Hadoop FS Standalone origin, reading from subdirectories, subdirectories in post-processing, multithreaded processing, Number of Threads, read order, read order, file name pattern and mode, file name pattern and mode, Hadoop FS Standalone origin" /><meta name="keywords" content="Hadoop FS Standalone, data formats, Hadoop FS Standalone origin, Hadoop FS Standalone origin, buffer limit and error handling, buffer limit and error handling, for the Hadoop FS Standalone origin, event generation, the event framework, Hadoop FS Standalone origin event generation, event records, event records, record header attributes, file processing, for the Hadoop FS Standalone origin, file processing, first file to process, file name pattern, for Hadoop FS Standalone origin, reading from subdirectories, subdirectories in post-processing, multithreaded processing, Number of Threads, read order, read order, file name pattern and mode, file name pattern and mode, Hadoop FS Standalone origin" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/Origins_title.html" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_lw2_tnm_vs" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/HTTPClient.html#concept_wk4_bjz_5r" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="version" content="3" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="release" content="16" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="modification" content="0" /><meta name="DC.Date.Created" content="2014-10-31" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_djz_pdm_hdb" /><title>Hadoop FS Standalone</title><!--  Generated with Oxygen version 20.0-SNAPSHOT, build number 2018042310.  --><meta name="wh-path2root" content="../../../" /><meta name="wh-toc-id" content="concept_djz_pdm_hdb-d46e56489" />         
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- Latest compiled and minified Bootstrap CSS -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap.min.css" />

        <!-- Bootstrap Optional theme -->
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap-theme.min.css" />
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/jquery-ui/jquery-ui.min.css" />

        <!-- Template default styles  -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/app/topic-page.css?buildId=2018042310" />
        

        <script type="text/javascript" src="../../../oxygen-webhelp/lib/jquery/jquery-3.1.1.min.js"><!----></script>

        <script data-main="../../../oxygen-webhelp/app/topic-page.js" src="../../../oxygen-webhelp/lib/requirejs/require.js"></script>
        
        <!-- Skin resources -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/template/light.css?buildId=2018042310" />
        <!-- EXM-36950 - Expand the args.hdf parameter here -->
        
        
    <link rel="stylesheet" type="text/css" href="../../../skin.css" /></head>

    <body class="wh_topic_page frmBody">
        <!-- EXM-36950 - Expand the args.hdr parameter here -->
        
        
        
<nav class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div class="wh_header_flex_container">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <!--
                            This component will be generated when the next parameters are specified in the transformation scenario:
                            'webhelp.logo.image' and 'webhelp.logo.image.target.url'.
                            See: http://oxygenxml.com/doc/versions/17.1/ug-editor/#topics/dita_webhelp_output.html.
                    -->
                    <a href="http://streamsets.com" class=" wh_logo hidden-xs "></a>
                    <div class=" wh_publication_title "><a href="../../../index.html"><span class="booktitle">  <span class="ph mainbooktitle"><span class="ph">Data Collector</span> User Guide</span>  </span></a></div>
                    
                </div>
                
                <!-- The menu button for mobile devices is copied in the output only when the 'webhelp.show.top.menu' parameter is set to 'yes' -->
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse">
                
                
                <div class=" wh_indexterms_link "><a href="../../../indexTerms.html" title="Index"><span>Index</span></a></div>
                
            </div>
        </div>
    </div>
</nav>

        <div class=" wh_search_input "><form id="searchForm" method="get" action="../../../search.html"><div><input type="search" placeholder="Search " class="wh_search_textfield" id="textToSearch" name="searchQuery" /><button type="submit" class="wh_search_button"><span>Search</span></button></div><script><!--
                                    $(document).ready(function () {
                                        $('#searchForm').submit(function (e) {
                                            if ($('.wh_search_textfield').val().length < 1) {
                                                e.preventDefault();
                                            }
                                        });
                                    });
                                --></script></form></div>
        
        <div class="container-fluid">
            <div class="row">

                <nav class="wh_tools hidden-print">
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol xmlns:html="http://www.w3.org/1999/xhtml" class="hidden-print"><li><span class="home"><a href="../../../index.html"><span>Home</span></a></span></li>
   <li><span class="topicref" data-id="concept_yjl_nc5_jq"><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span></li>
   <li class="active"><span class="topicref" data-id="concept_djz_pdm_hdb"><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_djz_pdm_hdb">Hadoop FS Standalone</a></span></span></li>
</ol></div>

                    <div class="wh_right_tools hidden-sm hidden-xs">
                        <div class=" wh_navigation_links "><span id="topic_navigation_links" class="navheader">
  
<span class="navprev"><a class="link" href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_lw2_tnm_vs" title="Hadoop FS"></a></span>  
<span class="navnext"><a class="link" href="../../../datacollector/UserGuide/Origins/HTTPClient.html#concept_wk4_bjz_5r" title="HTTP Client"></a></span>  </span></div>
                        <button class="wh_hide_highlight" title="Toggle search highlights"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" title="Collapse sections"></button>
                        <div class=" wh_print_link print "><a href="javascript:window.print();" title="Print this page"></a></div>
                    </div>
                </nav>
            </div>

            <div class="wh_content_area">
                <div class="row">
                    
                        <nav role="navigation" id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-3 hidden-xs navbar hidden-print">
                            <div class=" wh_publication_toc " data-tooltip-position="right"><ul>
   <li><span data-tocid="concept_htw_ghg_jq-d46e53" class="topicref" data-id="concept_htw_ghg_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Getting_Started/GettingStarted_Title.html#concept_htw_ghg_jq">Getting Started</a></span></span></li>
   <li><span data-tocid="concept_hz3_5fk_fy-d46e1069" class="topicref" data-id="concept_hz3_5fk_fy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/WhatsNew/WhatsNew_Title.html#concept_hz3_5fk_fy">What's New</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_l4q_flb_kr-d46e12090" class="topicref" data-id="concept_l4q_flb_kr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Installation/Install_title.html">Installation</a></span></span></li>
   <li><span data-tocid="concept_ylh_yyz_ky-d46e14866" class="topicref" data-id="concept_ylh_yyz_ky" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Configuration/Config_title.html">Configuration</a></span></span></li>
   <li><span data-tocid="concept_ejk_f1f_5v-d46e25044" class="topicref" data-id="concept_ejk_f1f_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Upgrade/Upgrade_title.html">Upgrade</a></span></span></li>
   <li><span data-tocid="concept_qsw_cjy_bt-d46e33436" class="topicref" data-id="concept_qsw_cjy_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Design/PipelineDesign_title.html">Pipeline Concepts and Design</a></span></span></li>
   <li><span data-tocid="concept_qn1_wn4_kq-d46e35308" class="topicref" data-id="concept_qn1_wn4_kq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Configuration/PipelineConfiguration_title.html">Pipeline Configuration</a></span></span></li>
   <li><span data-tocid="concept_hdr_gyw_41b-d46e39288" class="topicref" data-id="concept_hdr_gyw_41b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Formats/DataFormats-Title.html">Data Formats</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e41548" class="topicref" data-id="concept_yjl_nc5_jq" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span><ul class="nav nav-list">
         <li><span data-tocid="concept_hpr_twm_jq-d46e41570" class="topicref" data-id="concept_hpr_twm_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_overview.html#concept_hpr_twm_jq">Origins</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">An origin stage represents the source for the pipeline. You can use a single origin     stage in a pipeline.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kvs_3hh_ht-d46e42034" class="topicref" data-id="concept_kvs_3hh_ht" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AmazonS3.html#concept_kvs_3hh_ht">Amazon S3</a></span></span></li>
         <li><span data-tocid="concept_xsh_knm_5bb-d46e43113" class="topicref" data-id="concept_xsh_knm_5bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AmazonSQS.html#concept_xsh_knm_5bb">Amazon SQS Consumer</a></span></span></li>
         <li><span data-tocid="concept_osx_qgz_xhb-d46e43571" class="topicref" data-id="concept_osx_qgz_xhb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/ADLS-G1.html#concept_osx_qgz_xhb">Azure Data Lake Storage Gen1</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_osx_qgz_xhb-d46e46353" class="topicref" data-id="concept_osx_qgz_xhb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/ADLS-G2.html#concept_osx_qgz_xhb">Azure Data Lake Storage Gen2</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_c1z_15q_1bb-d46e49135" class="topicref" data-id="concept_c1z_15q_1bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AzureEventHub.html#concept_c1z_15q_1bb">Azure IoT/Event Hub Consumer</a></span></span></li>
         <li><span data-tocid="concept_wfy_ghn_sz-d46e49417" class="topicref" data-id="concept_wfy_ghn_sz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/CoAPServer.html#concept_wfy_ghn_sz">CoAP Server</a></span></span></li>
         <li><span data-tocid="concept_nsz_mnr_2jb-d46e49708" class="topicref" data-id="concept_nsz_mnr_2jb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/CronScheduler.html#concept_nsz_mnr_2jb">Cron Scheduler</a></span></span></li>
         <li><span data-tocid="concept_qcq_54n_jq-d46e49858" class="topicref" data-id="concept_qcq_54n_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Directory.html#concept_qcq_54n_jq">Directory</a></span></span></li>
         <li><span data-tocid="concept_f1q_vpm_2z-d46e51246" class="topicref" data-id="concept_f1q_vpm_2z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Elasticsearch.html#concept_f1q_vpm_2z">Elasticsearch </a></span></span></li>
         <li><span data-tocid="concept_n1y_qyp_5q-d46e51722" class="topicref" data-id="concept_n1y_qyp_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/FileTail.html#concept_n1y_qyp_5q">File Tail</a></span></span></li>
         <li><span data-tocid="concept_cg3_y3v_q1b-d46e52968" class="topicref" data-id="concept_cg3_y3v_q1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/BigQuery.html#concept_cg3_y3v_q1b">Google BigQuery</a></span></span></li>
         <li><span data-tocid="concept_iyd_wql_nbb-d46e53652" class="topicref" data-id="concept_iyd_wql_nbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/GCS.html#concept_iyd_wql_nbb">Google Cloud Storage</a></span></span></li>
         <li><span data-tocid="concept_pjw_qtl_r1b-d46e54328" class="topicref" data-id="concept_pjw_qtl_r1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PubSub.html#concept_pjw_qtl_r1b">Google Pub/Sub Subscriber</a></span></span></li>
         <li><span data-tocid="concept_chr_zjj_l3b-d46e54897" class="topicref" data-id="concept_chr_zjj_l3b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/GroovyScripting.html#concept_chr_zjj_l3b">Groovy Scripting</a></span></span></li>
         <li><span data-tocid="concept_yp1_4zs_yfb-d46e55697" class="topicref" data-id="concept_yp1_4zs_yfb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/gRPCClient.html#concept_yp1_4zs_yfb">gRPC Client</a></span></span></li>
         <li><span data-tocid="concept_lw2_tnm_vs-d46e55913" class="topicref" data-id="concept_lw2_tnm_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_lw2_tnm_vs">Hadoop FS </a></span></span></li>
         <li class="active"><span data-tocid="concept_djz_pdm_hdb-d46e56489" class="topicref" data-id="concept_djz_pdm_hdb" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_djz_pdm_hdb">Hadoop FS Standalone</a></span></span><ul class="nav nav-list">
               <li><span data-tocid="concept_wcp_zxk_1hb-d46e56843" class="topicref" data-id="concept_wcp_zxk_1hb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_wcp_zxk_1hb">File Directory</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                           </span></span></span></li>
               <li><span data-tocid="concept_exc_22h_ldb-d46e56867" class="topicref" data-id="concept_exc_22h_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_exc_22h_ldb">File Name Pattern and Mode</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">Use a file name pattern to define the files that the <span class="ph">Hadoop FS Standalone</span> origin         processes. <span class="ph">You can use either a glob pattern or a regular expression to define                 the file name pattern. </span></p>
                           </span></span></span></li>
               <li><span data-tocid="concept_ogz_q3h_ldb-d46e56919" class="topicref" data-id="concept_ogz_q3h_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_ogz_q3h_ldb">Read Order</a></span></span></li>
               <li><span data-tocid="concept_fgx_1jh_ldb-d46e56987" class="topicref" data-id="concept_fgx_1jh_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_fgx_1jh_ldb">Multithreaded Processing</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The <span class="ph">Hadoop FS Standalone</span> origin uses multiple concurrent threads to process data         based on the Number of Threads property. 
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_bwq_nyj_mdb-d46e57086" class="topicref" data-id="concept_bwq_nyj_mdb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_bwq_nyj_mdb">Reading from Subdirectories</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">When using the Last Modified Timestamp read order, the <span class="ph">Hadoop FS Standalone</span>         origin can read files in subdirectories of the specified file directory. 
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_a2q_4kh_ldb-d46e57338" class="topicref" data-id="concept_a2q_4kh_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_a2q_4kh_ldb">First File for Processing</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">Configure a first file for processing when you want the <span class="ph">Hadoop FS Standalone</span>         origin to ignore one or more existing files in the directory.
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="task_nbb_425_vjb-d46e57509" class="topicref" data-id="task_nbb_425_vjb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#task_nbb_425_vjb">Reading from Azure Blob Storage</a></span></span></li>
               <li><span data-tocid="concept_vfk_yrv_ldb-d46e57684" class="topicref" data-id="concept_vfk_yrv_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_vfk_yrv_ldb">Reading from Azure Blob Storage with Azure HDInsight</a></span></span></li>
               <li><span data-tocid="concept_asp_lfh_ldb-d46e57869" class="topicref" data-id="concept_asp_lfh_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_asp_lfh_ldb">Record Header Attributes</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">creates record header                 attributes that include <span class="ph">information about the originating file for                     the record</span>.</span>     
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_zlx_5rh_ldb-d46e58085" class="topicref" data-id="concept_zlx_5rh_ldb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_zlx_5rh_ldb">Event Generation</a></span></span></li>
               <li><span data-tocid="concept_jbn_md3_ldb-d46e58566" class="topicref" data-id="concept_jbn_md3_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_jbn_md3_ldb">Buffer Limit and Error Handling</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">passes each record to a buffer. The size of the buffer determines                 the maximum size of the record that can
                                 be processed. Decrease the buffer limit when                 memory on the <span class="ph">Data Collector</span>                 machine is limited. Increase the buffer limit to process larger records when memory                 is available.</span></p>
                           </span></span></span></li>
               <li><span data-tocid="concept_vvd_4zp_ldb-d46e58853" class="topicref" data-id="concept_vvd_4zp_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_vvd_4zp_ldb">Kerberos Authentication</a></span></span></li>
               <li><span data-tocid="concept_zx5_yzp_ldb-d46e59139" class="topicref" data-id="concept_zx5_yzp_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_zx5_yzp_ldb">HDFS Properties and Configuration Files</a></span></span></li>
               <li><span data-tocid="concept_ub1_zwp_ldb-d46e59435" class="topicref" data-id="concept_ub1_zwp_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_ub1_zwp_ldb">Impersonation User</a></span></span></li>
               <li><span data-tocid="concept_vym_zd3_ldb-d46e59741" class="topicref" data-id="concept_vym_zd3_ldb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_vym_zd3_ldb">Data Formats</a></span></span></li>
               <li><span data-tocid="task_l3t_sdm_hdb-d46e60069" class="topicref" data-id="task_l3t_sdm_hdb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#task_l3t_sdm_hdb">Configuring a Hadoop FS Standalone Origin</a></span></span></li>
            </ul>
         </li>
         <li><span data-tocid="concept_wk4_bjz_5r-d46e60415" class="topicref" data-id="concept_wk4_bjz_5r" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPClient.html#concept_wk4_bjz_5r">HTTP Client</a></span></span></li>
         <li><span data-tocid="concept_s2p_5hb_4y-d46e63027" class="topicref" data-id="concept_s2p_5hb_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPServer.html#concept_s2p_5hb_4y">HTTP Server</a></span></span></li>
         <li><span data-tocid="concept_izh_mqd_dy-d46e63491" class="topicref" data-id="concept_izh_mqd_dy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPtoKafka.html#concept_izh_mqd_dy">HTTP to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_kn5_bvt_m3b-d46e63774" class="topicref" data-id="concept_kn5_bvt_m3b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JavaScriptScripting.html#concept_kn5_bvt_m3b">JavaScript Scripting</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_zp3_wnw_4y-d46e64455" class="topicref" data-id="concept_zp3_wnw_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MultiTableJDBCConsumer.html#concept_zp3_wnw_4y">JDBC Multitable Consumer</a></span></span></li>
         <li><span data-tocid="concept_qhf_hjr_bs-d46e70534" class="topicref" data-id="concept_qhf_hjr_bs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JDBCConsumer.html#concept_qhf_hjr_bs">JDBC Query Consumer</a></span></span></li>
         <li><span data-tocid="concept_rhh_4nj_dt-d46e73876" class="topicref" data-id="concept_rhh_4nj_dt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JMS.html#concept_rhh_4nj_dt">JMS Consumer</a></span></span></li>
         <li><span data-tocid="concept_fxz_35t_m3b-d46e74244" class="topicref" data-id="concept_fxz_35t_m3b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JythonScripting.html#concept_fxz_35t_m3b">Jython Scripting</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_msz_wnr_5q-d46e75049" class="topicref" data-id="concept_msz_wnr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KConsumer.html#concept_msz_wnr_5q">Kafka Consumer</a></span></span></li>
         <li><span data-tocid="concept_ccs_fn4_x1b-d46e75424" class="topicref" data-id="concept_ccs_fn4_x1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_ccs_fn4_x1b">Kafka Multitopic Consumer</a></span></span></li>
         <li><span data-tocid="concept_anh_4y3_yr-d46e75888" class="topicref" data-id="concept_anh_4y3_yr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KinConsumer.html#concept_anh_4y3_yr">Kinesis Consumer</a></span></span></li>
         <li><span data-tocid="concept_qwj_5vm_pbb-d46e76456" class="topicref" data-id="concept_qwj_5vm_pbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRdbCDC.html#concept_qwj_5vm_pbb">MapR DB CDC</a></span></span></li>
         <li><span data-tocid="concept_ywh_k15_3y-d46e76738" class="topicref" data-id="concept_ywh_k15_3y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRDBJSON.html#concept_ywh_k15_3y">MapR DB JSON</a></span></span></li>
         <li><span data-tocid="concept_psz_db4_lx-d46e76837" class="topicref" data-id="concept_psz_db4_lx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRFS.html#concept_psz_db4_lx">MapR FS</a></span></span></li>
         <li><span data-tocid="concept_b43_3qc_mdb-d46e77221" class="topicref" data-id="concept_b43_3qc_mdb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRFSStandalone.html#concept_b43_3qc_mdb">MapR FS Standalone</a></span></span></li>
         <li><span data-tocid="concept_hvd_hww_lbb-d46e78830" class="topicref" data-id="concept_hvd_hww_lbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRStreamsMultiConsumer.html#concept_hvd_hww_lbb">MapR Multitopic Streams Consumer</a></span></span></li>
         <li><span data-tocid="concept_cvy_xsf_2v-d46e79291" class="topicref" data-id="concept_cvy_xsf_2v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRStreamsCons.html#concept_cvy_xsf_2v">MapR Streams Consumer</a></span></span></li>
         <li><span data-tocid="concept_bk4_2rs_ns-d46e79579" class="topicref" data-id="concept_bk4_2rs_ns" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MongoDB.html#concept_bk4_2rs_ns">MongoDB</a></span></span></li>
         <li><span data-tocid="concept_mjn_yqw_4y-d46e80256" class="topicref" data-id="concept_mjn_yqw_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MongoDBOplog.html#concept_mjn_yqw_4y">MongoDB Oplog</a></span></span></li>
         <li><span data-tocid="concept_ukz_3vt_lz-d46e80714" class="topicref" data-id="concept_ukz_3vt_lz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MQTTSubscriber.html#concept_ukz_3vt_lz">MQTT Subscriber</a></span></span></li>
         <li><span data-tocid="concept_kqg_1yh_xx-d46e80999" class="topicref" data-id="concept_kqg_1yh_xx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MySQLBinaryLog.html#concept_kqg_1yh_xx">MySQL Binary Log</a></span></span></li>
         <li><span data-tocid="concept_ynn_vdb_p3b-d46e81569" class="topicref" data-id="concept_ynn_vdb_p3b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/NiFi.html#concept_ynn_vdb_p3b">NiFi HTTP Server</a></span></span></li>
         <li><span data-tocid="concept_dsr_xmw_1s-d46e81625" class="topicref" data-id="concept_dsr_xmw_1s" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Omniture.html#concept_dsr_xmw_1s">Omniture</a></span></span></li>
         <li><span data-tocid="concept_nmf_1ly_f1b-d46e81679" class="topicref" data-id="concept_nmf_1ly_f1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/OPCUAClient.html#concept_nmf_1ly_f1b">OPC UA Client </a></span></span></li>
         <li><span data-tocid="concept_lnz_kzp_zgb-d46e81891" class="topicref" data-id="concept_lnz_kzp_zgb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/OracleBulk.html#concept_lnz_kzp_zgb">Oracle Bulkload</a></span></span></li>
         <li><span data-tocid="concept_rs5_hjj_tw-d46e83302" class="topicref" data-id="concept_rs5_hjj_tw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/OracleCDC.html#concept_rs5_hjj_tw">Oracle CDC Client</a></span></span></li>
         <li><span data-tocid="concept_cfs_4m4_n2b-d46e88043" class="topicref" data-id="concept_cfs_4m4_n2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PostgreSQL.html#concept_cfs_4m4_n2b">PostgreSQL CDC Client</a></span></span></li>
         <li><span data-tocid="concept_o2b_1pc_r2b-d46e88506" class="topicref" data-id="concept_o2b_1pc_r2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PulsarConsumer.html#concept_o2b_1pc_r2b">Pulsar Consumer</a></span></span></li>
         <li><span data-tocid="concept_dyg_lq1_h5-d46e88980" class="topicref" data-id="concept_dyg_lq1_h5" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/RabbitMQ.html#concept_dyg_lq1_h5">RabbitMQ Consumer</a></span></span></li>
         <li><span data-tocid="concept_plr_t3v_jw-d46e89193" class="topicref" data-id="concept_plr_t3v_jw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Redis.html#concept_plr_t3v_jw">Redis Consumer</a></span></span></li>
         <li><span data-tocid="concept_hfg_2sn_p2b-d46e89344" class="topicref" data-id="concept_hfg_2sn_p2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/RESTService.html#concept_hfg_2sn_p2b">REST Service </a></span></span></li>
         <li><span data-tocid="concept_odf_vr3_rx-d46e90752" class="topicref" data-id="concept_odf_vr3_rx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Salesforce.html#concept_odf_vr3_rx">Salesforce</a></span></span></li>
         <li><span data-tocid="concept_pmt_ml3_3mb-d46e93830" class="topicref" data-id="concept_pmt_ml3_3mb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SAPHana.html#concept_pmt_ml3_3mb">SAP HANA Query Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_agb_5c1_ct-d46e95247" class="topicref" data-id="concept_agb_5c1_ct" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SDC_RPCorigin.html#concept_agb_5c1_ct">SDC RPC </a></span></span></li>
         <li><span data-tocid="concept_tdk_slk_pw-d46e95301" class="topicref" data-id="concept_tdk_slk_pw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SDCRPCtoKafka.html#concept_tdk_slk_pw">SDC RPC to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_ic5_bzd_5v-d46e95672" class="topicref" data-id="concept_ic5_bzd_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SFTP.html#concept_ic5_bzd_5v">SFTP/FTP/FTPS Client</a></span></span></li>
         <li><span data-tocid="SQLServerBDCMultitable-d46e96477" class="topicref" data-id="SQLServerBDCMultitable" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SQLServerBDCMultitable.html#SQLServerBDCMultitable">SQL Server 2019 BDC Multitable Consumer</a></span></span></li>
         <li><span data-tocid="concept_ut3_ywc_v1b-d46e101293" class="topicref" data-id="concept_ut3_ywc_v1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SQLServerCDC.html#concept_ut3_ywc_v1b">SQL Server CDC Client</a></span></span></li>
         <li><span data-tocid="concept_ewq_b2s_r1b-d46e103046" class="topicref" data-id="concept_ewq_b2s_r1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SQLServerChange.html#concept_ewq_b2s_r1b">SQL Server Change Tracking</a></span></span></li>
         <li><span data-tocid="concept_ufc_53w_wlb-d46e104613" class="topicref" data-id="concept_ufc_53w_wlb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/StartJob.html#concept_ufc_53w_wlb">Start Jobs</a></span></span></li>
         <li><span data-tocid="concept_h1l_xpr_2jb-d46e104903" class="topicref" data-id="concept_h1l_xpr_2jb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/StartPipe.html#concept_h1l_xpr_2jb">Start Pipelines</a></span></span></li>
         <li><span data-tocid="concept_gzy_gmv_32b-d46e105057" class="topicref" data-id="concept_gzy_gmv_32b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SystemMetrics.html#concept_gzy_gmv_32b">System Metrics</a></span></span></li>
         <li><span data-tocid="concept_ppm_xb1_4z-d46e105211" class="topicref" data-id="concept_ppm_xb1_4z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/TCPServer.html#concept_ppm_xb1_4z">TCP Server</a></span></span></li>
         <li><span data-tocid="concept_zp3_wnw_4y-d46e105669" class="topicref" data-id="concept_zp3_wnw_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Teradata.html#concept_zp3_wnw_4y">Teradata Consumer</a></span></span></li>
         <li><span data-tocid="concept_wng_g5f_5bb-d46e110484" class="topicref" data-id="concept_wng_g5f_5bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDPMulti.html#concept_wng_g5f_5bb">UDP Multithreaded Source</a></span></span></li>
         <li><span data-tocid="concept_rst_2y5_1s-d46e110849" class="topicref" data-id="concept_rst_2y5_1s" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDP.html#concept_rst_2y5_1s">UDP Source</a></span></span></li>
         <li><span data-tocid="concept_jzq_jcz_pw-d46e110997" class="topicref" data-id="concept_jzq_jcz_pw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDPtoKafka.html#concept_jzq_jcz_pw">UDP to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_unk_nzk_fbb-d46e111211" class="topicref" data-id="concept_unk_nzk_fbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WebSocketClient.html#concept_unk_nzk_fbb">WebSocket Client</a></span></span></li>
         <li><span data-tocid="concept_u2r_gpc_3z-d46e111445" class="topicref" data-id="concept_u2r_gpc_3z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WebSocketServer.html#concept_u2r_gpc_3z">WebSocket Server</a></span></span></li>
         <li><span data-tocid="concept_agf_5jv_sbb-d46e111934" class="topicref" data-id="concept_agf_5jv_sbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WindowsLog.html#concept_agf_5jv_sbb">Windows Event Log</a></span></span></li>
      </ul>
   </li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e112031" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Processors/Processors_title.html">Processors</a></span></span></li>
   <li><span data-tocid="concept_agj_cfj_br-d46e132720" class="topicref" data-id="concept_agj_cfj_br" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations-title.html">Destinations</a></span></span></li>
   <li><span data-tocid="concept_umc_1lk_fx-d46e161471" class="topicref" data-id="concept_umc_1lk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-title.html">Executors</a></span></span></li>
   <li><span data-tocid="concept_fyf_gkq_4bb-d46e171123" class="topicref" data-id="concept_fyf_gkq_4bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Edge_Mode/EdgePipelines_title.html"><span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">StreamSets Data Collector Edge</span></a></span></span></li>
   <li><span data-tocid="concept_ugp_kwf_xw-d46e173726" class="topicref" data-id="concept_ugp_kwf_xw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM_title.html">StreamSets Control Hub</a></span></span></li>
   <li><span data-tocid="concept_xxd_f5r_kx-d46e177260" class="topicref" data-id="concept_xxd_f5r_kx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Event_Handling/EventFramework-Title.html#concept_xxd_f5r_kx">Dataflow Triggers</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_zq5_pb4_flb-d46e179451" class="topicref" data-id="concept_zq5_pb4_flb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Solutions/Solutions-title.html">Solutions</a></span></span></li>
   <li><span data-tocid="concept_wwq_gxc_py-d46e183788" class="topicref" data-id="concept_wwq_gxc_py" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wwq_gxc_py">Multithreaded Pipelines</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_gzw_tdm_p2b-d46e184370" class="topicref" data-id="concept_gzw_tdm_p2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Microservice/Microservice_Title.html#concept_gzw_tdm_p2b">Microservice Pipelines</a></span></span></li>
   <li><span data-tocid="Orchestrators_Title-d46e184742" class="topicref" data-id="Orchestrators_Title" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Orchestration_Pipelines/OrchestrationPipelines_Title.html#Orchestrators_Title">Orchestration Pipelines</a></span></span></li>
   <li><span data-tocid="concept_wr1_ktz_bt-d46e185034" class="topicref" data-id="concept_wr1_ktz_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/RPC_Pipelines/SDC_RPCpipelines_title.html#concept_wr1_ktz_bt">SDC RPC Pipelines</a></span></span></li>
   <li><span data-tocid="concept_fpz_5r4_vs-d46e185516" class="topicref" data-id="concept_fpz_5r4_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Cluster_Mode/ClusterPipelines_title.html">Cluster Pipelines</a></span></span></li>
   <li><span data-tocid="concept_jjk_23z_sq-d46e186661" class="topicref" data-id="concept_jjk_23z_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Preview/DataPreview_Title.html#concept_jjk_23z_sq">Data Preview</a></span></span></li>
   <li><span data-tocid="concept_pgk_brx_rr-d46e187617" class="topicref" data-id="concept_pgk_brx_rr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Alerts/RulesAlerts_title.html#concept_pgk_brx_rr">Rules and Alerts</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_asx_fdz_sq-d46e190245" class="topicref" data-id="concept_asx_fdz_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Monitoring/PipelineMonitoring_title.html#concept_asx_fdz_sq">Pipeline Monitoring</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_o3l_dtr_5q-d46e191502" class="topicref" data-id="concept_o3l_dtr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Maintenance/PipelineMaintenance_title.html#concept_o3l_dtr_5q">Pipeline Maintenance</a></span></span></li>
   <li><span data-tocid="concept_yms_ftm_sq-d46e193332" class="topicref" data-id="concept_yms_ftm_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Administration/Administration_title.html#concept_yms_ftm_sq">Administration</a></span></span></li>
   <li><span data-tocid="concept_nls_w1r_ks-d46e198182" class="topicref" data-id="concept_nls_w1r_ks" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Tutorial/Tutorial-title.html">Tutorial</a></span></span></li>
   <li><span data-tocid="concept_sh3_frm_tq-d46e199387" class="topicref" data-id="concept_sh3_frm_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Troubleshooting/Troubleshooting_title.html#concept_sh3_frm_tq">Troubleshooting</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_xbx_rs1_tq-d46e204830" class="topicref" data-id="concept_xbx_rs1_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Glossary/Glossary_title.html#concept_xbx_rs1_tq">Glossary</a></span></span></li>
   <li><span data-tocid="concept_jn1_nzb_kv-d46e204885" class="topicref" data-id="concept_jn1_nzb_kv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-DataFormats/DataFormat_Title.html#concept_jn1_nzb_kv">Data Formats by Stage</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_pvm_yt3_wq-d46e205107" class="topicref" data-id="concept_pvm_yt3_wq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Expression_Language/ExpressionLanguage_title.html">Expression Language</a></span></span></li>
   <li><span data-tocid="concept_vcj_1ws_js-d46e208778" class="topicref" data-id="concept_vcj_1ws_js" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-RegEx/RegEx-Title.html#concept_vcj_1ws_js">Regular Expressions</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_chv_vmj_wr-d46e209001" class="topicref" data-id="concept_chv_vmj_wr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-GrokPatterns/GrokPatterns_title.html#concept_chv_vmj_wr">Grok Patterns</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
</ul></div>
                        </nav>
                    
                    
                    <div class="col-lg-9 col-md-9 col-sm-9 col-xs-12" id="wh_topic_body">
                        <div class=" wh_topic_content body "><main role="main"><article role="article" aria-labelledby="ariaid-title1"><article class="nested0" aria-labelledby="ariaid-title1" id="concept_djz_pdm_hdb">
    <h1 class="title topictitle1" id="ariaid-title1">Hadoop FS Standalone</h1>

    <div class="body conbody">
        <div class="p"><div class="simpletable-container"><table cellpadding="4" cellspacing="0" summary="" id="concept_djz_pdm_hdb__simpletable_ijk_zjb_sgb" border="0" class="simpletable"><col style="width:100%" /><thead></thead><tbody><tr class="strow">
                <td style="vertical-align:top;" class="stentry"><a class="xref" href="../Pipeline_Configuration/ProductIcons_Doc.html#concept_mjg_ly5_pgb" title="In Data Collector, you can configure pipelines that are run by Data Collector and pipelines that are run by Data Collector Edge.">Supported pipeline types:</a><ul class="ul" id="concept_djz_pdm_hdb__d17e112">
                        <li class="li">
                            <p class="p"><img class="image" id="concept_djz_pdm_hdb__d17e117" src="../../../reusable-content/shared-graphics/icon-SDC.png" height="21" width="21" /> Data Collector</p>

                        </li>

                    </ul>
</td>

            </tr>
</tbody></table>
</div>The Hadoop FS Standalone origin
            reads files from HDFS. You can also use the origin to read from Azure Blob storage. </div>

        <p class="p">The files to be processed must all share a file name pattern and be fully written. The
            origin can use multiple threads to enable the parallel processing of files. Use the
            Hadoop FS Standalone origin only in pipelines configured for standalone execution mode.
            To read from HDFS in cluster execution mode, use the <a class="xref" href="HadoopFS-origin.html#concept_lw2_tnm_vs">Hadoop FS origin</a>.</p>

        <p class="p">When you configure the Hadoop FS Standalone origin, you define the directory to use, read
            order, file name pattern, file name pattern mode, and the first file to process. You can
            use glob patterns or regular expressions to define the file name pattern that you want
            to use. </p>

        <p class="p">When using the last-modified timestamp read order, you can configure the origin to read
            from subdirectories. To use multiple threads for processing, specify the number of
            threads to use. You can also enable reading compressed files. After processing a file,
            the Hadoop FS Standalone origin can keep, archive, or delete the file. </p>

        <p class="p">When the pipeline stops, the Hadoop FS Standalone origin notes where it stops reading.
            When the pipeline starts again, the origin continues processing from where it stopped by
            default. You can reset the origin to process all requested files. </p>

        <p class="p">The origin generates record header attributes that enable you to use the origins of a
            record in pipeline processing. </p>

        <p class="p">When necessary, you can enable Kerberos authentication. You can
                  also specify a Hadoop user to impersonate, define a Hadoop configuration file
                  directory, and add Hadoop configuration properties as needed. </p>

        <p class="p">The origin can generate events for an event stream. For
                  more information about dataflow triggers and the event framework, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">Dataflow Triggers Overview</a>. </p>

    </div>

<article class="topic concept nested1" aria-labelledby="ariaid-title2" id="concept_wcp_zxk_1hb">
    <h2 class="title topictitle2" id="ariaid-title2">File Directory</h2>

    
    <div class="body conbody"><p class="shortdesc"></p>

        <p class="p">To define the directory that the <span class="ph">Hadoop FS Standalone</span> origin reads files from, enter
            an absolute directory. Use a glob pattern to include wildcards and define multiple
            directories to read files from. </p>

        <div class="p">For example, suppose you have the following folders:
            <pre class="pre codeblock"><code>/hr/employees/CA/SFO
/hr/employees/CA/SJC
/hr/employees/CA/LAX
/hr/employees/WA/SEA</code></pre></div>

        <div class="p">When defining the directory, you can include wildcards to have the origin read files from
            different combinations of folders. The following table shows some possibilities: 
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_wcp_zxk_1hb__table_cyr_4zk_1hb" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:50%" /><col style="width:50%" /></colgroup><thead class="thead" style="text-align:left;">
                        <tr>
                            <th class="entry cellrowborder" id="d361497e498">Folders to Read</th>

                            <th class="entry cellrowborder" id="d361497e501">File Directory Defined</th>

                        </tr>

                    </thead>
<tbody class="tbody">
                        <tr>
                            <td class="entry cellrowborder" headers="d361497e498 "><span class="ph filepath">/hr/employees/CA/SFO</span><p class="p"><span class="ph filepath">/hr/employees/CA/SJC</span></p>
<p class="p"><span class="ph filepath">/hr/employees/CA/LAX</span></p>
</td>

                            <td class="entry cellrowborder" headers="d361497e501 "><kbd class="ph userinput">/hr/employees/CA/*</kbd></td>

                        </tr>

                        <tr>
                            <td class="entry cellrowborder" headers="d361497e498 "><span class="ph filepath">/hr/employees/CA/SFO</span><p class="p"><span class="ph filepath">/hr/employees/CA/SJC</span></p>
</td>

                            <td class="entry cellrowborder" headers="d361497e501 "><kbd class="ph userinput">/hr/employees/CA/S*</kbd></td>

                        </tr>

                        <tr>
                            <td class="entry cellrowborder" headers="d361497e498 "><span class="ph filepath">/hr/employees/CA/SFO</span><p class="p"><span class="ph filepath">/hr/employees/CA/SJC</span></p>
<p class="p"><span class="ph filepath">/hr/employees/WA/SEA</span></p>
</td>

                            <td class="entry cellrowborder" headers="d361497e501 "><kbd class="ph userinput">/hr/employees/*/S*</kbd></td>

                        </tr>

                    </tbody>
</table>
</div>
</div>

        <p class="p">For more information about glob patterns, see the <a class="xref" href="https://docs.oracle.com/javase/tutorial/essential/io/fileOps.html#glob" target="_blank">Oracle Java documentation</a>.</p>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title3" id="concept_exc_22h_ldb">
    <h2 class="title topictitle2" id="ariaid-title3">File Name Pattern and Mode</h2>

    
    <div class="body conbody"><p class="shortdesc">Use a file name pattern to define the files that the <span class="ph">Hadoop FS Standalone</span> origin
        processes. <span class="ph">You can use either a glob pattern or a regular expression to define
                the file name pattern. </span></p>

        <p class="p">The
                <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">processes files based on the file name pattern mode, file
                name pattern, and specified directory. For example, if you specify a
                    <code class="ph codeph">/logs/weblog/ </code>directory, glob mode, and <code class="ph codeph">*.json</code>
                as the file name pattern, the origin processes all files with the
                    <code class="ph codeph">json</code> extension in the <code class="ph codeph">/logs/weblog/</code>
                directory.</span></p>

        <p class="p">The origin processes files in order based on the specified read
            order.</p>

        <p class="p">For more information about glob syntax, see the <a class="xref" href="https://docs.oracle.com/javase/tutorial/essential/io/fileOps.html#glob" target="_blank">Oracle Java documentation</a>. For more
            information about regular expressions, see <a class="xref" href="../Apx-RegEx/RegEx-Title.html#concept_vd4_nsc_gs" title="A regular expression, also known as regex, describes a pattern for a string.">Regular Expressions Overview</a>.</p>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title4" id="concept_ogz_q3h_ldb">
    <h2 class="title topictitle2" id="ariaid-title4">Read Order</h2>

    <div class="body conbody">
        <p class="p">The
                <span class="ph">Hadoop FS Standalone</span> origin reads files in ascending order based on the
            timestamp or file name:</p>

        <div class="p">
            <dl class="dl">
                
                    <dt class="dt dlterm">Last Modified Timestamp</dt>

                    <dd class="dd">The <span class="ph">Hadoop FS Standalone</span> origin can read
                        files in ascending order based on the last modified timestamp associated
                        with the file. When the origin reads from a secondary location - not the
                        directory where the files are created and written - the last-modified
                        timestamp should be when the file is moved to the directory to be
                        processed.</dd>

                    <dd class="dd ddexpand">
                        <div class="note tip"><span class="tiptitle">Tip:</span> Avoid moving files using commands that preserve the
                            existing timestamp, such as <code class="ph codeph">cp -p</code>. Preserving the
                            existing timestamp can be problematic in some cases, such as moving
                            files across time zones.</div>

                    </dd>

                    <dd class="dd ddexpand">When ordering based on timestamp, any files with the same timestamp are read
                        in lexicographically ascending order based on the file names.</dd>

                    <dd class="dd ddexpand">For example, when reading files with the <code class="ph codeph">log*.json</code> file
                        name pattern, the origin reads the following files in the following
                        order:</dd>

                    <dd class="dd ddexpand">
                        <div class="simpletable-container"><table cellpadding="4" cellspacing="0" summary="" id="concept_ogz_q3h_ldb__simpletable_jmm_1g4_xv" border="0" class="simpletable"><col style="width:41.66666666666667%" /><col style="width:58.333333333333336%" /><thead></thead><tbody><tr class="strow">
                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph"><span class="ph uicontrol">File Name</span></code>
                                </td>

                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph"><span class="ph uicontrol">Last Modified</span></code>
                                </td>

                            </tr>
<tr class="strow">
                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">log-1.json</code>
                                </td>

                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">APR 24 2016 14:03:35</code>
                                </td>

                            </tr>
<tr class="strow">
                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">log-903.json</code>
                                </td>

                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">APR 24 2016 14:05:03</code>
                                </td>

                            </tr>
<tr class="strow">
                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">log-2.json</code>
                                </td>

                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">APR 24 2016 14:45:11</code>
                                </td>

                            </tr>
<tr class="strow">
                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">log-3.json</code></td>

                                <td style="vertical-align:top;" class="stentry">
                                    <code class="ph codeph">APR 24 2016 14:45:11</code></td>

                            </tr>
</tbody></table>
</div>
                    </dd>

                    <dd class="dd ddexpand">Notice, the <span class="ph filepath">log-2.json</span> and
                            <span class="ph filepath">log-3.json</span> files have identical timestamps, and so
                        are processed in lexicographically ascending order based on their file
                        names.</dd>

                
                
                    <dt class="dt dlterm">Lexicographically Ascending File Names</dt>

                    <dd class="dd">The <span class="ph">Hadoop FS Standalone</span> origin can read files in lexicographically
                        ascending order based on file names. Note that lexicographically ascending
                        order reads the numbers 1 through 11 as follows:</dd>

                    <dd class="dd ddexpand">
                        <pre class="pre codeblock"><code>1, 10, 11, 2, 3, 4... 9</code></pre>
                    </dd>

                    <dd class="dd ddexpand">For example, when reading files with the <code class="ph codeph">web*.log</code> file name
                        pattern, the <span class="ph">Hadoop FS Standalone</span> origin reads the following files in
                        the following
                        order:<pre class="pre codeblock"><code>web-1.log
web-10.log
web-11.log
web-2.log
web-3.log
web-4.log
web-5.log
web-6.log
web-7.log
web-8.log
web-9.log</code></pre></dd>

                    <dd class="dd ddexpand">To read these files in logical and lexicographically ascending order, you
                        might add leading zeros to the file naming convention as
                        follows:<pre class="pre codeblock"><code>web-0001.log
web-0002.log
web-0003.log
...
web-0009.log
web-0010.log
web-0011.log</code></pre></dd>

                
            </dl>

        </div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title5" id="concept_fgx_1jh_ldb">
    <h2 class="title topictitle2" id="ariaid-title5">Multithreaded Processing</h2>

    
    <div class="body conbody"><p class="shortdesc">The <span class="ph">Hadoop FS Standalone</span> origin uses multiple concurrent threads to process data
        based on the Number of Threads property. </p>

        <p class="p">Each
            thread reads data from a single file, and each file can have a maximum of one thread
            read from it at a time. The file read order is based on the configuration for the <a class="xref" href="HDFSStandalone.html#concept_ogz_q3h_ldb">Read Order property</a>.</p>

        <p class="p">As the pipeline runs, <span class="ph">each thread connects to the origin system,
                        creates a batch of data, and passes the batch to an available pipeline
                        runner. <span class="ph">A pipeline runner is a <dfn class="term">sourceless
                              pipeline instance</dfn> - an instance of the pipeline that includes
                        all of the processors, executors, and destinations in the pipeline and
                        handles all pipeline processing after the origin.</span></span></p>

        <p class="p">
            <span class="ph"><span class="ph" id="concept_fgx_1jh_ldb__d15e3219">Each pipeline runner
                              processes one batch at a time, just like a pipeline that runs on a
                              single thread.</span> When the flow of data slows, the pipeline runners
                        wait idly until they are needed, generating an empty batch at regular
                        intervals. You can configure the Runner Idle Time pipeline property to
                        specify the interval or to opt out of empty batch generation.</span></p>

        <p class="p"><span class="ph"><span class="ph" id="concept_fgx_1jh_ldb__d15e3226">Multithreaded pipelines preserve the order of records within each
                              batch, just like a single-threaded pipeline. But since</span> batches
                              <span class="ph" id="concept_fgx_1jh_ldb__d15e3229">are processed by different
                              pipeline runners, the order that batches are written to destinations
                              is not ensured.</span></span></p>

        <p class="p">For example, say you configure the origin to read files from a directory using five
            threads and the Last Modified Timestamp read order. When you start the pipeline, <span class="ph">the origin creates five
                              threads, and <span class="ph">Data Collector</span>
                              creates a matching number of pipeline runners.</span>
        </p>

        <p class="p">The <span class="ph">Hadoop FS Standalone</span> origin assigns a thread to each of the five oldest files in
            the directory. Each thread processes its assigned file, passing batches of data to the
            origin. <span class="ph">Upon receiving data, the origin passes a batch to
                              each of the pipeline runners for processing.</span>
        </p>

        <p class="p">After each thread completes processing a file, it continues to the next file based on the
            last-modified timestamp, until all files are processed. </p>

        <p class="p">For more information about multithreaded pipelines, see <a class="xref" href="../Multithreaded_Pipelines/MultithreadedPipelines.html#concept_zpp_2xc_py">Multithreaded Pipeline Overview</a>.</p>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title6" id="concept_bwq_nyj_mdb">
    <h2 class="title topictitle2" id="ariaid-title6">Reading from Subdirectories</h2>

    
    <div class="body conbody"><p class="shortdesc">When using the Last Modified Timestamp read order, the <span class="ph">Hadoop FS Standalone</span>
        origin can read files in subdirectories of the specified file directory. </p>

        <p class="p">When
            you configure the origin to read from subdirectories, it reads files from all
            subdirectories. It reads files in ascending order based on timestamp, regardless of the
            location of the file within the directory.</p>

        <div class="p">For example, say you configure the <span class="ph">Hadoop FS Standalone</span> origin to read from the
                <span class="ph filepath">/logs/ file</span> directory, select the Last Modified Timestamp read
            order, and enable reading from subdirectories. The <span class="ph">Hadoop FS Standalone</span> origin reads
            the following files in the following order based on timestamp, even though the files are
            written to different subdirectories. <div class="simpletable-container"><table cellpadding="4" cellspacing="0" summary="" id="concept_bwq_nyj_mdb__simpletable_jmm_1g4_xv" border="0" class="simpletable"><col style="width:33.33333333333333%" /><col style="width:33.33333333333333%" /><col style="width:33.33333333333333%" /><thead></thead><tbody><tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph"><span class="ph uicontrol">File Name</span></code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph"><span class="ph uicontrol">Directory</span></code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph"><span class="ph uicontrol">Last Modified Timestamp</span></code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-1.json</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/logs/west/</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">APR 24 2016 14:03:35</code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-0054.json</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/logs/east/</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">APR 24 2016 14:05:03</code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-0055.json </code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/logs/west/</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">APR 24 2016 14:45:11</code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-2.json</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/logs/</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">APR 24 2016 14:45:11</code>
                    </td>

                </tr>
</tbody></table>
</div></div>

    </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title7" id="concept_w3r_qhk_mdb">
    <h3 class="title topictitle3" id="ariaid-title7">Post-Processing Subdirectories</h3>

    
    <div class="body conbody"><p class="shortdesc">When the <span class="ph">Hadoop FS Standalone</span> origin reads from subdirectories, it uses the
        subdirectory structure when archiving files during post-processing. </p>

        <p class="p">You
            can archive files when the origin completes processing a file or when it cannot fully
            process a file.</p>

        <div class="p">For example, say you configure the origin to archive processed files to a "processed"
            archive directory. After successfully reading the files in the example above, it writes
            them to the following directories:<div class="simpletable-container"><table cellpadding="4" cellspacing="0" summary="" id="concept_w3r_qhk_mdb__simpletable_jmm_1g4_xv" border="0" class="simpletable"><col style="width:50%" /><col style="width:50%" /><thead></thead><tbody><tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph"><span class="ph uicontrol">File Name</span></code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph"><span class="ph uicontrol">Archive Directory</span></code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-1.json</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/processed/logs/west/</code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-0054.json</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/processed/logs/east/</code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-0055.json </code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/processed/logs/west/</code>
                    </td>

                </tr>
<tr class="strow">
                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">log-2.json</code>
                    </td>

                    <td style="vertical-align:top;" class="stentry">
                        <code class="ph codeph">/processed/logs/</code>
                    </td>

                </tr>
</tbody></table>
</div></div>

    </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title8" id="concept_a2q_4kh_ldb">
    <h2 class="title topictitle2" id="ariaid-title8">First File for Processing</h2>

    
    <div class="body conbody"><p class="shortdesc">Configure a first file for processing when you want the <span class="ph">Hadoop FS Standalone</span>
        origin to ignore one or more existing files in the directory.</p>

        <p class="p">When
            you define a first file to process, the <span class="ph">Hadoop FS Standalone</span> origin starts
            processing with the specified file and continues based on the read order and file name
            pattern. When you do not specify a first file, the origin processes all files in the
            directory that match the file name pattern. </p>

        <p class="p">For example, say the <span class="ph">Hadoop FS Standalone</span> origin reads files based on last-modified
            timestamp. To ignore all files older than a particular file, use that file name as the
            first file to process.</p>

        <p class="p">Similarly, say you have the origin reading files based on lexicographically ascending
            file names, and the file directory includes the following files:
                <span class="ph filepath">web_001.log</span>, <span class="ph filepath">web_002.log</span>,
                <span class="ph filepath">web_003.log</span>. </p>

        <p class="p">If you configure <span class="ph filepath">web_002.log</span> as the first file, the origin reads
                <span class="ph filepath">web_002.log</span> and continues to <span class="ph filepath">web_003.log</span>.
            It skips <span class="ph filepath">web_001.log</span>. </p>

    </div>

</article>
<article class="topic task nested1" aria-labelledby="ariaid-title9" id="task_nbb_425_vjb">
    <h2 class="title topictitle2" id="ariaid-title9">Reading from Azure Blob Storage</h2>

    <div class="body taskbody">
        <section class="section context">
            <p class="p">Using the HDP stage
                library, the Hadoop FS Standalone origin can access Azure Blob storage with the WASB
                protocol. To read from Azure Blob storage, configure the Hadoop FS Standalone origin
                to use the HDP stage library and to connect with the appropriate URI and Azure
                credentials.</p>

        </section>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">General</span> tab, set the <span class="ph uicontrol">Stage
                        Library</span> property to the HDP stage library version 2.4 or later.
                </span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Connection</span> tab, set the <span class="ph uicontrol">File System
                        URI</span> property as follows:</span>
                <div class="itemgroup info">
                    <pre class="pre codeblock"><code>&lt;wasb[s]&gt;://&lt;container name&gt;@&lt;storage account name&gt;.blob.core.windows.net</code></pre>
                    <p class="p">In the URI, &lt;container name&gt; is the Azure container name, and &lt;storage
                        account name&gt; is the Azure storage account name.</p>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the <span class="ph uicontrol">Additional Configuration</span> property, enter the
                    Azure credentials: </span>
                <ol type="a" class="ol substeps" id="task_nbb_425_vjb__d23e11816">
                    <li class="li substep">
                        <span class="ph cmd">If necessary, click the <span class="ph uicontrol">Add</span> icon to add an
                            additional configuration property.</span>
                    </li>

                    <li class="li substep">
                        <span class="ph cmd">In the <span class="ph uicontrol">Name</span> property, enter the Azure storage
                            account.</span>
                    </li>

                    <li class="li substep">
                        <span class="ph cmd">In the <span class="ph uicontrol">Value</span> property, enter the plain-text key
                            for the storage account. </span>
                    </li>

                </ol>

                <div class="itemgroup info">
                    <div class="note note"><span class="notetitle">Note:</span> You can also use <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">bulk edit mode</a> to add configuration properties.</div>

                </div>
            </li>
</ol>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title10" id="concept_vfk_yrv_ldb">
    <h2 class="title topictitle2" id="ariaid-title10">Reading from Azure Blob Storage with Azure HDInsight</h2>

    <div class="body conbody">
        <p class="p">If you <span class="ph"><a class="xref" href="../Installation/CloudInstall.html#task_vnj_rl2_wdb" title="You can install the full Data Collector on a Microsoft Azure HDInsight cluster.">installed <span class="ph">Data Collector</span> on Azure HDInsight</a></span>, then you can read from Azure Blob storage with
                HDInsight.</p>

        <div class="p">To read from Azure Blob storage with HDInsight, configure the Hadoop FS Standalone origin
            to use the HDP stage library and to connect with the appropriate Azure credentials and
            URI. <ol class="ol" id="concept_vfk_yrv_ldb__ol_kvn_mnf_sw">
                <li class="li">On the <span class="keyword wintitle">General</span> tab of the Hadoop FS Standalone origin, set
                    the <span class="ph uicontrol">Stage Library</span> property to the HDP stage library
                    version 2.4 or later. </li>

                <li class="li">Configure Azure credentials in one of the following ways:<ul class="ul" id="concept_vfk_yrv_ldb__ul_hzr_q2g_sw">
                        <li class="li">If the Azure credentials are defined in the HDFS configuration file
                                <code class="ph codeph">core-site.xml</code>, configure the origin to access the
                                file.<ol class="ol" type="a" id="concept_vfk_yrv_ldb__ol_sjt_rmd_rx">
                                <li class="li">On the <span class="ph uicontrol">Connection</span> tab, configure the
                                        <span class="ph uicontrol">Configuration Files Directory</span>
                                    property to point to the directory that includes the file. </li>

                            </ol>
</li>

                        <li class="li">If the credentials are not defined in the <code class="ph codeph">core-site.xml</code>
                            file, configure the origin to pass an additional configuration property
                            that contains the Azure credentials:<ol class="ol" type="a" id="concept_vfk_yrv_ldb__ol_yxb_1ht_px">
                                <li class="li">On the <span class="keyword wintitle">Connection</span> tab, configure the
                                        <span class="ph uicontrol">Additional Configuration</span> property to
                                    pass the Azure credentials. <p class="p">You can use <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a> to add configuration
                                        properties.</p>
</li>

                                <li class="li">If necessary, click the <span class="ph uicontrol">Add</span> icon to add a
                                    new additional configuration property. </li>

                                <li class="li">In the <span class="ph uicontrol">Name</span> property, enter the Azure
                                    storage account name as
                                    follows:<pre class="pre codeblock"><code>fs.azure.account.key.&lt;storage account name&gt;.blob.core.windows.net</code></pre>For
                                    example, if the storage account name is <code class="ph codeph">sdchd</code>,
                                    then enter the following name for the property:
                                        <pre class="pre codeblock"><code>fs.azure.account.key.sdchd.blob.core.windows.net</code></pre><div class="note tip"><span class="tiptitle">Tip:</span> You can find the Azure storage account name on
                                        the <span class="keyword wintitle">Access Keys</span> page in the Microsoft
                                        Azure portal. To view the page in the Microsoft Azure
                                        portal, click <span class="ph menucascade"><span class="ph uicontrol">All Resources</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Storage Account</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Access Keys</span></span>. A page like the following appears, with the
                                        storage account name and access keys:</div>
<p class="p"><img class="image" id="concept_vfk_yrv_ldb__image_v3c_j3t_px" src="../Graphics/Azure-AccessKeys.png" height="425" width="602" /></p>
</li>

                                <li class="li">In the <span class="ph uicontrol">Value</span> property, enter an access
                                    key value for the Azure storage account. You can use any valid key.<div class="p">
                                        <div class="note tip"><span class="tiptitle">Tip:</span> The account key value also displays on the
                                                <span class="keyword wintitle">Access Keys</span> page. For example,
                                            on the image above, you could use either the key1 or
                                            key2 value. </div>

                                    </div>
</li>

                            </ol>
</li>

                    </ul>
</li>

                <li class="li">On the <span class="keyword wintitle">Connection</span> tab, configure the <span class="ph uicontrol">File System
                        URI</span> property as
                        follows:<pre class="pre codeblock"><code>&lt;wasb[s]&gt;://&lt;container name&gt;@&lt;storage account name&gt;.blob.core.windows.net/&lt;path to files&gt;</code></pre><p class="p">In
                        the URI, &lt;container name&gt; is the Azure container name, and &lt;storage
                        account name&gt; is the Azure storage account name. </p>
<div class="p">For example, for a
                            <code class="ph codeph">sdc-hd</code> container in a storage account named
                            <code class="ph codeph">sdchd</code>, with all files in a <span class="ph filepath">files</span>
                        directory, you would define the file system URI as
                        follows:<pre class="pre codeblock"><code>wasbs://sdc-hd@sdchd.blob.core.windows.net/files</code></pre></div>
<div class="p">
                        <div class="note tip"><span class="tiptitle">Tip:</span> You can find the container name and storage account name on
                            the <span class="keyword wintitle">Essentials</span> page in the Microsoft Azure portal.
                            For a standard storage account, in the Microsoft Azure portal, click <span class="ph menucascade"><span class="ph uicontrol">All Resources</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Storage Account</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Overview</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Blobs</span></span>. For a blob storage account, click <span class="ph menucascade"><span class="ph uicontrol">All Resources</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Storage Account</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Overview</span></span>. </div>

                    </div>
<p class="p">The page shows the container name and storage account name:</p>
<p class="p"><img class="image" id="concept_vfk_yrv_ldb__image_r2s_snt_px" src="../Graphics/Azure-BlobService.png" height="374" width="498" /></p>
Though the host name for the file system URI is
                        <code class="ph codeph">&lt;storage account name&gt;.blob.core.windows.net</code>, you can
                    alternatively use the host name of the Azure blob service endpoint as the host
                    name for the file system URI.</li>

            </ol>
</div>

        <section class="section" id="concept_vfk_yrv_ldb__section_ond_csv_ldb"><h3 class="title sectiontitle">Example</h3>
            
            <p class="p">The following image shows how to configure the Hadoop FS Standalone origin to read
                from Azure Blob storage with HDInsight using the Azure account information from the
                examples above:</p>

            <p class="p"><img class="image" id="concept_vfk_yrv_ldb__image_ufb_rtv_ldb" src="../Graphics/AzureHDInsight-HDFSStandalone.png" /></p>

        </section>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title11" id="concept_asp_lfh_ldb">
    <h2 class="title topictitle2" id="ariaid-title11">Record Header Attributes</h2>

    
    <div class="body conbody"><p class="shortdesc">The <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">creates record header
                attributes that include <span class="ph" id="d55e21">information about the originating file for
                    the record</span>.</span>
    </p>

        <p class="p">When
            the origin <span class="ph">processes Avro data, it includes the Avro schema in
                        an avroSchema record header attribute.</span></p>

        <p class="p"><span class="ph" id="concept_asp_lfh_ldb__d18e22">You can use the <code class="ph codeph">record:attribute</code> or
                    <code class="ph codeph">record:attributeOrDefault</code> functions to access the information
                in the attributes. For more information about working with record header attributes,
                see <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_rd2_ghz_dz">Working with Header Attributes</a>.</span></p>

        <div class="p">The <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">creates the following record header
                attributes:</span><ul class="ul" id="concept_asp_lfh_ldb__ul_nsd_xfb_j1b">
                <li class="li">avroSchema - When processing Avro data, provides the
                              Avro schema.</li>

                <li class="li">baseDir - Base directory containing the file where the record originated.</li>

            </ul>
<ul class="ul" id="concept_asp_lfh_ldb__ul_wqg_nk1_2z">
                <li class="li" id="concept_asp_lfh_ldb__d55e33">filename - Provides the name of the file where the record
                    originated.</li>

                <li class="li" id="concept_asp_lfh_ldb__d55e36">file - Provides the file path and file name where the record
                    originated.</li>

                <li class="li" id="concept_asp_lfh_ldb__d55e39">mtime - Provides the last-modified time for the file.</li>

                <li class="li" id="concept_asp_lfh_ldb__d55e42">offset - Provides the file offset in bytes. The file offset is
                    the location in the file where the record originated.</li>

            </ul>
<ul class="ul" id="concept_asp_lfh_ldb__ul_ebw_1hh_ldb">
                <li class="li">atime - Provides the last accessed time.</li>

                <li class="li">isDirectory - Indicates if the file is a directory.</li>

                <li class="li">isSymbolicLink - Indicates if the file is a symbolic link.</li>

                <li class="li">size - Provides the file size.</li>

                <li class="li">owner - Provides the file owner.</li>

                <li class="li">group - Provides the group associated with the file.</li>

                <li class="li">blocksize - Provides the block size of the file.</li>

                <li class="li">replication - Provides the replication of the file. </li>

                <li class="li">isEncrypted - Indicates if the file is encrypted.</li>

            </ul>
</div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title12" id="concept_zlx_5rh_ldb">
    <h2 class="title topictitle2" id="ariaid-title12">Event Generation</h2>

    <div class="body conbody">
        <p class="p">The
                <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">can generate events that you can use in an event stream. When
                        you enable event generation, the origin generates event records each time
                        the origin starts or completes reading a file.</span> It can also generate events when it completes processing all available data and the
            configured batch wait time has elapsed.</p>

        <div class="p">Events generated by the <span class="ph">Hadoop FS Standalone</span> origin can be used in any logical way.
            For example: <ul class="ul" id="concept_zlx_5rh_ldb__ul_vgr_wrh_ldb">
                <li class="li">With the Pipeline Finisher executor to
                              stop the pipeline and transition the pipeline to a Finished state when
                              the origin completes processing available data.<p class="p">When you restart a
                                    pipeline stopped by the Pipeline Finisher executor, the origin
                                    continues processing from the last-saved offset unless you reset
                                    the origin.</p>
<p class="p">For an example, see <a class="xref" href="../Solutions/StopPipeline.html#concept_kff_ykv_lz" title="This solution describes how to design a pipeline that stops automatically after it finishes processing all available data.">Stopping a Pipeline After Processing All Available Data</a>.</p>
</li>

                <li class="li">With the Email executor to send a custom email
                              after receiving an event.<p class="p">For an example, see <a class="xref" href="../Solutions/SendEmail.html#concept_t2t_lp5_xz" title="This solution describes how to design a pipeline to send email notifications at different moments during pipeline processing.">Sending Email During Pipeline Processing</a>.</p>
</li>

            </ul>
<ul class="ul" id="concept_zlx_5rh_ldb__ul_xcz_dx4_vz">
                <li class="li">With a destination to store event information.
                                    <p class="p">For an example, see <a class="xref" href="../Solutions/EventStorage.html#concept_ocb_nnl_px" title="This solution describes how to design a pipeline that preserves an audit trail of pipeline and stage events that occur.">Preserving an Audit Trail of Events</a>.</p>
</li>

            </ul>
</div>

        <p class="p"><span class="ph">For more information about dataflow
                        triggers and the event framework, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">Dataflow Triggers Overview</a>.</span></p>

    </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title13" id="concept_p5x_2d3_ldb">
    <h3 class="title topictitle3" id="ariaid-title13">Event Records</h3>

    <div class="body conbody">
        <div class="p">Event
            records generated by the <span class="ph">Hadoop FS Standalone</span> origin have the following
            event-related record header attributes. Record header attributes are stored as String
                values:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_p5x_2d3_ldb__table_brz_3gp_qx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                        <tr>
                            <th class="entry cellrowborder" id="d361497e1764">Record Header Attribute</th>

                            <th class="entry cellrowborder" id="d361497e1767">Description</th>

                        </tr>

                    </thead>
<tbody class="tbody">
                        <tr>
                            <td class="entry cellrowborder" headers="d361497e1764 ">sdc.event.type</td>

                            <td class="entry cellrowborder" headers="d361497e1767 ">Event type. Uses one of the following types:<ul class="ul" id="concept_p5x_2d3_ldb__ul_m12_mgp_qx">
                                    <li class="li">new-file - Generated when the origin starts processing a new
                                        file. </li>

                                    <li class="li">finished-file - Generated when the origin completes
                                        processing a file.</li>

                                    <li class="li">no-more-data - Generated after the origin completes
                                        processing all available files and the number of seconds
                                        configured for Batch Wait Time has elapsed.</li>

                                </ul>
</td>

                        </tr>

                        <tr>
              <td class="entry cellrowborder" headers="d361497e1764 ">sdc.event.version</td>

              <td class="entry cellrowborder" headers="d361497e1767 ">Integer that indicates the version of the event record type.</td>

            </tr>

                        <tr>
              <td class="entry cellrowborder" headers="d361497e1764 ">sdc.event.creation_timestamp</td>

              <td class="entry cellrowborder" id="concept_p5x_2d3_ldb__d31e2883" headers="d361497e1767 ">Epoch timestamp when the stage created the event.
              </td>

            </tr>

                    </tbody>
</table>
</div>
</div>

        <p class="p">The <span class="ph">Hadoop FS Standalone</span> origin can generate the following types of event records: </p>

        <dl class="dl">
            
                <dt class="dt dlterm">new-file</dt>

                <dd class="dd">The <span class="ph">Hadoop FS Standalone</span> origin generates a new-file event record when it
                    starts processing a new file. </dd>

                <dd class="dd ddexpand">New-file event records have the <code class="ph codeph">sdc.event.type</code> record header
                    attribute set to <code class="ph codeph">new-file</code> and include the following
                        field:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_p5x_2d3_ldb__table_vmc_l42_px" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e1854">Event Record Field</th>

                                    <th class="entry cellrowborder" id="d361497e1857">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e1854 ">filepath</td>

                                    <td class="entry cellrowborder" headers="d361497e1857 ">Path and name of the file that the origin started or
                                        finished processing.</td>

                                </tr>

                            </tbody>
</table>
</div>
</dd>

            
            
                <dt class="dt dlterm">finished-file</dt>

                <dd class="dd">The <span class="ph">Hadoop FS Standalone</span> origin generates a finished-file event record when
                    it finishes processing a file.</dd>

                <dd class="dd ddexpand">Finished-file event records have the <code class="ph codeph">sdc.event.type</code> record
                    header attribute set to <code class="ph codeph">finished-file</code> and include the following
                        fields:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_p5x_2d3_ldb__table_msq_qzn_j1b" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e1908">Event Record Field</th>

                                    <th class="entry cellrowborder" id="d361497e1911">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e1908 ">filepath</td>

                                    <td class="entry cellrowborder" headers="d361497e1911 ">Path and name of the file that the origin started or
                                        finished processing.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e1908 ">record-count</td>

                                    <td class="entry cellrowborder" headers="d361497e1911 ">Number of records successfully generated from the
                                        file.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e1908 ">error-count</td>

                                    <td class="entry cellrowborder" headers="d361497e1911 ">Number of error records generated from the file. </td>

                                </tr>

                            </tbody>
</table>
</div>
</dd>

            
            
                <dt class="dt dlterm">no-more-data</dt>

                <dd class="dd">The <span class="ph">Hadoop FS Standalone</span> origin generates a no-more-data event record when
                    the origin completes processing all available records and the number of seconds
                    configured for Batch Wait Time elapses without any new files appearing to be
                    processed. </dd>

                <dd class="dd ddexpand">No-more-data event records have the <code class="ph codeph">sdc.event.type</code> record
                    header attribute set to <code class="ph codeph">no-more-data</code> and include the following
                        fields:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_p5x_2d3_ldb__table_fcv_xx4_j1b" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e1980">Event Record Field</th>

                                    <th class="entry cellrowborder" id="d361497e1983">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
              <td class="entry cellrowborder" headers="d361497e1980 ">record-count</td>

              <td class="entry cellrowborder" headers="d361497e1983 ">Number of records successfully generated since the pipeline started or since
                the last no-more-data event was created. </td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e1980 ">error-count</td>

              <td class="entry cellrowborder" headers="d361497e1983 ">Number of error records generated since the pipeline started or since the last
                no-more-data event was created.</td>

            </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e1980 ">file-count</td>

                                    <td class="entry cellrowborder" headers="d361497e1983 ">Number of files the origin attempted to process. Can
                                        include files that were unable to be processed or were not
                                        fully processed.</td>

                                </tr>

                            </tbody>
</table>
</div>
</dd>

            
        </dl>

    </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title14" id="concept_jbn_md3_ldb">
    <h2 class="title topictitle2" id="ariaid-title14">Buffer Limit and Error Handling</h2>

    
    <div class="body conbody"><p class="shortdesc">The <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">passes each record to a buffer. The size of the buffer determines
                the maximum size of the record that can be processed. Decrease the buffer limit when
                memory on the <span class="ph">Data Collector</span>
                machine is limited. Increase the buffer limit to process larger records when memory
                is available.</span></p>

        <div class="p">When
            a record is larger than the specified limit, the <span class="ph">Hadoop FS Standalone</span> origin <span class="ph">processes the source file based on the stage error
            handling:</span><dl class="dl">
                
                    <dt class="dt dlterm">Discard</dt>

                    <dd class="dd">The origin discards the record and all remaining records in the file, and
                        then continues processing the next file.</dd>

                
                
                    <dt class="dt dlterm">Send to Error </dt>

                    <dd class="dd">With a buffer limit error, the origin cannot send the record to the pipeline
                        for error handling because it is unable to fully process the record.
                            <p class="p">Instead, the origin creates a message stating that a buffer overrun
                            error occurred. The message includes the file and offset where the
                            buffer overrun error occurred. The information displays in the pipeline
                                history<span class="ph"> and displays as an alert when you monitor
                                the pipeline</span>. </p>
<p class="p">If an error directory is configured for
                            the stage, the origin moves the file to the error directory and
                            continues processing the next file. </p>
</dd>

                
                
                    <dt class="dt dlterm">Stop Pipeline</dt>

                    <dd class="dd">The origin stops the pipeline and creates a message stating that a buffer
                        overrun error occurred. The message includes the file and offset where the
                        buffer overrun error occurred. The information displays <span class="ph">as
                            an alert and </span>in the pipeline history. </dd>

                    <dd class="dd ddexpand">
                        <div class="note note" id="concept_jbn_md3_ldb__d273e118"><span class="notetitle">Note:</span> You can also check the <span class="ph">Data Collector</span> log file for error details. </div>

                    </dd>

                
            </dl>
</div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title15" id="concept_vvd_4zp_ldb">
    <h2 class="title topictitle2" id="ariaid-title15">Kerberos Authentication</h2>

    <div class="body conbody">
        <p class="p"><span class="ph">You can use Kerberos authentication to connect to HDFS. When you
                use Kerberos authentication, <span class="ph">Data Collector</span>
                uses the Kerberos principal and keytab to connect to HDFS. By default, <span class="ph">Data Collector</span>
                uses the user account who started it to connect.</span></p>

        <p class="p"><span class="ph">The Kerberos principal and keytab are defined in the <span class="ph">Data Collector</span>
                configuration file, <code class="ph codeph">$SDC_CONF/sdc.properties</code>. To use Kerberos
                authentication, configure all Kerberos properties in the <span class="ph">Data Collector</span>
                configuration file, and then enable Kerberos in the</span> Hadoop FS Standalone origin.</p>

        <p class="p"><span class="ph">For more information about enabling Kerberos authentication
                        for <span class="ph">Data Collector</span>, see <a class="xref" href="../Configuration/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Kerberos Authentication</a>.</span></p>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title16" id="concept_zx5_yzp_ldb">
    <h2 class="title topictitle2" id="ariaid-title16">HDFS Properties and Configuration Files</h2>

    <div class="body conbody">
        <div class="p">You can configure the Hadoop FS
            Standalone origin to use individual HDFS properties or HDFS configuration
                files:<dl class="dl">
                
                    <dt class="dt dlterm">HDFS configuration files</dt>

                    <dd class="dd">You can use the following HDFS configuration files with the Hadoop FS
                        Standalone origin:<ul class="ul" id="concept_zx5_yzp_ldb__ul_qhn_ytr_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                  </ul>
</dd>

                    <dd class="dd ddexpand">To use HDFS configuration files: <ol class="ol" id="concept_zx5_yzp_ldb__ol_rb2_2nr_bt">
                            <li class="li">Store the files or a symlink to the files in the <span class="ph">Data Collector</span> resources directory. </li>

                            <li class="li">In the Hadoop FS Standalone origin, configure the
                                    <span class="ph uicontrol">Configuration Files Directory</span> property to
                                specify the location of the files. </li>

                        </ol>
<div class="note note"><span class="notetitle">Note:</span>  For a Cloudera Manager installation, Data Collector
                            automatically creates a symlink to the files named
                                <code class="ph codeph">hadoop-conf</code>. Enter <code class="ph codeph">hadoop-conf</code> for
                            the location of the files in the Hadoop FS Standalone
                        origin.</div>
</dd>

                
                
                    <dt class="dt dlterm">Individual properties</dt>

                    <dd class="dd">You can configure individual HDFS properties in the origin. To add an HDFS
                        property, you specify the exact property name and the value. The Hadoop FS
                        Standalone origin does not validate the property names or
                            values.<div class="note note"><span class="notetitle">Note:</span> Individual properties override properties defined in HDFS
                            configuration files. </div>
</dd>

                
            </dl>
</div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title17" id="concept_ub1_zwp_ldb">
    <h2 class="title topictitle2" id="ariaid-title17">Impersonation User</h2>

    <div class="body conbody">
        <p class="p"><span class="ph"><span class="ph">Data Collector</span>
                        can either use the currently logged in <span class="ph">Data Collector</span> user or a
                        user configured in the</span> Hadoop FS Standalone origin to read from HDFS. </p>

        <p class="p">A <span class="ph">Data Collector</span> configuration property can be set that requires using the currently logged in
                        <span class="ph">Data Collector</span> user. When
                  this property is not set, you can specify a user in the origin. For more
                  information about Hadoop impersonation and the Data Collector property, see <a class="xref" href="../Configuration/DCConfig.html#concept_pmr_sy5_nz">Hadoop Impersonation Mode</a>. </p>

        <p class="p">Note that the origin <span class="ph">uses a different user account to
                        connect to HDFS. <span class="ph" id="concept_ub1_zwp_ldb__d15e4961">By default, <span class="ph">Data Collector</span> uses
                              the user account who started it to connect to external systems. When
                              using Kerberos, <span class="ph">Data Collector</span> uses
                              the Kerberos principal.</span>
                  </span></p>

        <div class="p">To configure a user in the Hadoop FS Standalone origin to read from HDFS, perform the
            following tasks:<ol class="ol" id="concept_ub1_zwp_ldb__ul_mb1_xpt_ls">
                <li class="li">On Hadoop, configure the user as a proxy user and
                              authorize the user to impersonate a Hadoop user. <p class="p">For more
                                    information, see the Hadoop documentation. </p>
</li>

                <li class="li">In the Hadoop FS Standalone origin, on the <span class="keyword wintitle">Connection</span> tab,
                    configure the <span class="ph uicontrol">Impersonation User</span> property.</li>

            </ol>
</div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title18" id="concept_vym_zd3_ldb">
    <h2 class="title topictitle2" id="ariaid-title18">Data Formats</h2>

    <div class="body conbody">
        <div class="p">The
                <span class="ph">Hadoop FS Standalone</span> origin processes data differently based on the data format.
            The origin processes the following types of data:<dl class="dl">
                
                              <dt class="dt dlterm">Avro</dt>

                              <dd class="dd">Generates a record for every Avro record. The origin includes <span class="ph" id="concept_vym_zd3_ldb__d15e1374">the Avro schema in the
                                                <code class="ph codeph">avroSchema</code>
                                          <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz">record header attribute</a></span>. It also
                                    includes <span class="ph" id="concept_vym_zd3_ldb__d15e1382">a
                                                <code class="ph codeph">precision</code> and
                                                <code class="ph codeph">scale</code>
                                          <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed."> field attribute</a> for each Decimal
                                          field.</span></dd>

                              <dd class="dd ddexpand">The origin expects each file to contain the Avro schema and uses
                                    the schema to process the Avro data.</dd>

                              <dd class="dd ddexpand">The origin reads files <span class="ph" id="concept_vym_zd3_ldb__d15e1399">compressed by
                                          Avro-supported compression codecs without requiring
                                          additional configuration.</span></dd>

                        
                
                              <dt class="dt dlterm">Delimited</dt>

                              <dd class="dd">Generates a record for each delimited line. You can use the
                                    following delimited format types:<ul class="ul" id="concept_vym_zd3_ldb__ul_evg_nsl_mcb">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                        <li class="li"><span class="ph uicontrol">Multi Character Delimited</span> - File that uses
                              multiple user-defined characters to delimit fields and lines, and
                              single user-defined escape and quote characters. </li>

                  </ul>
</dd>

                              <dd class="dd ddexpand"><span class="ph">You can use a list or list-map
                                          root field type for delimited data, and optionally include
                                          field names from a header line, when available.</span> For
                                    more information about the root field types, see <a class="xref" href="../Data_Formats/Delimited.html#concept_zcg_bm4_fs">Delimited Data Root Field Type</a>.</dd>

                              <dd class="dd ddexpand"><span class="ph">When using a header line, you
                                          can enable handling records with additional columns. The
                                          additional columns are named using a custom prefix and
                                          integers in sequential increasing order, such as
                                                <code class="ph codeph">_extra_1</code>,
                                          <code class="ph codeph">_extra_2</code>. When you disallow additional
                                          columns, records that include additional columns are sent
                                          to error.</span></dd>

                              <dd class="dd ddexpand"><span class="ph">You can also replace a string
                                          constant with null values.</span></dd>

                              <dd class="dd ddexpand"><span class="ph">When a record exceeds the maximum
                                          record length defined for the stage,</span> the origin
                                          <span class="ph" id="concept_vym_zd3_ldb__d15e1787">cannot continue reading
                                          the file. Records already read from the file are passed to
                                          the pipeline. The behavior of the origin is then based on
                                          the error handling configured for the stage</span>:<ul class="ul" id="concept_vym_zd3_ldb__d15e1790">
                                          <li class="li">Discard - The origin continues processing with the
                                                next file, leaving the partially-processed file in
                                                the directory. </li>

                                          <li class="li">To Error - The origin continues processing with the
                                                next file. If a post-processing error directory is
                                                configured for the stage, the origin moves the
                                                partially-processed file to the error directory.
                                                Otherwise, it leaves the file in the directory.</li>

                                          <li class="li">Stop Pipeline - The origin stops the pipeline. </li>

                                    </ul>
</dd>

                        
                
                              <dt class="dt dlterm">Excel</dt>

                              <dd class="dd">Generates a record for every row in the file. Can process
                                          <code class="ph codeph">.xls</code> or <code class="ph codeph">.xlsx</code>
                                          files.<p class="p">You can specify <span class="ph" id="concept_vym_zd3_ldb__d15e1818"><span class="ph" id="concept_vym_zd3_ldb__d15e1819">whether files include a
                                                  header row and whether to ignore the header row. A
                                                  header row must be the first row of a file.</span>
                                                Vertical header columns are not
                                          recognized.</span></p>
<p class="p">The origin cannot process Excel
                                          files with large numbers of rows. You can save such files
                                          as CSV files in Excel, and then use the origin to process
                                          with the delimited data format.</p>
</dd>

                        
                
                              <dt class="dt dlterm">JSON</dt>

                              <dd class="dd">Generates a record for each JSON object. You can process JSON
                                    files that include multiple JSON objects or a single JSON
                                    array.</dd>

                              <dd class="dd ddexpand">When an object exceeds the maximum object length defined for the
                                    origin, the origin cannot continue processing data in the file.
                                    Records already processed from the file are passed to the
                                    pipeline. The behavior of the origin is then based on the error
                                    handling configured for the stage:<ul class="ul" id="concept_vym_zd3_ldb__d15e1860">
                                          <li class="li">Discard - The origin continues processing with the
                                                next file, leaving the partially-processed file in
                                                the directory. </li>

                                          <li class="li">To Error - The origin continues processing with the
                                                next file. If a post-processing error directory is
                                                configured for the stage, the origin moves the
                                                partially-processed file to the error directory.
                                                Otherwise, it leaves the file in the directory.</li>

                                          <li class="li">Stop Pipeline - The origin stops the pipeline. </li>

                                    </ul>
</dd>

                        
                
                              <dt class="dt dlterm">Log</dt>

                              <dd class="dd">Generates a record for every log line. </dd>

                              <dd class="dd ddexpand">When a line exceeds the user-defined maximum line length, the
                                    origin truncates longer lines. </dd>

                              <dd class="dd ddexpand">You can include the processed log line as a field in the record.
                                    If the log line is truncated, and you request the log line in
                                    the record, the origin includes the truncated line.</dd>

                              <dd class="dd ddexpand">You can define the <a class="xref" href="../Data_Formats/LogFormats.html#concept_tr1_spd_sr" title="When you use an origin to read log data, you define the format of the log files to be read.">log format</a> or type to be read.</dd>

                        
                
                        <dt class="dt dlterm">Protobuf</dt>

                        <dd class="dd">Generates a record for every protobuf message. </dd>

                        <dd class="dd ddexpand">Protobuf messages must match the specified message type and be described
                              in the descriptor file. </dd>

                        <dd class="dd ddexpand">When the data for a record exceeds 1 MB, the origin cannot continue
                              processing data in the file. The origin handles the file based on file
                              error handling properties and continues reading the next file. </dd>

                        <dd class="dd ddexpand">For information about generating the descriptor file, see <a class="xref" href="../Data_Formats/Protobuf-Prerequisites.html" title="Perform the following prerequisites before reading or writing protobuf data.">Protobuf Data Format Prerequisites</a>.</dd>

                  
                
                              <dt class="dt dlterm">SDC Record</dt>

                              <dd class="dd">Generates a record for every record. Use to process records
                                    generated by a <span class="ph">Data Collector</span>
                                    pipeline using the SDC Record data format.</dd>

                              <dd class="dd ddexpand">For error records, the origin provides the original record as read
                                    from the origin in the original pipeline, as well as error
                                    information that you can use to correct the record. </dd>

                              <dd class="dd ddexpand">When processing error records, the origin expects the error file
                                    names and contents as generated by the original pipeline.</dd>

                        
                
                              <dt class="dt dlterm">Text</dt>

                              <dd class="dd">Generates a record for each line of text or for each section of
                                    text based on a custom delimiter.</dd>

                              <dd class="dd ddexpand">When a line or section exceeds the maximum line length defined for
                                    the origin, the origin truncates it. The origin adds a boolean
                                    field named Truncated to indicate if the line was
                                    truncated.</dd>

                              <dd class="dd ddexpand">For more information about processing text with a custom
                                    delimiter, see <a class="xref" href="../Data_Formats/TextCDelim.html#concept_lg2_gcg_jx">Text Data Format with Custom Delimiters</a>.</dd>

                        
                
                              <dt class="dt dlterm">Whole File</dt>

                              <dd class="dd">Streams whole files from the origin system to the destination
                                    system. You can specify a transfer rate or use all available
                                    resources to perform the transfer. </dd>

                              <dd class="dd ddexpand">The origin generates two fields: one for a file reference and one
                                    for file information. For more information, see <a class="xref" href="../Data_Formats/WholeFile.html#concept_nfc_qkh_xw" title="You can use the whole file data format to transfer entire files from an origin system to a destination system. With the whole file data format, you can transfer any type of file.">Whole File Data Format</a>.</dd>

                        
                
                              <dt class="dt dlterm">XML</dt>

                              <dd class="dd">Generates records based on a user-defined delimiter element. Use
                                    an XML element directly under the root element or define a
                                    simplified XPath expression. If you do not define a delimiter
                                    element, the origin treats the XML file as a single record. </dd>

                              <dd class="dd ddexpand">Generated records include XML attributes and namespace
                                    declarations as fields in the record by default. You can
                                    configure the stage to include them in the record as field
                                    attributes. </dd>

                              <dd class="dd ddexpand">You can include XPath information for each parsed XML element and
                                    XML attribute in field attributes. This also places each
                                    namespace in an xmlns record header attribute. </dd>

                              <dd class="dd ddexpand">
                                    <div class="note note"><span class="notetitle">Note:</span> <span class="ph">Field attributes and record header attributes are
                        written to destination systems automatically only when you use the SDC RPC
                        data format in destinations. For more information about working with field
                        attributes and record header attributes, and how to include them in records,
                        see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a> and <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz">Record Header Attributes</a>.</span></div>

                              </dd>

                              <dd class="dd ddexpand">When a record exceeds the user-defined maximum record length, the
                                    origin cannot continue processing data in the file. Records
                                    already processed from the file are passed to the pipeline. The
                                    behavior of the origin is then based on the error handling
                                    configured for the stage:<ul class="ul" id="concept_vym_zd3_ldb__d15e2155">
                                          <li class="li">Discard - The origin continues processing with the
                                                next file, leaving the partially-processed file in
                                                the directory. </li>

                                          <li class="li">To Error - The origin continues processing with the
                                                next file. If a post-processing error directory is
                                                configured for the stage, the origin moves the
                                                partially-processed file to the error directory.
                                                Otherwise, it leaves the file in the directory.</li>

                                          <li class="li">Stop Pipeline - The origin stops the pipeline. </li>

                                    </ul>
</dd>

                              <dd class="dd ddexpand">Use the XML data format to process valid XML documents. For more
                                    information about XML processing, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_lty_42b_dy">Reading and Processing XML Data</a>. <div class="note tip"><span class="tiptitle">Tip:</span> <span class="ph" id="concept_vym_zd3_ldb__d15e2172">If
                                                you want to process invalid XML documents, you can
                                                try using the text data format with custom
                                                delimiters. For more information, see <a class="xref" href="../Data_Formats/TextCDelim.html#concept_okt_kmg_jx">Processing XML Data with Custom Delimiters</a>.</span>
                                    </div>
</dd>

                        
            </dl>
</div>

    </div>

</article>
<article class="topic task nested1" aria-labelledby="ariaid-title19" id="task_l3t_sdm_hdb">
    <h2 class="title topictitle2" id="ariaid-title19">Configuring a Hadoop FS Standalone Origin</h2>

    <div class="body taskbody">
        <section class="section context" id="task_l3t_sdm_hdb__context_wzt_zn3_ldb">Configure a Hadoop FS
            Standalone origin to read files in HDFS.</section>

        <ol class="ol steps" id="task_l3t_sdm_hdb__steps_tvn_b5v_yq"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__table_ac1_hss_5x" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e2742">General Property</th>

                                    <th class="entry cellrowborder" id="d361497e2745">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
              <td class="entry cellrowborder" headers="d361497e2742 ">Name</td>

              <td class="entry cellrowborder" headers="d361497e2745 ">Stage name.</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e2742 ">Description</td>

              <td class="entry cellrowborder" headers="d361497e2745 ">Optional description.</td>

            </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2742 "><a class="xref" href="HDFSStandalone.html#concept_zlx_5rh_ldb">Produce
                                        Events</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2745 ">Generates event records when events occur. Use for
                  <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">event handling</a>.</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e2742 "><a class="xref" href="../Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r">On Record Error</a></td>

              <td class="entry cellrowborder" headers="d361497e2745 ">Error record handling for the stage: <ul class="ul" id="task_l3t_sdm_hdb__d31e808">
                  <li class="li">Discard - Discards the record.</li>

                  <li class="li">Send to Error - Sends the record to the pipeline for error handling.</li>

                  <li class="li">Stop Pipeline - Stops the pipeline. </li>

                </ul>
</td>

            </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Connection</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__table_rst_t4d_br" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:33.33333333333333%" /><col style="width:66.66666666666666%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e2834">Connection Property</th>

                                    <th class="entry cellrowborder" id="d361497e2837">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                            <td class="entry cellrowborder" headers="d361497e2834 ">File System URI</td>

                            <td class="entry cellrowborder" headers="d361497e2837 ">Optional HDFS URI. <p class="p" id="task_l3t_sdm_hdb__d273e500">When not configured,
                                    the stage uses the URI defined by the fs.defaultFS property in
                                    the core-site.xml file. </p>
</td>

                        </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2834 "><a class="xref" href="HDFSStandalone.html#concept_ub1_zwp_ldb">Impersonation
                                            User</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2837 ">The HDFS user to impersonate to access HDFS.
                                When using this property, make sure HDFS is configured
                                    appropriately.<p class="p">When not configured, the pipeline uses the
                                    currently logged in <span class="ph">Data Collector</span> user. </p>
<p class="p">Not configurable when <span class="ph">Data Collector</span> is configured to use the currently logged in <span class="ph">Data Collector</span> user. <span class="ph">For more information, see <a class="xref" href="../Configuration/DCConfig.html#concept_pmr_sy5_nz">Hadoop Impersonation Mode</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2834 "><a class="xref" href="HDFSStandalone.html#concept_vvd_4zp_ldb">Kerberos
                                            Authentication </a></td>

                                    <td class="entry cellrowborder" headers="d361497e2837 ">Uses Kerberos credentials to connect to HDFS.
                                    <p class="p">When selected, uses the Kerberos principal and keytab defined
                                    in the <span class="ph">Data Collector</span> configuration file,
                                    <code class="ph codeph">$SDC_CONF/sdc.properties</code>. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2834 "><a class="xref" href="HDFSStandalone.html#concept_zx5_yzp_ldb">Configuration Files Directory</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2837 ">Location of the HDFS configuration
                                    files.<p class="p">For a Cloudera Manager installation, enter
                                        <code class="ph codeph">hadoop-conf</code>. For all other installations,
                                    use a directory or symlink within the <span class="ph">Data Collector</span> resources directory.</p>
<div class="p">You can use the following
                                    configuration files:<ul class="ul" id="task_l3t_sdm_hdb__ul_qnc_jtt_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                  </ul>
</div>
<div class="note note"><span class="notetitle">Note:</span> Properties in the configuration files are
                                    overridden by individual properties defined in the
                                stage.</div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2834 "><a class="xref" href="HDFSStandalone.html#concept_zx5_yzp_ldb">Additional Configuration</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2837 ">Additional HDFS properties to pass to
                                HDFS. These properties take precedence over properties defined in
                                Hadoop configuration files.<p class="p">To add properties, click
                                        <span class="ph uicontrol">Add</span> and define the property name and
                                    value. Use the property names and values as expected by
                                    HDFS.</p>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Files</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__table_tm4_vck_5q" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:27.77777777777778%" /><col style="width:72.22222222222221%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e2978">Files Property</th>

                                    <th class="entry cellrowborder" id="d361497e2981">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 "><a class="xref" href="HDFSStandalone.html#concept_wcp_zxk_1hb">Files
                                        Directory</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2981 ">The HDFS directory where source files are stored. Enter
                                        an absolute path. Use a glob pattern to specify multiple
                                        directories.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 ">
                                        <a class="xref" href="HDFSStandalone.html#concept_fgx_1jh_ldb" title="The Hadoop FS Standalone origin uses multiple concurrent threads to process data based on the Number of Threads property.">Number of
                                            Threads</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2981 "><span class="ph" id="task_l3t_sdm_hdb__d273e178">Number of threads
                                    the origin generates and uses for multithreaded processing.
                                    Default is 1. </span></td>

                                </tr>

                                <tr>
                            <td class="entry cellrowborder" headers="d361497e2978 ">File Name Pattern Mode</td>

                            <td class="entry cellrowborder" headers="d361497e2981 ">Syntax of the file name pattern:<ul class="ul" id="task_l3t_sdm_hdb__d273e189">
                                    <li class="li">Glob</li>

                                    <li class="li">Regular Expression</li>

                                </ul>
</td>

                        </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 ">
                                        <a class="xref" href="HDFSStandalone.html#concept_exc_22h_ldb" title="Use a file name pattern to define the files that the Hadoop FS Standalone origin processes. You can use either a glob pattern or a regular expression to define the file name pattern.">File Name
                                            Pattern</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2981 ">Pattern of the file names to process.
                                Use glob patterns or regular expressions based on the specified file
                                name pattern mode. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 ">
                                        <a class="xref" href="HDFSStandalone.html#concept_ogz_q3h_ldb">Read Order</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2981 ">The order to use when reading
                                    files:<ul class="ul" id="task_l3t_sdm_hdb__d273e243">
                                    <li class="li">Last-Modified Timestamp - Reads files in ascending order
                                        based on the last-modified timestamp. When files have
                                        matching timestamps, reads files in lexicographically
                                        ascending order based on file names.</li>

                                    <li class="li">Lexicographically Ascending File Names - Reads files in
                                        lexicographically ascending order based on file name.</li>

                                </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 ">
                                        <a class="xref" href="HDFSStandalone.html#concept_bwq_nyj_mdb" title="When using the Last Modified Timestamp read order, the Hadoop FS Standalone origin can read files in subdirectories of the specified file directory.">Process
                                            Subdirectories</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2981 ">Reads files in any subdirectory
                                of the specified file directory. Reads files in ascending order
                                based on the last-modified timestamp, regardless of the location
                                within the file directory. <p class="p">Uses the subdirectory for any
                                    configured post-processing directories.</p>
<p class="p">Available only
                                    when using the Last Modified Timestamp read order. </p>
</td>

                                </tr>

                                <tr>
                            <td class="entry cellrowborder" headers="d361497e2978 ">Batch Size (recs)</td>

                            <td class="entry cellrowborder" headers="d361497e2981 ">Number of records to pass through the pipeline at one time.
                                Honors values up to the <span class="ph">Data Collector</span> maximum batch size. <p class="p">Default is 1000. The <span class="ph">Data Collector</span> default is 1000.</p>
</td>

                        </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 ">
                                        <a class="xref" href="Origins_overview.html#concept_ypd_vgr_5q">Batch
                                            Wait Time (secs)</a></td>

                                    <td class="entry cellrowborder" headers="d361497e2981 ">Number of seconds to wait before sending
                                a partial or empty batch.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 "><a class="xref" href="HDFSStandalone.html#concept_a2q_4kh_ldb" title="Configure a first file for processing when you want the Hadoop FS Standalone origin to ignore one or more existing files in the directory.">First File to
                                            Process</a>
                                    </td>

                                    <td class="entry cellrowborder" headers="d361497e2981 ">Name of the first file to process.
                                    <p class="p">When you do not enter a first file name, the origin reads all
                                    files in the directory with the specified file name
                                pattern.</p>
</td>

                                </tr>

                                <tr>
                            <td class="entry cellrowborder" headers="d361497e2978 ">Max Files Soft Limit </td>

                            <td class="entry cellrowborder" headers="d361497e2981 ">Maximum number of files that the origin can add to the processing
                                queue at one time. This value is a soft limit - meaning that the
                                origin can temporarily exceed it. <p class="p">If the origin exceeds this soft
                                    limit, the origin starts the spooling period timer. If the
                                    number of files in the processing queue goes below the soft
                                    limit, the origin adds more files from the directory to the
                                    queue. If the number of files in the processing queue remains
                                    above the soft limit after the configured spooling period
                                    expires, no more files are added to the queue until the queue
                                    goes below the soft limit.</p>
<p class="p">Configure the soft limit to the
                                    expected maximum number of files in the directory.</p>
<p class="p">Default
                                    is 1000.</p>
</td>

                        </tr>

                                <tr>
                            <td class="entry cellrowborder" headers="d361497e2978 ">Spooling Period (secs)</td>

                            <td class="entry cellrowborder" headers="d361497e2981 ">Number of seconds to continue adding files to the processing
                                queue after the maximum files soft limit has been exceeded. When the
                                spooling period expires, no additional files are added to the
                                processing queue until the queue goes below the soft
                                    limit.<p class="p">Default is 5 seconds.</p>
</td>

                        </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e2978 ">
                                        <a class="xref" href="HDFSStandalone.html#concept_jbn_md3_ldb" title="The Hadoop FS Standalone origin passes each record to a buffer. The size of the buffer determines the maximum size of the record that can be processed. Decrease the buffer limit when memory on the Data Collector machine is limited. Increase the buffer limit to process larger records when memory is available.">Buffer Limit (KB)</a>
                                    </td>

                                    <td class="entry cellrowborder" headers="d361497e2981 ">Maximum buffer size. The buffer size
                                determines the size of the record that can be processed. <p class="p">Decrease
                                    when memory on the <span class="ph">Data Collector</span> machine is limited. Increase to process larger records when
                                    memory is available. </p>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Post Processing</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__table_eqz_brp_ldb" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:22.22222222222222%" /><col style="width:77.77777777777779%" /></colgroup><thead class="thead" style="text-align:left;">
                        <tr>
                            <th class="entry cellrowborder" id="d361497e3230">Post Processing Property</th>

                            <th class="entry cellrowborder" id="d361497e3233">Description</th>

                        </tr>

                    </thead>
<tbody class="tbody">
                        <tr>
                            <td class="entry cellrowborder" headers="d361497e3230 ">Error Directory</td>

                            <td class="entry cellrowborder" headers="d361497e3233 ">The directory for files that cannot be fully processed due to
                                data handling errors. <p class="p">When you specify an error directory, files
                                    that cannot be fully processed are moved to this directory.
                                    </p>
<p class="p">Use to manage files for error handling and reprocessing.
                                </p>
</td>

                        </tr>

                        <tr id="task_l3t_sdm_hdb__d273e422">
                            <td class="entry cellrowborder" headers="d361497e3230 ">File Post Processing</td>

                            <td class="entry cellrowborder" headers="d361497e3233 ">The action taken after processing a file: <ul class="ul" id="task_l3t_sdm_hdb__d273e429">
                                    <li class="li">None - Keeps the file in place.</li>

                                    <li class="li">Archive - Moves the file to the archive directory.</li>

                                    <li class="li">Delete - Deletes the file.</li>

                                </ul>
</td>

                        </tr>

                        <tr id="task_l3t_sdm_hdb__d273e442">
                            <td class="entry cellrowborder" headers="d361497e3230 ">Archive Directory</td>

                            <td class="entry cellrowborder" headers="d361497e3233 ">The directory for files that are fully processed. <p class="p">When you
                                    specify an archive directory, files are moved to this directory
                                    after being fully processed.</p>
Use to archive processed
                                files.</td>

                        </tr>

                        <tr>
                            <td class="entry cellrowborder" headers="d361497e3230 ">Archive Retention Time (mins)</td>

                            <td class="entry cellrowborder" headers="d361497e3233 ">Number of minutes processed files are saved in the archive
                                directory. Use 0 to keep archived files indefinitely.</td>

                        </tr>

                    </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Data Format</span> tab, configure the following
                    property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__table_hvy_pt3_vx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e3321">Data Format Property</th>

                                    <th class="entry cellrowborder" id="d361497e3324">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e3321 "><a class="xref" href="HDFSStandalone.html#concept_vym_zd3_ldb">Data Format</a>
                                    </td>

                                    <td class="entry cellrowborder" headers="d361497e3324 ">Data format for source files. Use one of the following
                  formats:<ul class="ul" id="task_l3t_sdm_hdb__d31e1792">
                  <li class="li">Avro</li>

                  <li class="li">Delimited</li>

                  <li class="li">Excel</li>

                  <li class="li">JSON</li>

                  <li class="li">Log</li>

                  <li class="li">Protobuf</li>

                  <li class="li"><a class="xref" href="../Data_Formats/SDCRecordFormat.html#concept_qkk_mwk_br" title="SDC Record is a proprietary data format that Data Collector uses to generate error records. Data Collector can also use the data format to read and write data.">SDC Record</a></li>

                  <li class="li">Text</li>

                  <li class="li"><a class="xref" href="../Data_Formats/WholeFile.html#concept_nfc_qkh_xw" title="You can use the whole file data format to transfer entire files from an origin system to a destination system. With the whole file data format, you can transfer any type of file.">Whole File</a></li>

                  <li class="li">XML</li>

                </ul>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For delimited data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e2024" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e3420">Delimited Property</th>

                                    <th class="entry cellrowborder" id="d361497e3423">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr id="task_l3t_sdm_hdb__d23e2046">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Delimiter Format Type</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Delimiter format type. Use one of the following options:
                                            <ul class="ul" id="task_l3t_sdm_hdb__ul_s5z_b3z_3r">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                        <li class="li"><span class="ph uicontrol">Multi Character Delimited</span> - File that uses
                              multiple user-defined characters to delimit fields and lines, and
                              single user-defined escape and quote characters. </li>

                  </ul>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2059">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Header Line</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Indicates whether a file contains a header line, and
                                        whether to use the header line.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2068">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Delimiter Character</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Delimiter character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                            character.<p class="p">You can enter a Unicode control character
                                            using the format <kbd class="ph userinput">\uNNNN</kbd>, where
                                                <em class="ph i">N</em> is a hexadecimal digit from the numbers
                                            0-9 or the letters A-F. For example, enter
                                                <kbd class="ph userinput">\u0000</kbd> to use the null
                                            character as the delimiter or
                                                <kbd class="ph userinput">\u2028</kbd> to use a line
                                            separator as the delimiter.</p>
<p class="p">Default is the pipe
                                            character ( | ).</p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2093">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Multi Character Field Delimiter</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Characters that delimit fields for multi-character
                                        delimiter format.<p class="p">Default is two pipe characters
                                        (||).</p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2104">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Multi Character Line Delimiter</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Characters that delimit lines or records for
                                        multi-character delimiter format.<p class="p">Default is the newline
                                            character (\n).</p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2116">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Escape Character</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Escape character for a custom or multi-character
                                        delimiter format.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2125">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Quote Character</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Quote character for a custom or multi-character delimiter
                                        format.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2134">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Enable Comments</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Allows commented data to be ignored for custom delimiter
                                        format.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2143">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Comment Marker</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Character that marks a comment when comments are enabled
                                        for custom delimiter format.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2152">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Lines to Skip</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Number of lines to skip before reading data. </td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3420 "><a class="xref" href="../Data_Formats/DataFormats-Overview.html#concept_uxr_g52_qs" title="Origins and processors that read files can read uncompressed files, compressed files, archives, and compressed archives.">Compression Format </a></td>

              <td class="entry cellrowborder" headers="d361497e3423 ">The compression format of the files:<ul class="ul" id="task_l3t_sdm_hdb__d31e1653">
                  <li class="li">None - Processes only uncompressed files.</li>

                  <li class="li">Compressed File - Processes files compressed by the supported compression
                    formats.</li>

                  <li class="li">Archive - Processes files archived by the supported archive formats.</li>

                  <li class="li">Compressed Archive - Processes files archived and compressed by the supported
                    archive and compression formats.</li>

                </ul>
</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3420 ">File Name Pattern within Compressed Directory</td>

              <td class="entry cellrowborder" headers="d361497e3423 ">For archive and compressed archive files, file name pattern that represents the
                files to process within the compressed directory. You can use UNIX-style wildcards,
                such as an asterisk or question mark. For example, *.json.<p class="p">Default is *, which
                  processes all files.</p>
</td>

            </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2172">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Allow Extra Columns</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">When processing data with a header line, allows
                                        processing records with more columns than exist in the
                                        header line.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2181">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Extra Column Prefix</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Prefix to use for any additional columns. Extra columns
                                        are named using the prefix and sequential increasing
                                        integers as follows:
                                            <code class="ph codeph">&lt;prefix&gt;&lt;integer&gt;</code>. <p class="p">For
                                            example, <code class="ph codeph">_extra_1</code>. Default is
                                                <code class="ph codeph">_extra_</code>.</p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2201">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Max Record Length (chars)</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Maximum length of a record in characters. Longer records
                                        are not read. <p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2212">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Ignore Empty Lines</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Allows empty lines to be ignored for custom delimiter
                                        format.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2221">
                                    <td class="entry cellrowborder" headers="d361497e3420 "><a class="xref" href="../Data_Formats/Delimited.html#concept_zcg_bm4_fs">Root Field Type</a></td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Root field type to use:<ul class="ul" id="task_l3t_sdm_hdb__d23e2229">
                                            <li class="li">List-Map - Generates an indexed list of data.
                                                Enables you to use standard functions to process
                                                data. Use for new pipelines.</li>

                                            <li class="li">List - Generates a record with an indexed list with
                                                a map for header and value. Requires the use of
                                                delimited data functions to process data. Use only
                                                to maintain pipelines created before 1.1.0.</li>

                                        </ul>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2240">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">Parse NULLs</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">Replaces the specified string constant with null
                                        values.</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2249">
                                    <td class="entry cellrowborder" headers="d361497e3420 ">NULL Constant</td>

                                    <td class="entry cellrowborder" headers="d361497e3423 ">String constant to replace with null values.</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3420 ">Charset</td>

              <td class="entry cellrowborder" headers="d361497e3423 ">Character encoding of the files to be processed.</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3420 "><a class="xref" href="../Pipeline_Design/ControlCharacters.html#concept_hfs_dkm_js" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">Ignore Control Characters</a></td>

              <td class="entry cellrowborder" headers="d361497e3423 ">Removes all ASCII control characters except for the tab, line feed, and
                carriage return characters.</td>

            </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For Excel files, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e2562" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" style="text-align:left;" id="d361497e3774">Excel Property</th>

                                    <th class="entry cellrowborder" style="text-align:left;" id="d361497e3777">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" style="text-align:left;" headers="d361497e3774 "><a class="xref" href="../Data_Formats/Excel.html">Excel Header Option</a></td>

                                    <td class="entry cellrowborder" style="text-align:left;" headers="d361497e3777 ">Indicates <span class="ph">whether files include a
                                                  header row and whether to ignore the header row. A
                                                  header row must be the first row of a file.</span></td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For JSON data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e2621" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e3824">JSON Property</th>

                                    <th class="entry cellrowborder" id="d361497e3827">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr id="task_l3t_sdm_hdb__d23e2643">
                                    <td class="entry cellrowborder" headers="d361497e3824 ">JSON Content</td>

                                    <td class="entry cellrowborder" headers="d361497e3827 ">Type of JSON content. Use one of the following options: <div class="p">
                                            <ul class="ul" id="task_l3t_sdm_hdb__d23e2652">
                                                <li class="li">Array of Objects </li>

                                                <li class="li">Multiple Objects</li>

                                            </ul>

                                        </div>
</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3824 "><a class="xref" href="../Data_Formats/DataFormats-Overview.html#concept_uxr_g52_qs" title="Origins and processors that read files can read uncompressed files, compressed files, archives, and compressed archives.">Compression Format </a></td>

              <td class="entry cellrowborder" headers="d361497e3827 ">The compression format of the files:<ul class="ul" id="task_l3t_sdm_hdb__d31e1653">
                  <li class="li">None - Processes only uncompressed files.</li>

                  <li class="li">Compressed File - Processes files compressed by the supported compression
                    formats.</li>

                  <li class="li">Archive - Processes files archived by the supported archive formats.</li>

                  <li class="li">Compressed Archive - Processes files archived and compressed by the supported
                    archive and compression formats.</li>

                </ul>
</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3824 ">File Name Pattern within Compressed Directory</td>

              <td class="entry cellrowborder" headers="d361497e3827 ">For archive and compressed archive files, file name pattern that represents the
                files to process within the compressed directory. You can use UNIX-style wildcards,
                such as an asterisk or question mark. For example, *.json.<p class="p">Default is *, which
                  processes all files.</p>
</td>

            </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2673">
                                    <td class="entry cellrowborder" headers="d361497e3824 ">Max Object Length (chars)</td>

                                    <td class="entry cellrowborder" headers="d361497e3827 ">Maximum number of characters in a JSON object. <p class="p">Longer
                                            objects are diverted to the pipeline for error handling.
                                                </p>
<p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3824 ">Charset</td>

              <td class="entry cellrowborder" headers="d361497e3827 ">Character encoding of the files to be processed.</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3824 "><a class="xref" href="../Pipeline_Design/ControlCharacters.html#concept_hfs_dkm_js" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">Ignore Control Characters</a></td>

              <td class="entry cellrowborder" headers="d361497e3827 ">Removes all ASCII control characters except for the tab, line feed, and
                carriage return characters.</td>

            </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For log data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e2835" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e3965">Log Property</th>

                                    <th class="entry cellrowborder" id="d361497e3968">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr id="task_l3t_sdm_hdb__d23e2857">
                                    <td class="entry cellrowborder" headers="d361497e3965 "><a class="xref" href="../Data_Formats/LogFormats.html" title="When you use an origin to read log data, you define the format of the log files to be read.">Log Format</a></td>

                                    <td class="entry cellrowborder" headers="d361497e3968 ">Format of the log files. Use one of the following
                                            options:<ul class="ul" id="task_l3t_sdm_hdb__d23e2865">
                                            <li class="li">Common Log Format</li>

                                            <li class="li">Combined Log Format</li>

                                            <li class="li">Apache Error Log Format</li>

                                            <li class="li">Apache Access Log Custom Format</li>

                                            <li class="li">Regular Expression</li>

                                            <li class="li">Grok Pattern</li>

                                            <li class="li">Log4j</li>

                                            <li class="li">Common Event Format (CEF)</li>

                                            <li class="li">Log Event Extended Format (LEEF)</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3965 "><a class="xref" href="../Data_Formats/DataFormats-Overview.html#concept_uxr_g52_qs" title="Origins and processors that read files can read uncompressed files, compressed files, archives, and compressed archives.">Compression Format </a></td>

              <td class="entry cellrowborder" headers="d361497e3968 ">The compression format of the files:<ul class="ul" id="task_l3t_sdm_hdb__d31e1653">
                  <li class="li">None - Processes only uncompressed files.</li>

                  <li class="li">Compressed File - Processes files compressed by the supported compression
                    formats.</li>

                  <li class="li">Archive - Processes files archived by the supported archive formats.</li>

                  <li class="li">Compressed Archive - Processes files archived and compressed by the supported
                    archive and compression formats.</li>

                </ul>
</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3965 ">File Name Pattern within Compressed Directory</td>

              <td class="entry cellrowborder" headers="d361497e3968 ">For archive and compressed archive files, file name pattern that represents the
                files to process within the compressed directory. You can use UNIX-style wildcards,
                such as an asterisk or question mark. For example, *.json.<p class="p">Default is *, which
                  processes all files.</p>
</td>

            </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2907">
                                    <td class="entry cellrowborder" headers="d361497e3965 ">Max Line Length</td>

                                    <td class="entry cellrowborder" headers="d361497e3968 ">Maximum length of a log line. The origin truncates longer
                                        lines. <p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e2918">
                                    <td class="entry cellrowborder" headers="d361497e3965 ">Retain Original Line</td>

                                    <td class="entry cellrowborder" headers="d361497e3968 ">Determines how to treat the original log line. Select to
                                        include the original log line as a field in the resulting
                                            record.<p class="p">By default, the original line is
                                            discarded.</p>
</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3965 ">Charset</td>

              <td class="entry cellrowborder" headers="d361497e3968 ">Character encoding of the files to be processed.</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e3965 "><a class="xref" href="../Pipeline_Design/ControlCharacters.html#concept_hfs_dkm_js" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">Ignore Control Characters</a></td>

              <td class="entry cellrowborder" headers="d361497e3968 ">Removes all ASCII control characters except for the tab, line feed, and
                carriage return characters.</td>

            </tr>

                            </tbody>
</table>
</div>

                    <ul class="ul" id="task_l3t_sdm_hdb__d23e2943">
                        <li class="li">When you select <span class="ph uicontrol">Apache Access Log Custom Format</span>,
                            use Apache log format strings to define the <span class="ph uicontrol">Custom Log
                                Format</span>.</li>

                        <li class="li">When you select <span class="ph uicontrol">Regular Expression</span>, enter the
                            regular expression that describes the log format, and then map the
                            fields that you want to include to each regular expression group.</li>

                        <li class="li">When you select <span class="ph uicontrol">Grok Pattern</span>, you can use the
                                <span class="ph uicontrol">Grok Pattern Definition</span> field to define
                            custom grok patterns. You can define a pattern on each line. <p class="p">In the
                                    <span class="ph uicontrol">Grok Pattern</span> field, enter the pattern to
                                use to parse the log. You can use a predefined grok patterns or
                                create a custom grok pattern using patterns defined in
                                    <span class="ph uicontrol">Grok Pattern Definition</span>.</p>
<p class="p">For more
                                information about defining grok patterns and supported grok
                                patterns, see <a class="xref" href="../Apx-GrokPatterns/GrokPatterns_title.html#concept_vdk_xjb_wr" title="You can use the grok patterns in this appendix to define the structure of log data.">Defining Grok Patterns</a>.</p>
</li>

                        <li class="li">When you select <span class="ph uicontrol">Log4j</span>, define the following properties:<div class="p">
                                
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e2988" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:22.22222222222222%" /><col style="width:77.77777777777779%" /></colgroup><thead class="thead" style="text-align:left;">
                                            <tr>
                                                <th class="entry cellrowborder" id="d361497e4177">Log4j Property</th>

                                                <th class="entry cellrowborder" id="d361497e4180">Description</th>

                                            </tr>

                                        </thead>
<tbody class="tbody">
                                            <tr>
                                                <td class="entry cellrowborder" headers="d361497e4177 ">On Parse Error</td>

                                                <td class="entry cellrowborder" headers="d361497e4180 ">Determines how to handle information that
                                                  cannot be parsed:<ul class="ul" id="task_l3t_sdm_hdb__d23e3017">
                                                  <li class="li">Skip and Log Error - Skips reading the line
                                                  and logs a stage error.</li>

                                                  <li class="li">Skip, No Error - Skips reading the line and
                                                  does not log an error.</li>

                                                  <li class="li">Include as Stack Trace - Includes information
                                                  that cannot be parsed as a stack trace to the
                                                  previously-read log line. The information is added
                                                  to the message field for the last valid log
                                                  line.</li>

                                                  </ul>
</td>

                                            </tr>

                                            <tr>
                                                <td class="entry cellrowborder" headers="d361497e4177 ">Use Custom Log Format</td>

                                                <td class="entry cellrowborder" headers="d361497e4180 ">Allows you to define a custom log
                                                  format.</td>

                                            </tr>

                                            <tr>
                                                <td class="entry cellrowborder" headers="d361497e4177 ">Custom Log4J Format</td>

                                                <td class="entry cellrowborder" headers="d361497e4180 ">Use log4j variables to define a custom log
                                                  format. </td>

                                            </tr>

                                        </tbody>
</table>
</div>

                            </div>
</li>

                    </ul>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For protobuf data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e3187" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e4254">Protobuf Property</th>

                                    <th class="entry cellrowborder" id="d361497e4257">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e4254 ">Protobuf Descriptor File </td>

                                    <td class="entry cellrowborder" headers="d361497e4257 ">Descriptor file (.desc) to use. The descriptor file must
                                        be in the <span class="ph">Data Collector</span> resources directory, <code class="ph codeph">$SDC_RESOURCES</code>.
                                                <p class="p"><span class="ph">For more information about environment variables, see
                              <a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_rng_qym_qr">Data Collector Environment Configuration</a>.</span> For information about generating the descriptor file,
                                            see <a class="xref" href="../Data_Formats/Protobuf-Prerequisites.html" title="Perform the following prerequisites before reading or writing protobuf data.">Protobuf Data Format Prerequisites</a>.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e4254 ">Message Type</td>

                                    <td class="entry cellrowborder" headers="d361497e4257 ">The fully-qualified name for the message type to use when
                                        reading data.<p class="p">Use the following format:
                                                <code class="ph codeph">&lt;package name&gt;.&lt;message
                                            type&gt;</code>. </p>
Use a message type defined in the
                                        descriptor file.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e4254 ">Delimited Messages</td>

                                    <td class="entry cellrowborder" headers="d361497e4257 ">Indicates if a file might include more than one protobuf
                                        message.</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4254 "><a class="xref" href="../Data_Formats/DataFormats-Overview.html#concept_uxr_g52_qs" title="Origins and processors that read files can read uncompressed files, compressed files, archives, and compressed archives.">Compression Format </a></td>

              <td class="entry cellrowborder" headers="d361497e4257 ">The compression format of the files:<ul class="ul" id="task_l3t_sdm_hdb__d31e1653">
                  <li class="li">None - Processes only uncompressed files.</li>

                  <li class="li">Compressed File - Processes files compressed by the supported compression
                    formats.</li>

                  <li class="li">Archive - Processes files archived by the supported archive formats.</li>

                  <li class="li">Compressed Archive - Processes files archived and compressed by the supported
                    archive and compression formats.</li>

                </ul>
</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4254 ">File Name Pattern within Compressed Directory</td>

              <td class="entry cellrowborder" headers="d361497e4257 ">For archive and compressed archive files, file name pattern that represents the
                files to process within the compressed directory. You can use UNIX-style wildcards,
                such as an asterisk or question mark. For example, *.json.<p class="p">Default is *, which
                  processes all files.</p>
</td>

            </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For SDC Record data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e3288" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e4384">SDC Record Property</th>

                                    <th class="entry cellrowborder" id="d361497e4387">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
              <td class="entry cellrowborder" headers="d361497e4384 "><a class="xref" href="../Data_Formats/DataFormats-Overview.html#concept_uxr_g52_qs" title="Origins and processors that read files can read uncompressed files, compressed files, archives, and compressed archives.">Compression Format </a></td>

              <td class="entry cellrowborder" headers="d361497e4387 ">The compression format of the files:<ul class="ul" id="task_l3t_sdm_hdb__d31e1653">
                  <li class="li">None - Processes only uncompressed files.</li>

                  <li class="li">Compressed File - Processes files compressed by the supported compression
                    formats.</li>

                  <li class="li">Archive - Processes files archived by the supported archive formats.</li>

                  <li class="li">Compressed Archive - Processes files archived and compressed by the supported
                    archive and compression formats.</li>

                </ul>
</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4384 ">File Name Pattern within Compressed Directory</td>

              <td class="entry cellrowborder" headers="d361497e4387 ">For archive and compressed archive files, file name pattern that represents the
                files to process within the compressed directory. You can use UNIX-style wildcards,
                such as an asterisk or question mark. For example, *.json.<p class="p">Default is *, which
                  processes all files.</p>
</td>

            </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For text data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e3495" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e4461">Text Property</th>

                                    <th class="entry cellrowborder" id="d361497e4464">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
              <td class="entry cellrowborder" headers="d361497e4461 "><a class="xref" href="../Data_Formats/DataFormats-Overview.html#concept_uxr_g52_qs" title="Origins and processors that read files can read uncompressed files, compressed files, archives, and compressed archives.">Compression Format </a></td>

              <td class="entry cellrowborder" headers="d361497e4464 ">The compression format of the files:<ul class="ul" id="task_l3t_sdm_hdb__d31e1653">
                  <li class="li">None - Processes only uncompressed files.</li>

                  <li class="li">Compressed File - Processes files compressed by the supported compression
                    formats.</li>

                  <li class="li">Archive - Processes files archived by the supported archive formats.</li>

                  <li class="li">Compressed Archive - Processes files archived and compressed by the supported
                    archive and compression formats.</li>

                </ul>
</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4461 ">File Name Pattern within Compressed Directory</td>

              <td class="entry cellrowborder" headers="d361497e4464 ">For archive and compressed archive files, file name pattern that represents the
                files to process within the compressed directory. You can use UNIX-style wildcards,
                such as an asterisk or question mark. For example, *.json.<p class="p">Default is *, which
                  processes all files.</p>
</td>

            </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3527">
                                    <td class="entry cellrowborder" headers="d361497e4461 ">Max Line Length</td>

                                    <td class="entry cellrowborder" headers="d361497e4464 ">Maximum number of characters allowed for a line. Longer
                                        lines are truncated.<p class="p">Adds a boolean field to the record to
                                            indicate if it was truncated. The field name is
                                            Truncated. </p>
<p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3540">
                                    <td class="entry cellrowborder" headers="d361497e4461 "><a class="xref" href="../Data_Formats/TextCDelim.html#concept_lg2_gcg_jx">Use Custom Delimiter</a></td>

                                    <td class="entry cellrowborder" headers="d361497e4464 ">Uses custom delimiters to define records instead of line
                                        breaks. </td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3550">
                                    <td class="entry cellrowborder" headers="d361497e4461 ">Custom Delimiter</td>

                                    <td class="entry cellrowborder" headers="d361497e4464 ">One or more characters to use to define records. </td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3560">
                                    <td class="entry cellrowborder" headers="d361497e4461 ">Include Custom Delimiter</td>

                                    <td class="entry cellrowborder" headers="d361497e4464 ">Includes delimiter characters in the record.</td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4461 ">Charset</td>

              <td class="entry cellrowborder" headers="d361497e4464 ">Character encoding of the files to be processed.</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4461 "><a class="xref" href="../Pipeline_Design/ControlCharacters.html#concept_hfs_dkm_js" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">Ignore Control Characters</a></td>

              <td class="entry cellrowborder" headers="d361497e4464 ">Removes all ASCII control characters except for the tab, line feed, and
                carriage return characters.</td>

            </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For whole files, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e3716" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e4611">Whole File Property</th>

                                    <th class="entry cellrowborder" id="d361497e4614">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e4611 ">Buffer Size (bytes)</td>

                                    <td class="entry cellrowborder" headers="d361497e4614 ">Size of the buffer to use to transfer data.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d361497e4611 "><a class="xref" href="../Data_Formats/WholeFile.html#concept_prp_jzd_py">Rate per Second</a></td>

                                    <td class="entry cellrowborder" headers="d361497e4614 ">Transfer rate to use. <p class="p">Enter a number to specify a rate
                                            in bytes per second. Use an expression to specify a rate
                                            that uses a different unit of measure per second, e.g.
                                            ${5 * MB}. Use -1 to opt out of this property. </p>
<p class="p">By
                                            default, the origin does not use a transfer rate.
                                        </p>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For XML data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_l3t_sdm_hdb__d23e3868" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d361497e4672">XML Property</th>

                                    <th class="entry cellrowborder" id="d361497e4675">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr id="task_l3t_sdm_hdb__d23e3890">
                                    <td class="entry cellrowborder" headers="d361497e4672 "><a class="xref" href="../Data_Formats/XMLDFormat.html#concept_tmc_4bc_dy">Delimiter Element</a></td>

                                    <td class="entry cellrowborder" headers="d361497e4675 ">
                                        <div class="p">Delimiter to use to generate records. Omit a delimiter to
                                            treat the entire XML document as one record. Use one of
                                            the following:<ul class="ul" id="task_l3t_sdm_hdb__d23e3900">
                                                <li class="li">An XML element directly under the root element.
                                                  <p class="p">Use the XML element name without surrounding
                                                  angle brackets ( &lt; &gt; ) . For example, msg
                                                  instead of &lt;msg&gt;. </p>
</li>

                                                <li class="li">A simplified XPath expression that specifies the
                                                  data to use.<p class="p">Use a simplified XPath expression
                                                  to access data deeper in the XML document or data
                                                  that requires a more complex access
                                                  method.</p>
<p class="p">For more information about valid
                                                  syntax, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_tmc_4bc_dy">Simplified XPath Syntax</a>.</p>
</li>

                                            </ul>
</div>

                                    </td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4672 "><a class="xref" href="../Data_Formats/DataFormats-Overview.html#concept_uxr_g52_qs" title="Origins and processors that read files can read uncompressed files, compressed files, archives, and compressed archives.">Compression Format </a></td>

              <td class="entry cellrowborder" headers="d361497e4675 ">The compression format of the files:<ul class="ul" id="task_l3t_sdm_hdb__d31e1653">
                  <li class="li">None - Processes only uncompressed files.</li>

                  <li class="li">Compressed File - Processes files compressed by the supported compression
                    formats.</li>

                  <li class="li">Archive - Processes files archived by the supported archive formats.</li>

                  <li class="li">Compressed Archive - Processes files archived and compressed by the supported
                    archive and compression formats.</li>

                </ul>
</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4672 ">File Name Pattern within Compressed Directory</td>

              <td class="entry cellrowborder" headers="d361497e4675 ">For archive and compressed archive files, file name pattern that represents the
                files to process within the compressed directory. You can use UNIX-style wildcards,
                such as an asterisk or question mark. For example, *.json.<p class="p">Default is *, which
                  processes all files.</p>
</td>

            </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3929">
                                    <td class="entry cellrowborder" headers="d361497e4672 "><a class="xref" href="../Data_Formats/XMLDFormat.html#concept_qls_yfs_vkb" title="You can include the root element in the generated record by enabling the Preserve Root Element property.">Preserve Root Element</a></td>

                                    <td class="entry cellrowborder" headers="d361497e4675 ">Includes the root element in the generated
                                            records.<p class="p">When omitting a delimiter to generate a
                                            single record, the root element is the root element of
                                            the XML document. </p>
<p class="p">When specifying a delimiter to
                                            generate multiple records, the root element is the XML
                                            element specified as the delimiter element or is the
                                            last XML element in the simplified XPath expression
                                            specified as the delimiter element.</p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3943">
                                    <td class="entry cellrowborder" headers="d361497e4672 "><a class="xref" href="../Data_Formats/XMLDFormat.html#concept_w3k_1ch_qz">Include Field XPaths</a></td>

                                    <td class="entry cellrowborder" headers="d361497e4675 ">Includes the XPath to each parsed XML element and XML
                                        attribute in field attributes. Also includes each namespace
                                        in an xmlns record header attribute. <p class="p">When not selected,
                                            this information is not included in the record. By
                                            default, the property is not selected.</p>
<div class="p">
                                            <div class="note note"><span class="notetitle">Note:</span> <span class="ph">Field attributes and record header attributes are
                        written to destination systems automatically only when you use the SDC RPC
                        data format in destinations. For more information about working with field
                        attributes and record header attributes, and how to include them in records,
                        see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a> and <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz">Record Header Attributes</a>.</span></div>

                                        </div>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3961">
                                    <td class="entry cellrowborder" headers="d361497e4672 ">Namespaces </td>

                                    <td class="entry cellrowborder" headers="d361497e4675 ">Namespace prefix and URI to use when parsing the XML
                                        document. Define namespaces when the XML element being used
                                        includes a namespace prefix or when the XPath expression
                                        includes namespaces.<p class="p">For information about using
                                            namespaces with an XML element, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_ilc_r3g_2y">Using XML Elements with Namespaces</a>.</p>
<p class="p">For information about using namespaces with
                                            XPath expressions, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_mkk_3zj_dy">Using XPath Expressions with Namespaces</a>.</p>
<p class="p">Using <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a>, click the
                                                <span class="ph uicontrol">Add</span> icon to add additional
                                            namespaces.</p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e3986">
                                    <td class="entry cellrowborder" headers="d361497e4672 ">Output Field Attributes</td>

                                    <td class="entry cellrowborder" headers="d361497e4675 ">Includes XML attributes and namespace declarations in the
                                        record as field attributes. When not selected, XML
                                        attributes and namespace declarations are included in the
                                        record as fields.<div class="note note"><span class="notetitle">Note:</span> <span class="ph">Field attributes are automatically included in
                        records written to destination systems only when you use the SDC RPC data
                        format in the destination.</span> For more information about working with field
                                            attributes, see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a>.</div>
<p class="p">By default, the property is not
                                            selected.</p>
</td>

                                </tr>

                                <tr id="task_l3t_sdm_hdb__d23e4002">
                                    <td class="entry cellrowborder" headers="d361497e4672 ">Max Record Length (chars) </td>

                                    <td class="entry cellrowborder" headers="d361497e4675 ">
                                        <p class="p">The maximum number of characters in a record. Longer
                                            records are diverted to the pipeline for error handling. </p>

                                        <p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>

                                    </td>

                                </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4672 ">Charset</td>

              <td class="entry cellrowborder" headers="d361497e4675 ">Character encoding of the files to be processed.</td>

            </tr>

                                <tr>
              <td class="entry cellrowborder" headers="d361497e4672 "><a class="xref" href="../Pipeline_Design/ControlCharacters.html#concept_hfs_dkm_js" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">Ignore Control Characters</a></td>

              <td class="entry cellrowborder" headers="d361497e4675 ">Removes all ASCII control characters except for the tab, line feed, and
                carriage return characters.</td>

            </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
</ol>

    </div>

</article>
</article>
</article></main></div>
                        
                        
                        
                    </div>
                    
                </div>
            </div>
        </div> <nav class="navbar navbar-default wh_footer">
  <div class=" footer-container text-center ">
    <!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script>
  </div>
</nav>

        
        <div id="go2top">
            <span class="glyphicon glyphicon-chevron-up"></span>
        </div>
        
        <!-- The modal container for images -->
        <div id="modal_img_large" class="modal">
            <span class="close glyphicon glyphicon-remove"></span>
            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="modal-img" />
            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>
        
        <script src="../../../oxygen-webhelp/lib/bootstrap/js/bootstrap.min.js" type="text/javascript"></script>
         Apache License, Version 2.0.
    </body>
</html>