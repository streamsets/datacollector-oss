
<!DOCTYPE html
  PUBLIC "" "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:whc="http://www.oxygenxml.com/webhelp/components" xml:lang="en-us" lang="en-us">
    <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="shortcut icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><link rel="icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link>        
      <meta name="copyright" content="(C) Copyright 2018" /><meta name="DC.rights.owner" content="(C) Copyright 2018" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Hadoop FS" /><meta name="abstract" content="The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS), Amazon S3, or other file systems using the Hadoop FileSystem interface." /><meta name="description" content="The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS), Amazon S3, or other file systems using the Hadoop FileSystem interface." /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/Origins_title.html" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/PubSub.html#concept_pjw_qtl_r1b" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_djz_pdm_hdb" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="DC.Date.Created" content="2014-10-31" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_lw2_tnm_vs" /><title>Hadoop FS</title><!--  Generated with Oxygen version 20.0-SNAPSHOT, build number 2018042310.  --><meta name="wh-path2root" content="../../../" /><meta name="wh-toc-id" content="concept_lw2_tnm_vs-d46e31446" />         
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- Latest compiled and minified Bootstrap CSS -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap.min.css" />

        <!-- Bootstrap Optional theme -->
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap-theme.min.css" />
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/jquery-ui/jquery-ui.min.css" />

        <!-- Template default styles  -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/app/topic-page.css?buildId=2018042310" />
        

        <script type="text/javascript" src="../../../oxygen-webhelp/lib/jquery/jquery-3.1.1.min.js"><!----></script>

        <script data-main="../../../oxygen-webhelp/app/topic-page.js" src="../../../oxygen-webhelp/lib/requirejs/require.js"></script>
        
        <!-- Skin resources -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/template/light.css?buildId=2018042310" />
        <!-- EXM-36950 - Expand the args.hdf parameter here -->
        
        
    <link rel="stylesheet" type="text/css" href="../../../skin.css" /></head>

    <body class="wh_topic_page frmBody">
        <!-- EXM-36950 - Expand the args.hdr parameter here -->
        
        
        
<nav class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div class="wh_header_flex_container">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <!--
                            This component will be generated when the next parameters are specified in the transformation scenario:
                            'webhelp.logo.image' and 'webhelp.logo.image.target.url'.
                            See: http://oxygenxml.com/doc/versions/17.1/ug-editor/#topics/dita_webhelp_output.html.
                    -->
                    <a href="../../../index.html" class=" wh_logo hidden-xs "></a>
                    <div class=" wh_publication_title "><a href="../../../index.html"><span class="booktitle">  <span class="ph mainbooktitle"><span class="ph">Data Collector</span> User Guide</span>  </span></a></div>
                    
                </div>
                
                <!-- The menu button for mobile devices is copied in the output only when the 'webhelp.show.top.menu' parameter is set to 'yes' -->
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse">
                
                
                <div class=" wh_indexterms_link "><a href="../../../indexTerms.html" title="Index"><span>Index</span></a></div>
                
            </div>
        </div>
    </div>
</nav>

        <div class=" wh_search_input "><form id="searchForm" method="get" action="../../../search.html"><div><input type="search" placeholder="Search " class="wh_search_textfield" id="textToSearch" name="searchQuery" /><button type="submit" class="wh_search_button"><span>Search</span></button></div><script><!--
                                    $(document).ready(function () {
                                        $('#searchForm').submit(function (e) {
                                            if ($('.wh_search_textfield').val().length < 1) {
                                                e.preventDefault();
                                            }
                                        });
                                    });
                                --></script></form></div>
        
        <div class="container-fluid">
            <div class="row">

                <nav class="wh_tools hidden-print">
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol xmlns:html="http://www.w3.org/1999/xhtml" class="hidden-print"><li><span class="home"><a href="../../../index.html"><span>Home</span></a></span></li>
   <li><span class="topicref" data-id="concept_yjl_nc5_jq"><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span></li>
   <li class="active"><span class="topicref" data-id="concept_lw2_tnm_vs"><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_lw2_tnm_vs">Hadoop FS</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS), Amazon     S3, or other file systems using
                  the Hadoop FileSystem interface. 
                  
               </p>
               </span></span></span></li>
</ol></div>

                    <div class="wh_right_tools hidden-sm hidden-xs">
                        <div class=" wh_navigation_links "><span id="topic_navigation_links" class="navheader">
  
<span class="navprev"><a class="link" href="../../../datacollector/UserGuide/Origins/PubSub.html#concept_pjw_qtl_r1b" title="Google Pub/Sub Subscriber"></a></span>  
<span class="navnext"><a class="link" href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_djz_pdm_hdb" title="Hadoop FS Standalone"></a></span>  </span></div>
                        <button class="wh_hide_highlight" title="Toggle search highlights"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" title="Collapse sections"></button>
                        <div class=" wh_print_link print "><a href="javascript:window.print();" title="Print this page"></a></div>
                    </div>
                </nav>
            </div>

            <div class="wh_content_area">
                <div class="row">
                    
                        <nav role="navigation" id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-3 hidden-xs navbar hidden-print">
                            <div class=" wh_publication_toc " data-tooltip-position="right"><ul>
   <li><span data-tocid="concept_htw_ghg_jq-d46e54" class="topicref" data-id="concept_htw_ghg_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Getting_Started/GettingStarted_Title.html#concept_htw_ghg_jq">Getting Started</a></span></span></li>
   <li><span data-tocid="concept_hz3_5fk_fy-d46e557" class="topicref" data-id="concept_hz3_5fk_fy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/WhatsNew/WhatsNew_Title.html#concept_hz3_5fk_fy">What's New</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_l4q_flb_kr-d46e4414" class="topicref" data-id="concept_l4q_flb_kr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Installation/Install_title.html">Installation</a></span></span></li>
   <li><span data-tocid="concept_ylh_yyz_ky-d46e6481" class="topicref" data-id="concept_ylh_yyz_ky" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Configuration/Config_title.html">Configuration</a></span></span></li>
   <li><span data-tocid="concept_ejk_f1f_5v-d46e13895" class="topicref" data-id="concept_ejk_f1f_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Upgrade/Upgrade_title.html">Upgrade</a></span></span></li>
   <li><span data-tocid="concept_qsw_cjy_bt-d46e18499" class="topicref" data-id="concept_qsw_cjy_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Design/PipelineDesign_title.html">Pipeline Concepts and Design</a></span></span></li>
   <li><span data-tocid="concept_qn1_wn4_kq-d46e20154" class="topicref" data-id="concept_qn1_wn4_kq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Configuration/PipelineConfiguration_title.html">Pipeline Configuration</a></span></span></li>
   <li><span data-tocid="concept_hdr_gyw_41b-d46e22651" class="topicref" data-id="concept_hdr_gyw_41b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Formats/DataFormats-Title.html">Data Formats</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e24466" class="topicref" data-id="concept_yjl_nc5_jq" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span><ul class="nav nav-list">
         <li><span data-tocid="concept_hpr_twm_jq-d46e24488" class="topicref" data-id="concept_hpr_twm_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_overview.html#concept_hpr_twm_jq">Origins</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">An origin stage represents the source for the pipeline. You can use a single origin     stage in a pipeline.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kvs_3hh_ht-d46e25058" class="topicref" data-id="concept_kvs_3hh_ht" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AmazonS3.html#concept_kvs_3hh_ht">Amazon S3</a></span></span></li>
         <li><span data-tocid="concept_xsh_knm_5bb-d46e25998" class="topicref" data-id="concept_xsh_knm_5bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AmazonSQS.html#concept_xsh_knm_5bb">Amazon SQS Consumer</a></span></span></li>
         <li><span data-tocid="concept_c1z_15q_1bb-d46e26462" class="topicref" data-id="concept_c1z_15q_1bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AzureEventHub.html#concept_c1z_15q_1bb">Azure IoT/Event Hub Consumer</a></span></span></li>
         <li><span data-tocid="concept_wfy_ghn_sz-d46e26744" class="topicref" data-id="concept_wfy_ghn_sz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/CoAPServer.html#concept_wfy_ghn_sz">CoAP Server</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">Constrained Application Protocol (CoAP) is a web transfer protocol designed for         machine-to-machine devices. The CoAP
                        Server origin is a multithreaded origin that listens on         a CoAP endpoint and processes the contents of all authorized
                        CoAP requests. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_qcq_54n_jq-d46e27039" class="topicref" data-id="concept_qcq_54n_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Directory.html#concept_qcq_54n_jq">Directory</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Directory origin reads data from files in a directory. The origin can use         multiple threads to enable the parallel
                        processing of files. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_f1q_vpm_2z-d46e28311" class="topicref" data-id="concept_f1q_vpm_2z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Elasticsearch.html#concept_f1q_vpm_2z">Elasticsearch </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Elasticsearch origin is a multithreaded origin that reads data from an Elasticsearch         cluster, including Elastic
                        Cloud clusters (formerly Found clusters). The origin generates a         record for each Elasticsearch document.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_n1y_qyp_5q-d46e28695" class="topicref" data-id="concept_n1y_qyp_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/FileTail.html#concept_n1y_qyp_5q">File Tail</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The File Tail origin reads lines of data as they are written to an active file after         reading related archived files
                        in the same directory. File Tail generates a record for each         line of data.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_cg3_y3v_q1b-d46e29944" class="topicref" data-id="concept_cg3_y3v_q1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/BigQuery.html#concept_cg3_y3v_q1b">Google BigQuery</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Google BigQuery origin executes a query job and reads the result from Google         BigQuery. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_iyd_wql_nbb-d46e30414" class="topicref" data-id="concept_iyd_wql_nbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/GCS.html#concept_iyd_wql_nbb">Google Cloud Storage</a></span></span></li>
         <li><span data-tocid="concept_pjw_qtl_r1b-d46e30976" class="topicref" data-id="concept_pjw_qtl_r1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PubSub.html#concept_pjw_qtl_r1b">Google Pub/Sub Subscriber</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Google Pub/Sub Subscriber origin consumes messages from a Google Pub/Sub         subscription. </p>
                     </span></span></span></li>
         <li class="active"><span data-tocid="concept_lw2_tnm_vs-d46e31446" class="topicref" data-id="concept_lw2_tnm_vs" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_lw2_tnm_vs">Hadoop FS</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS), Amazon     S3, or other file systems using
                        the Hadoop FileSystem interface. 
                        
                     </p>
                     </span></span></span><ul class="nav nav-list">
               <li><span data-tocid="concept_ud1_wd2_h2b-d46e31552" class="topicref" data-id="concept_ud1_wd2_h2b" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_ud1_wd2_h2b">Reading from Amazon S3</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS origin included in a cluster batch or cluster EMR batch pipeline allows         you to read from Amazon S3.</p>
                           </span></span></span></li>
               <li><span data-tocid="concept_ogc_xzd_f1b-d46e31577" class="topicref" data-id="concept_ogc_xzd_f1b" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_ogc_xzd_f1b">Reading from Other File Systems</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS origin included in a cluster batch pipeline allows you to read from         file systems other than HDFS using
                              the Hadoop FileSystem interface.
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_xy5_4tm_vs-d46e31612" class="topicref" data-id="concept_xy5_4tm_vs" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_xy5_4tm_vs">Kerberos Authentication</a></span></span></li>
               <li><span data-tocid="concept_u4h_lwt_ls-d46e31654" class="topicref" data-id="concept_u4h_lwt_ls" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_u4h_lwt_ls">Using a Hadoop User</a></span></span></li>
               <li><span data-tocid="concept_xh5_y4d_br-d46e31706" class="topicref" data-id="concept_xh5_y4d_br" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_xh5_y4d_br">Hadoop Properties and Configuration Files</a></span></span></li>
               <li><span data-tocid="concept_efs_2fs_fdb-d46e31768" class="topicref" data-id="concept_efs_2fs_fdb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_efs_2fs_fdb">Record Header Attributes</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS origin <span class="ph">creates record header                 attributes that include <span class="ph">information about the originating file for                     the record</span>.</span></p>
                           </span></span></span></li>
               <li><span data-tocid="concept_jx4_zym_vs-d46e31849" class="topicref" data-id="concept_jx4_zym_vs" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_jx4_zym_vs">Data Formats</a></span></span></li>
               <li><span data-tocid="task_hgl_vgn_vs-d46e31932" class="topicref" data-id="task_hgl_vgn_vs" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#task_hgl_vgn_vs">Configuring a Hadoop FS Origin</a></span></span></li>
            </ul>
         </li>
         <li><span data-tocid="concept_djz_pdm_hdb-d46e32025" class="topicref" data-id="concept_djz_pdm_hdb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_djz_pdm_hdb">Hadoop FS Standalone</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS Standalone origin reads files in HDFS. The origin can use multiple         threads to enable the parallel processing
                        of files. The files to be processed must all share         a file name pattern and be fully written. You can also configure
                        the origin to read from         Azure HDInsight.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_wk4_bjz_5r-d46e33814" class="topicref" data-id="concept_wk4_bjz_5r" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPClient.html#concept_wk4_bjz_5r">HTTP Client</a></span></span></li>
         <li><span data-tocid="concept_s2p_5hb_4y-d46e36212" class="topicref" data-id="concept_s2p_5hb_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPServer.html#concept_s2p_5hb_4y">HTTP Server</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The HTTP Server origin is a multithreaded origin that listens on an HTTP endpoint and         processes the contents of all
                        authorized HTTP POST and PUT requests. Use the HTTP Server         origin to read high volumes of HTTP POST and PUT requests
                        using multiple threads. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_izh_mqd_dy-d46e36679" class="topicref" data-id="concept_izh_mqd_dy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPtoKafka.html#concept_izh_mqd_dy">HTTP to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_zp3_wnw_4y-d46e37240" class="topicref" data-id="concept_zp3_wnw_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MultiTableJDBCConsumer.html#concept_zp3_wnw_4y">JDBC Multitable Consumer</a></span></span></li>
         <li><span data-tocid="concept_qhf_hjr_bs-d46e41106" class="topicref" data-id="concept_qhf_hjr_bs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JDBCConsumer.html#concept_qhf_hjr_bs">JDBC Query Consumer</a></span></span></li>
         <li><span data-tocid="concept_rhh_4nj_dt-d46e42868" class="topicref" data-id="concept_rhh_4nj_dt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JMS.html#concept_rhh_4nj_dt">JMS Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The JMS Consumer origin reads data from a Java Messaging Service (JMS). </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_msz_wnr_5q-d46e43243" class="topicref" data-id="concept_msz_wnr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KConsumer.html#concept_msz_wnr_5q">Kafka Consumer</a></span></span></li>
         <li><span data-tocid="concept_ccs_fn4_x1b-d46e44052" class="topicref" data-id="concept_ccs_fn4_x1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_ccs_fn4_x1b">Kafka Multitopic Consumer</a></span></span></li>
         <li><span data-tocid="concept_anh_4y3_yr-d46e44992" class="topicref" data-id="concept_anh_4y3_yr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KinConsumer.html#concept_anh_4y3_yr">Kinesis Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Kinesis Consumer origin reads data from Amazon Kinesis Streams. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_qwj_5vm_pbb-d46e45465" class="topicref" data-id="concept_qwj_5vm_pbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRdbCDC.html#concept_qwj_5vm_pbb">MapR DB CDC</a></span></span></li>
         <li><span data-tocid="concept_ywh_k15_3y-d46e45747" class="topicref" data-id="concept_ywh_k15_3y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRDBJSON.html#concept_ywh_k15_3y">MapR DB JSON</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR DB JSON origin reads JSON documents from MapR DB JSON tables. The origin         converts each document into a record.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_psz_db4_lx-d46e45849" class="topicref" data-id="concept_psz_db4_lx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRFS.html#concept_psz_db4_lx">MapR FS</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR FS origin reads files from MapR FS. Use this origin only in pipelines         configured for cluster batch pipeline
                        execution mode. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_b43_3qc_mdb-d46e46235" class="topicref" data-id="concept_b43_3qc_mdb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRFSStandalone.html#concept_b43_3qc_mdb">MapR FS Standalone</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR FS Standalone origin reads files in MapR. The origin can use multiple         threads to enable the parallel processing
                        of files. The files to be processed must all share         a file name pattern and be fully written. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hvd_hww_lbb-d46e47848" class="topicref" data-id="concept_hvd_hww_lbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRStreamsMultiConsumer.html#concept_hvd_hww_lbb">MapR Multitopic Streams Consumer</a></span></span></li>
         <li><span data-tocid="concept_cvy_xsf_2v-d46e48309" class="topicref" data-id="concept_cvy_xsf_2v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRStreamsCons.html#concept_cvy_xsf_2v">MapR Streams Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR Streams Consumer origin reads messages from MapR Streams.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_bk4_2rs_ns-d46e48601" class="topicref" data-id="concept_bk4_2rs_ns" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MongoDB.html#concept_bk4_2rs_ns">MongoDB</a></span></span></li>
         <li><span data-tocid="concept_mjn_yqw_4y-d46e49162" class="topicref" data-id="concept_mjn_yqw_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MongoDBOplog.html#concept_mjn_yqw_4y">MongoDB Oplog</a></span></span></li>
         <li><span data-tocid="concept_ukz_3vt_lz-d46e49620" class="topicref" data-id="concept_ukz_3vt_lz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MQTTSubscriber.html#concept_ukz_3vt_lz">MQTT Subscriber</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MQTT Subscriber origin subscribes to topics on an MQTT broker to read messages         from the broker. The origin functions
                        as an MQTT client that receives messages, generating a         record for each message.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kqg_1yh_xx-d46e49839" class="topicref" data-id="concept_kqg_1yh_xx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MySQLBinaryLog.html#concept_kqg_1yh_xx">MySQL Binary Log</a></span></span></li>
         <li><span data-tocid="concept_dsr_xmw_1s-d46e50410" class="topicref" data-id="concept_dsr_xmw_1s" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Omniture.html#concept_dsr_xmw_1s">Omniture</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Omniture origin processes JSON website usage reports generated by the Omniture   reporting APIs. Omniture is also known
                        as the Adobe Marketing Cloud.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_nmf_1ly_f1b-d46e50467" class="topicref" data-id="concept_nmf_1ly_f1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/OPCUAClient.html#concept_nmf_1ly_f1b">OPC UA Client </a></span></span></li>
         <li><span data-tocid="concept_rs5_hjj_tw-d46e50679" class="topicref" data-id="concept_rs5_hjj_tw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/OracleCDC.html#concept_rs5_hjj_tw">Oracle CDC Client</a></span></span></li>
         <li><span data-tocid="concept_cfs_4m4_n2b-d46e54821" class="topicref" data-id="concept_cfs_4m4_n2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PostgreSQL.html#concept_cfs_4m4_n2b">PostgreSQL CDC Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The PostgreSQL CDC Client origin processes Write-Ahead Logging (WAL) data to generate         change data capture records
                        for a PostgreSQL database. Use the PostgreSQL CDC Client origin         to process WAL data from PostgreSQL 9.4 or later.
                        Earlier versions do not support         WAL.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_dyg_lq1_h5-d46e55290" class="topicref" data-id="concept_dyg_lq1_h5" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/RabbitMQ.html#concept_dyg_lq1_h5">RabbitMQ Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">RabbitMQ Consumer reads AMQP messages from a single RabbitMQ queue.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_plr_t3v_jw-d46e55510" class="topicref" data-id="concept_plr_t3v_jw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Redis.html#concept_plr_t3v_jw">Redis Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Redis Consumer origin reads messages from Redis. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_odf_vr3_rx-d46e55664" class="topicref" data-id="concept_odf_vr3_rx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Salesforce.html#concept_odf_vr3_rx">Salesforce</a></span></span></li>
         <li><span data-tocid="concept_agb_5c1_ct-d46e58262" class="topicref" data-id="concept_agb_5c1_ct" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SDC_RPCorigin.html#concept_agb_5c1_ct">SDC RPC </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"> The SDC RPC origin enables connectivity between two SDC RPC pipelines. The SDC RPC     origin reads data passed from an SDC
                        RPC destination. Use the SDC RPC origin as part of an SDC     RPC destination pipeline.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_tdk_slk_pw-d46e58319" class="topicref" data-id="concept_tdk_slk_pw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SDCRPCtoKafka.html#concept_tdk_slk_pw">SDC RPC to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_ic5_bzd_5v-d46e58999" class="topicref" data-id="concept_ic5_bzd_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SFTP.html#concept_ic5_bzd_5v">SFTP/FTP Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The SFTP/FTP Client origin reads files from a server using the Secure File Transfer         Protocol (SFTP) or the File Transfer
                        Protocol (FTP). 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ut3_ywc_v1b-d46e59566" class="topicref" data-id="concept_ut3_ywc_v1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SQLServerCDC.html#concept_ut3_ywc_v1b">SQL Server CDC Client</a></span></span></li>
         <li><span data-tocid="concept_ewq_b2s_r1b-d46e60961" class="topicref" data-id="concept_ewq_b2s_r1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SQLServerChange.html#concept_ewq_b2s_r1b">SQL Server Change Tracking</a></span></span></li>
         <li><span data-tocid="concept_gzy_gmv_32b-d46e62038" class="topicref" data-id="concept_gzy_gmv_32b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SystemMetrics.html#concept_gzy_gmv_32b">System Metrics</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The System Metrics origin reads system metrics from the edge device where <span class="ph">StreamSets</span>         <span class="ph">Data Collector Edge</span>             (<span class="ph">SDC Edge</span>)         is installed. Use the System Metrics origin only in pipelines configured for edge execution         mode. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ppm_xb1_4z-d46e62149" class="topicref" data-id="concept_ppm_xb1_4z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/TCPServer.html#concept_ppm_xb1_4z">TCP Server</a></span></span></li>
         <li><span data-tocid="concept_wng_g5f_5bb-d46e62607" class="topicref" data-id="concept_wng_g5f_5bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDPMulti.html#concept_wng_g5f_5bb">UDP Multithreaded Source</a></span></span></li>
         <li><span data-tocid="concept_rst_2y5_1s-d46e62972" class="topicref" data-id="concept_rst_2y5_1s" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDP.html#concept_rst_2y5_1s">UDP Source</a></span></span></li>
         <li><span data-tocid="concept_jzq_jcz_pw-d46e63120" class="topicref" data-id="concept_jzq_jcz_pw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDPtoKafka.html#concept_jzq_jcz_pw">UDP to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_unk_nzk_fbb-d46e63581" class="topicref" data-id="concept_unk_nzk_fbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WebSocketClient.html#concept_unk_nzk_fbb">WebSocket Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The WebSocket Client origin reads data from a WebSocket server endpoint. Use the origin         to read data from a WebSocket
                        resource URL. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_u2r_gpc_3z-d46e63734" class="topicref" data-id="concept_u2r_gpc_3z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WebSocketServer.html#concept_u2r_gpc_3z">WebSocket Server</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The WebSocket Server origin is a multithreaded origin that listens on a WebSocket         endpoint and processes the contents
                        of all authorized WebSocket client requests. Use the         WebSocket Server origin to read high volumes of WebSocket client
                        requests using multiple         threads. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_agf_5jv_sbb-d46e64111" class="topicref" data-id="concept_agf_5jv_sbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WindowsLog.html#concept_agf_5jv_sbb">Windows Event Log</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Windows Event Log origin reads data from a Microsoft Windows event log located on a         Windows machine. The origin
                        generates a record for each event in the log. 
                        
                     </p>
                     </span></span></span></li>
      </ul>
   </li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e64169" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Processors/Processors_title.html">Processors</a></span></span></li>
   <li><span data-tocid="concept_agj_cfj_br-d46e77391" class="topicref" data-id="concept_agj_cfj_br" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations-title.html">Destinations</a></span></span></li>
   <li><span data-tocid="concept_umc_1lk_fx-d46e92871" class="topicref" data-id="concept_umc_1lk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-title.html">Executors</a></span></span></li>
   <li><span data-tocid="concept_ugp_kwf_xw-d46e98772" class="topicref" data-id="concept_ugp_kwf_xw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM_title.html">StreamSets Control Hub</a></span></span></li>
   <li><span data-tocid="concept_xxd_f5r_kx-d46e102096" class="topicref" data-id="concept_xxd_f5r_kx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Event_Handling/EventFramework-Title.html#concept_xxd_f5r_kx">Dataflow Triggers</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fjj_zcf_2w-d46e106011" class="topicref" data-id="concept_fjj_zcf_2w" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w">Drift Synchronization Solution for Hive</a></span></span></li>
   <li><span data-tocid="concept_kgt_pnr_4cb-d46e108837" class="topicref" data-id="concept_kgt_pnr_4cb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/JDBC_DriftSolution/JDBC_DriftSyncSolution_title.html#concept_kgt_pnr_4cb">Drift Synchronization Solution for PostgreSQL</a></span></span></li>
   <li><span data-tocid="concept_wwq_gxc_py-d46e109636" class="topicref" data-id="concept_wwq_gxc_py" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wwq_gxc_py">Multithreaded Pipelines</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fyf_gkq_4bb-d46e110218" class="topicref" data-id="concept_fyf_gkq_4bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Edge_Mode/EdgePipelines_title.html">Edge Pipelines</a></span></span></li>
   <li><span data-tocid="concept_wr1_ktz_bt-d46e111818" class="topicref" data-id="concept_wr1_ktz_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/RPC_Pipelines/SDC_RPCpipelines_title.html#concept_wr1_ktz_bt">SDC RPC Pipelines</a></span></span></li>
   <li><span data-tocid="concept_fpz_5r4_vs-d46e112299" class="topicref" data-id="concept_fpz_5r4_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Cluster_Mode/ClusterPipelines_title.html">Cluster Pipelines</a></span></span></li>
   <li><span data-tocid="concept_jjk_23z_sq-d46e113641" class="topicref" data-id="concept_jjk_23z_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Preview/DataPreview_Title.html#concept_jjk_23z_sq">Data Preview</a></span></span></li>
   <li><span data-tocid="concept_pgk_brx_rr-d46e114610" class="topicref" data-id="concept_pgk_brx_rr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Alerts/RulesAlerts_title.html#concept_pgk_brx_rr">Rules and Alerts</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_asx_fdz_sq-d46e117238" class="topicref" data-id="concept_asx_fdz_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Monitoring/PipelineMonitoring_title.html#concept_asx_fdz_sq">Pipeline Monitoring</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_o3l_dtr_5q-d46e118495" class="topicref" data-id="concept_o3l_dtr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Maintenance/PipelineMaintenance_title.html#concept_o3l_dtr_5q">Pipeline Maintenance</a></span></span></li>
   <li><span data-tocid="concept_yms_ftm_sq-d46e120286" class="topicref" data-id="concept_yms_ftm_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Administration/Administration_title.html#concept_yms_ftm_sq">Administration</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_nls_w1r_ks-d46e124782" class="topicref" data-id="concept_nls_w1r_ks" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Tutorial/Tutorial-title.html">Tutorial</a></span></span></li>
   <li><span data-tocid="concept_sh3_frm_tq-d46e125996" class="topicref" data-id="concept_sh3_frm_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Troubleshooting/Troubleshooting_title.html#concept_sh3_frm_tq">Troubleshooting</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_xbx_rs1_tq-d46e129904" class="topicref" data-id="concept_xbx_rs1_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Glossary/Glossary_title.html#concept_xbx_rs1_tq">Glossary</a></span></span></li>
   <li><span data-tocid="concept_jn1_nzb_kv-d46e129959" class="topicref" data-id="concept_jn1_nzb_kv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-DataFormats/DataFormat_Title.html#concept_jn1_nzb_kv">Data Formats by Stage</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_pvm_yt3_wq-d46e130119" class="topicref" data-id="concept_pvm_yt3_wq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Expression_Language/ExpressionLanguage_title.html">Expression Language</a></span></span></li>
   <li><span data-tocid="concept_vcj_1ws_js-d46e131600" class="topicref" data-id="concept_vcj_1ws_js" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-RegEx/RegEx-Title.html#concept_vcj_1ws_js">Regular Expressions</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_chv_vmj_wr-d46e131822" class="topicref" data-id="concept_chv_vmj_wr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-GrokPatterns/GrokPatterns_title.html#concept_chv_vmj_wr">Grok Patterns</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
</ul></div>
                        </nav>
                    
                    
                    <div class="col-lg-9 col-md-9 col-sm-9 col-xs-12" id="wh_topic_body">
                        <div class=" wh_topic_content body "><main role="main"><article role="article" aria-labelledby="ariaid-title1"><article class="nested0" aria-labelledby="ariaid-title1" id="concept_lw2_tnm_vs">
  <h1 class="title topictitle1" id="ariaid-title1">Hadoop FS</h1>

  
  <div class="body conbody"><p class="shortdesc">The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS), Amazon
    S3, or other file systems using the Hadoop FileSystem interface. </p>

    <div class="p">Use this origin only in pipelines configured for one of the
      following cluster modes:<dl class="dl">
        
          <dt class="dt dlterm">Cluster batch mode</dt>

          <dd class="dd">Cluster batch mode pipelines use a Hadoop FS origin and run on a Cloudera distribution
            of Hadoop (CDH) or Hortonworks Data Platform (HDP) cluster to process data from HDFS,
            Amazon S3, or other file systems using the Hadoop FileSystem interface. </dd>

        
        
          <dt class="dt dlterm">Cluster EMR batch mode</dt>

          <dd class="dd">Cluster EMR batch mode pipelines use a Hadoop FS origin and run on an Amazon EMR
            cluster to process data from Amazon S3. </dd>

        
      </dl>
</div>

    <p class="p">For more information about cluster pipelines, see <a class="xref" href="../Cluster_Mode/ClusterPipelines.html#concept_hmh_kfn_1s" title="A cluster pipeline is a pipeline that runs in cluster execution mode. You can run a pipeline in standalone execution mode or cluster execution mode.">Cluster Pipeline Overview</a>. To read from HDFS in
      standalone execution mode, use the <a class="xref" href="HDFSStandalone.html#concept_djz_pdm_hdb" title="The Hadoop FS Standalone origin reads files in HDFS. The origin can use multiple threads to enable the parallel processing of files. The files to be processed must all share a file name pattern and be fully written. You can also configure the origin to read from Azure HDInsight.">Hadoop
        FS Standalone origin</a>.</p>

    <p class="p">When you configure the Hadoop FS origin, you specify the input path and data format for the
      data to be read. You can configure the origin to read from all subdirectories and to generate
      a single record for records that include multiple objects. </p>

    <p class="p">The origin reads compressed data based on file extension for all Hadoop-supported compression
      codecs.</p>

    <p class="p">When necessary, you can enable Kerberos authentication and
                  specify a Hadoop user. You can also use Hadoop configuration files and add other
                  Hadoop configuration properties as needed. </p>

    <p class="p">The Hadoop FS origin generates record header attributes that enable you to use the origins of
      a record in pipeline processing.</p>

  </div>

<article class="topic concept nested1" aria-labelledby="ariaid-title2" id="concept_ud1_wd2_h2b">
    <h2 class="title topictitle2" id="ariaid-title2">Reading from Amazon S3</h2>

    
    <div class="body conbody"><p class="shortdesc">The Hadoop FS origin included in a cluster batch or cluster EMR batch pipeline allows
        you to read from Amazon S3.</p>

        <p class="p">To
            read from Amazon S3, specify the appropriate URI for Amazon S3 when you configure the
            Hadoop FS origin. For example, instead of hdfs://&lt;authority&gt;, configure the URI to
            point to the Amazon S3 bucket to read from, as follows:</p>

        <pre class="pre codeblock"><code>s3a://&lt;bucket&gt;</code></pre>
        <div class="p">For example:<pre class="pre codeblock"><code>s3a://WebServer</code></pre></div>

        <p class="p">Then in the Input Paths property, enter the full path to the data to be read within that
            Amazon S3 bucket. You can enter multiple paths for the Input Paths property, as
            follows:</p>

        <p class="p"><img class="image" id="concept_ud1_wd2_h2b__image_v2t_dg2_h2b" src="../Graphics/HDFSorigin_ReadS3.png" height="165" width="580" /></p>

        <p class="p">For additional requirements when using the Hadoop FS origin to read from Amazon S3, see
                <a class="xref" href="../Cluster_Mode/AmazonS3Requirements.html#concept_opj_jmf_f2b" title="Cluster EMR batch and cluster batch mode pipelines can process data from Amazon S3.">Amazon S3 Requirements</a>.</p>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title3" id="concept_ogc_xzd_f1b">
 <h2 class="title topictitle2" id="ariaid-title3">Reading from Other File Systems</h2>

    
 <div class="body conbody"><p class="shortdesc">The Hadoop FS origin included in a cluster batch pipeline allows you to read from
        file systems other than HDFS using the Hadoop FileSystem interface.</p>

  <p class="p">For example, you can use the Hadoop FS origin to read
            data from Microsoft Azure Data Lake Store for a cluster batch pipeline if the origin
            system has the Hadoop FileSystem interface installed.</p>

        <div class="p">To read from a file system other than HDFS, perform the following steps:<ol class="ol" id="concept_ogc_xzd_f1b__ol_n25_tvj_f1b">
                <li class="li">Make sure the Hadoop FileSystem interface is installed on the file system.</li>

                <li class="li">Install all required file system application JAR files as external libraries for
                    the Hadoop FS stage library that you use. See the file system documentation for
                    details about the files to install. For instructions on installing external
                    libraries, see <a class="xref" href="../Configuration/ExternalLibs.html#concept_pdv_qlw_ft">Install External Libraries</a>.</li>

                <li class="li">When you configure the Hadoop FS origin, specify the appropriate URI for the
                    origin system. For example, instead of hdfs://&lt;authority&gt;, to connect to
                    Azure Data Lake Store, you might use adls://&lt;authority&gt;.</li>

            </ol>
</div>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title4" id="concept_xy5_4tm_vs">
  <h2 class="title topictitle2" id="ariaid-title4">Kerberos Authentication</h2>

  <div class="body conbody">
    <p class="p"><span class="ph">You can use Kerberos authentication to connect to HDFS. When you
                use Kerberos authentication, <span class="ph">Data Collector</span>
                uses the Kerberos principal and keytab to connect to HDFS. By default, <span class="ph">Data Collector</span>
                uses the user account who started it to connect.</span></p>

    <div class="note note"><span class="notetitle">Note:</span> Cluster EMR batch mode pipelines that read from Amazon S3 do not support Kerberos
            authentication at this time.</div>

    <p class="p"><span class="ph">The Kerberos principal and keytab are defined in the <span class="ph">Data Collector</span>
                configuration file, <code class="ph codeph">$SDC_CONF/sdc.properties</code>. To use Kerberos
                authentication, configure all Kerberos properties in the <span class="ph">Data Collector</span>
                configuration file, and then enable Kerberos in the</span> Hadoop FS origin.</p>

    <p class="p"><span class="ph">For more information about enabling Kerberos authentication
                        for <span class="ph">Data Collector</span>, see <a class="xref" href="../Configuration/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Kerberos Authentication</a>.</span></p>

  </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title5" id="concept_u4h_lwt_ls">
  <h2 class="title topictitle2" id="ariaid-title5">Using a Hadoop User</h2>

  <div class="body conbody">
    <p class="p"><span class="ph"><span class="ph">Data Collector</span>
                        can either use the currently logged in <span class="ph">Data Collector</span> user or a
                        user configured in the</span> Hadoop FS origin to read from HDFS. </p>

    <p class="p">A <span class="ph">Data Collector</span> configuration property can be set that requires using the currently logged in
                        <span class="ph">Data Collector</span> user. When
                  this property is not set, you can specify a user in the origin. For more
                  information about Hadoop impersonation and the Data Collector property, see <a class="xref" href="../Configuration/DCConfig.html#concept_pmr_sy5_nz">Hadoop Impersonation Mode</a>. </p>

    <p class="p">Note that the origin <span class="ph">uses a different user account to
                        connect to HDFS. <span class="ph" id="concept_u4h_lwt_ls__d11e3687">By default, <span class="ph">Data Collector</span> uses
                              the user account who started it to connect to external systems. When
                              using Kerberos, <span class="ph">Data Collector</span> uses
                              the Kerberos principal.</span>
                  </span></p>

    <div class="p">To configure a user in the Hadoop FS origin to read from HDFS, perform the following
        tasks:<ol class="ol" id="concept_u4h_lwt_ls__ul_mb1_xpt_ls">
        <li class="li">On Hadoop, configure the user as a proxy user and
                              authorize the user to impersonate a Hadoop user. <p class="p">For more
                                    information, see the Hadoop documentation. </p>
</li>

        <li class="li">In the Hadoop FS origin, on the <span class="keyword wintitle">Hadoop FS</span> tab, configure the
            <span class="ph uicontrol">Hadoop FS User</span> property.</li>

      </ol>
</div>

  </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title6" id="concept_xh5_y4d_br">
 <h2 class="title topictitle2" id="ariaid-title6">Hadoop Properties and Configuration Files</h2>

    <div class="body conbody">
        <div class="p">You can configure the Hadoop FS origin to use
            individual Hadoop properties or Hadoop configuration files:<dl class="dl">
                
                    <dt class="dt dlterm">Hadoop configuration files</dt>

                    <dd class="dd">You can use the following Hadoop configuration files with the Hadoop FS
                            origin:<ul class="ul" id="concept_xh5_y4d_br__ul_hq2_l4r_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                        <li class="li">yarn-site.xml</li>

                        <li class="li">mapred-site.xml</li>

                  </ul>
</dd>

                    <dd class="dd ddexpand">To use Hadoop configuration files: <ol class="ol" id="concept_xh5_y4d_br__ol_rb2_2nr_bt">
                            <li class="li">Store the files or a symlink to the files in the <span class="ph">Data Collector</span> resources directory. </li>

                            <li class="li">In the Hadoop FS origin, specify the location of the files. </li>

                        </ol>
<div class="note note"><span class="notetitle">Note:</span>  For a Cloudera Manager installation, <span class="ph">Data Collector</span> automatically creates a symlink to the files named
                                <code class="ph codeph">hadoop-conf</code>. Enter <code class="ph codeph">hadoop-conf</code> for
                            the location of the files in the Hadoop FS origin.</div>
</dd>

                
                
                    <dt class="dt dlterm">Individual properties</dt>

                    <dd class="dd">You can configure individual Hadoop properties in the origin. To add a
                        Hadoop property, you specify the exact property name and the value. The
                        Hadoop FS origin does not validate the property names or
                            values.<div class="note note"><span class="notetitle">Note:</span> Individual properties override properties defined in the
                            Hadoop configuration files. </div>
</dd>

                
            </dl>
</div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title7" id="concept_efs_2fs_fdb">
    <h2 class="title topictitle2" id="ariaid-title7">Record Header Attributes</h2>

    
    <div class="body conbody"><p class="shortdesc">The Hadoop FS origin <span class="ph">creates record header
                attributes that include <span class="ph" id="d25e21">information about the originating file for
                    the record</span>.</span></p>

        <p class="p"><span class="ph">You can use the record:attribute or
                record:attributeOrDefault functions to access the information in the attributes. For
                more information about working with record header attributes, see <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_rd2_ghz_dz">Working with Header Attributes</a>.</span></p>

        <div class="p">The Hadoop FS origin <span class="ph">creates the following record header
                attributes:</span><ul class="ul" id="concept_efs_2fs_fdb__ul_cvh_5hs_fdb">
                <li class="li">file - Provides the file path and file name where the record
                    originated.</li>

                <li class="li">offset - Provides the file offset in bytes. The file offset is
                    the location in the file where the record originated.</li>

            </ul>
</div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title8" id="concept_jx4_zym_vs">
 <h2 class="title topictitle2" id="ariaid-title8">Data Formats</h2>

 <div class="body conbody">
  <div class="p">The Hadoop FS origin processes data
      differently based on the data format that you select. The origin processes the following types
      of data:<dl class="dl">
        
                              <dt class="dt dlterm">Avro</dt>

                              <dd class="dd">Generates a record for every Avro record. Includes a "precision"
                                    and "scale" field attribute for each Decimal field. For more
                                    information about field attributes, see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a>.</dd>

                              <dd class="dd ddexpand">The origin writes the Avro schema to an avroSchema record header
                                    attribute. For more information about record header attributes,
                                    see <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz">Record Header Attributes</a>. </dd>

                              <dd class="dd ddexpand">You can use one of the following methods to specify the location
                                    of the Avro schema definition:<ul class="ul" id="concept_jx4_zym_vs__d11e1122">
                                          <li class="li"><span class="ph uicontrol">Message/Data Includes Schema</span> -
                                                Use the schema in the file.</li>

                                          <li class="li"><span class="ph uicontrol">In Pipeline Configuration</span> - Use
                                                the schema that you provide in the stage
                                                configuration.</li>

                                          <li class="li"><span class="ph uicontrol">Confluent Schema Registry</span> -
                                                Retrieve the schema from Confluent Schema Registry.
                                                The Confluent Schema Registry is a distributed
                                                storage layer for Avro schemas. You can configure
                                                the origin to look up the schema in the Confluent
                                                Schema Registry by the schema ID or subject
                                                specified in the stage configuration.</li>

                                    </ul>
</dd>

                              <dd class="dd ddexpand">Using a schema in the stage configuration or retrieving a schema
                                    from the Confluent Schema Registry overrides any schema that
                                    might be included in the file and can improve performance.</dd>

                              <dd class="dd ddexpand">The origin reads files compressed by Avro-supported compression
                                    codecs without requiring additional configuration.</dd>

                        
        
                              <dt class="dt dlterm">Delimited</dt>

                              <dd class="dd">Generates a record for each delimited line. You can use the
                                    following delimited format types:<ul class="ul" id="concept_jx4_zym_vs__ul_vyp_ksl_mcb">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                  </ul>
</dd>

                              <dd class="dd ddexpand">You can use a list or list-map root field type for delimited data,
                                    optionally including the header information when available. For
                                    more information about the root field types, see <a class="xref" href="../Data_Formats/DelimitedDataRootFieldTypes.html#concept_zcg_bm4_fs">Delimited Data Root Field Type</a>.</dd>

                              <dd class="dd ddexpand">When using a header line, you can allow processing records with
                                    additional columns. The additional columns are named using a
                                    custom prefix and integers in sequential increasing order, such
                                    as _extra_1, _extra_2. When you disallow additional columns when
                                    using a header line, records that include additional columns are
                                    sent to error.</dd>

                              <dd class="dd ddexpand">You can also replace a string constant with null values.</dd>

                              <dd class="dd ddexpand">When a record exceeds the maximum record length defined for the
                                    origin, the origin processes the object based on the error
                                    handling configured for the stage.</dd>

                        
        
                              <dt class="dt dlterm">Text</dt>

                              <dd class="dd">Generates a record for each line of text or for each section of
                                    text based on a custom delimiter.</dd>

                              <dd class="dd ddexpand">When a line or section exceeds the maximum line length defined for
                                    the origin, the origin truncates it. The origin adds a boolean
                                    field named Truncated to indicate if the line was
                                    truncated.</dd>

                              <dd class="dd ddexpand">For more information about processing text with a custom
                                    delimiter, see <a class="xref" href="../Data_Formats/TextCDelim.html#concept_lg2_gcg_jx">Text Data Format with Custom Delimiters</a>.</dd>

                        
      </dl>
</div>

 </div>

</article>
<article class="topic task nested1" aria-labelledby="ariaid-title9" id="task_hgl_vgn_vs">
    <h2 class="title topictitle2" id="ariaid-title9">Configuring a Hadoop FS Origin</h2>

    <div class="body taskbody">
        <section class="section context">Configure
            a Hadoop FS origin in a cluster pipeline to read data from HDFS, Amazon S3, or other
            file system using the Hadoop FileSystem interface.</section>

        <ol class="ol steps" id="task_hgl_vgn_vs__steps_v51_1hn_vs"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__d62e531" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d268396e780">General Property</th>

                                    <th class="entry cellrowborder" id="d268396e783">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e780 ">Name</td>

                                    <td class="entry cellrowborder" headers="d268396e783 ">Stage name.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e780 ">Description</td>

                                    <td class="entry cellrowborder" headers="d268396e783 ">Optional description.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e780 ">Stage Library</td>

                                    <td class="entry cellrowborder" headers="d268396e783 ">Library version that you want to use. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e780 ">On Record Error <a class="xref" href="../Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r">
                                            <img class="image" id="task_hgl_vgn_vs__d62e586" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e783 ">Error record handling for the stage: <ul class="ul" id="task_hgl_vgn_vs__d62e590">
                                            <li class="li">Discard - Discards the record.</li>

                                            <li class="li">Send to Error - Sends the record to the pipeline for
                                                error handling.</li>

                                            <li class="li">Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Hadoop FS</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__table_b55_mkn_vs" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:27.77777777777778%" /><col style="width:72.22222222222221%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d268396e868">Hadoop FS Property</th>

                                    <th class="entry cellrowborder" id="d268396e871">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Hadoop FS URI</td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">Optional URI to use. To read from HDFS, include the HDFS
                                        scheme and authority as follows:
                                            <code class="ph codeph">&lt;scheme&gt;://&lt;authority&gt;</code>.<div class="p">For
                                            example:<pre class="pre codeblock"><code>hdfs://nameservice</code></pre></div>
<p class="p">To
                                            read from Amazon S3 or other file systems using the
                                            Hadoop FileSystem interface, enter the appropriate URI
                                            for the system. For more information, see <a class="xref" href="HadoopFS-origin.html#concept_ud1_wd2_h2b" title="The Hadoop FS origin included in a cluster batch or cluster EMR batch pipeline allows you to read from Amazon S3.">Reading from Amazon S3</a> or <a class="xref" href="HadoopFS-origin.html#concept_ogc_xzd_f1b" title="The Hadoop FS origin included in a cluster batch pipeline allows you to read from file systems other than HDFS using the Hadoop FileSystem interface.">Reading from Other File Systems</a>.</p>
<p class="p">When not configured,
                                    the destination uses the URI defined by the fs.defaultFS
                                    property in the core-site.xml file. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Input Paths</td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">Location of the input data to be read. Enter the path as
                                        follows: <code class="ph codeph">/&lt;path&gt;</code>.<div class="p">For
                                            example:<pre class="pre codeblock"><code>/user/hadoop/directory</code></pre></div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Include All Subdirectories</td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">Reads from all directories within the specified input
                                        path.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Produce Single Record</td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">Generates a single record when a record includes multiple
                                        objects. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Kerberos Authentication <a class="xref" href="HadoopFS-origin.html#concept_xy5_4tm_vs">
                                            <img class="image" id="task_hgl_vgn_vs__image_a5x_jzn_vs" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">Uses Kerberos credentials to connect to HDFS. <p class="p">When
                                            selected, uses the Kerberos principal and keytab defined
                                            in the <span class="ph">Data Collector</span> configuration file,
                                                <code class="ph codeph">$SDC_CONF/sdc.properties</code>. </p>
<div class="note note"><span class="notetitle">Note:</span> Cluster EMR batch mode pipelines that read from Amazon S3 do not support Kerberos
            authentication at this time.</div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Hadoop FS Configuration Directory <a class="xref" href="HadoopFS-origin.html#concept_xh5_y4d_br">
                                            <img class="image" id="task_hgl_vgn_vs__image_ocv_4qg_xs" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">
                                        <p class="p">Location of the Hadoop configuration files. </p>

                                        <p class="p">For a Cloudera Manager installation, enter
                                                <code class="ph codeph">hadoop-conf</code>. For all other
                                            installations, use a directory or symlink within the <span class="ph">Data Collector</span> resources directory.</p>

                                        <div class="p">You can use the following files with the Hadoop FS
                                                origin:<ul class="ul" id="task_hgl_vgn_vs__ul_o22_m4r_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                        <li class="li">yarn-site.xml</li>

                        <li class="li">mapred-site.xml</li>

                  </ul>
</div>

                                        <div class="p">
                                            <div class="note note"><span class="notetitle">Note:</span> Properties in the configuration files are
                                                overridden by individual properties defined in the
                                                stage. </div>

                                        </div>

                                    </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Hadoop FS User <a class="xref" href="HadoopFS-origin.html#concept_u4h_lwt_ls">
                                            <img class="image" id="task_hgl_vgn_vs__image_t3x_4qg_xs" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">The Hadoop user to use to read from HDFS. When using this
                                        property, make sure HDFS is configured appropriately.<p class="p">When
                                            not configured, the pipeline uses the currently logged
                                            in <span class="ph">Data Collector</span> user. </p>
<p class="p">Not configurable when <span class="ph">Data Collector</span> is configured to use the currently logged in <span class="ph">Data Collector</span> user. <span class="ph">For more information, see <a class="xref" href="../Configuration/DCConfig.html#concept_pmr_sy5_nz">Hadoop Impersonation Mode</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e868 ">Hadoop FS Configuration <a class="xref" href="HadoopFS-origin.html#concept_xh5_y4d_br">
                                            <img class="image" id="task_hgl_vgn_vs__image_if3_4hl_xs" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e871 ">
                                        <p class="p">Additional Hadoop configuration properties to use. To add
                                            properties, click <span class="ph uicontrol">Add</span> and define
                                            the property name and value. </p>

                                        <p class="p">Use the property names and values as expected by Hadoop.
                                        </p>

                                    </td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d268396e868 ">Max Batch Size (records)</td>

       <td class="entry cellrowborder" headers="d268396e871 ">Maximum number of records processed at one time. Honors values up to the <span class="ph">Data Collector</span> maximum batch size. <p class="p">Default is
         1000. The <span class="ph">Data Collector</span> default is
         1000.</p>
</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Data Format</span> tab, configure the following
                    property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__table_hvy_pt3_vx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d268396e1116">Data Format Property</th>

                                    <th class="entry cellrowborder" id="d268396e1119">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1116 ">Data Format <a class="xref" href="HadoopFS-origin.html#concept_jx4_zym_vs">
                                            <img class="image" id="task_hgl_vgn_vs__image_mfn_hwx_5r" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e1119 ">
                                        <div class="p">Type of data to be read. Use one of the following
                                            options: <ul class="ul" id="task_hgl_vgn_vs__ul_czf_y14_vs">
                                                <li class="li">Avro</li>

                                                <li class="li">Delimited</li>

                                                <li class="li">Text</li>

                                            </ul>
</div>

                                    </td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand" id="task_hgl_vgn_vs__O-AVRO-FILE">
                <span class="ph cmd">For Avro data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__table_fv4_ggf_lx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d268396e1180">Avro Property</th>

                                    <th class="entry cellrowborder" id="d268396e1183">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1180 ">Avro Schema Location</td>

                                    <td class="entry cellrowborder" headers="d268396e1183 ">Location of the Avro schema definition to use when
                                        processing data:<ul class="ul" id="task_hgl_vgn_vs__d62e757">
                                            <li class="li">Message/Data Includes Schema - Use the schema in the
                                                file.</li>

                                            <li class="li">In Pipeline Configuration - Use the schema provided
                                                in the stage configuration.</li>

                                            <li class="li">Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry.</li>

                                        </ul>
<p class="p">Using a schema in the stage configuration or in the
                                            Confluent Schema Registry can improve
                                        performance.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1180 ">Avro Schema</td>

                                    <td class="entry cellrowborder" headers="d268396e1183 ">Avro schema definition used to process the data.
                                        Overrides any existing schema definitions associated with
                                        the data. <p class="p">You can optionally use the runtime:loadResource
                                            function to use a schema definition stored in a runtime
                                            resource file. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1180 ">Schema Registry URLs</td>

                                    <td class="entry cellrowborder" headers="d268396e1183 ">Confluent Schema Registry URLs used to look up the
                                        schema. To add a URL, click <span class="ph uicontrol">Add</span>. Use
                                        the following format to enter the
                                        URL:<pre class="pre codeblock"><code>http://&lt;host name&gt;:&lt;port number&gt;</code></pre></td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1180 ">Lookup Schema By</td>

                                    <td class="entry cellrowborder" headers="d268396e1183 ">Method used to look up the schema in the Confluent Schema
                                            Registry:<ul class="ul" id="task_hgl_vgn_vs__d62e804">
                                            <li class="li">Subject - Look up the specified Avro schema
                                                subject.</li>

                                            <li class="li">Schema ID - Look up the specified Avro schema ID.
                                            </li>

                                        </ul>
Overrides any existing schema definitions associated
                                        with the data. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1180 ">Schema Subject</td>

                                    <td class="entry cellrowborder" headers="d268396e1183 ">Avro schema subject to look up in the Confluent Schema
                                            Registry.<p class="p">If the specified subject has multiple schema
                                            versions, the origin uses the latest schema version for
                                            that subject. To use an older version, find the
                                            corresponding schema ID, and then set the
                                                <span class="ph uicontrol">Look Up Schema By</span> property to
                                            Schema ID.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1180 ">Schema ID</td>

                                    <td class="entry cellrowborder" headers="d268396e1183 ">Avro schema ID to look up in the Confluent Schema
                                        Registry.</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand" id="task_hgl_vgn_vs__DelimFILE">
                <span class="ph cmd">For delimited data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__table_DelimitedData" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d268396e1306">Delimited Property</th>

                                    <th class="entry cellrowborder" id="d268396e1309">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Delimiter Format Type</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Delimiter format type. Use one of the following options:
                                            <ul class="ul" id="task_hgl_vgn_vs__ul_s5z_b3z_3r">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                  </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Header Line</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Indicates whether a file contains a header line, and
                                        whether to use the header line.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Allow Extra Columns</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">When processing data with a header line, allows
                                        processing records with more columns than exist in the
                                        header line.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Extra Column Prefix</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Prefix to use for any additional columns. Extra columns
                                        are named using the prefix and sequential increasing
                                        integers as follows:
                                            <code class="ph codeph">&lt;prefix&gt;&lt;integer&gt;</code>. <p class="p">For
                                            example, _extra_1. Default is _extra_.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Max Record Length (chars)</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Maximum length of a record in characters. Longer records
                                        are not read. <p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Delimiter Character</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Delimiter character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                            character.<p class="p">You can enter a Unicode control character
                                            using the format \u<em class="ph i">NNNN</em>, where <em class="ph i">N</em> is a
                                            hexadecimal digit from the numbers 0-9 or the letters
                                            A-F. For example, enter \u0000 to use the null character
                                            as the delimiter or \u2028 to use a line separator as
                                            the delimiter.</p>
<p class="p">Default is the pipe character ( |
                                            ).</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Escape Character</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Escape character for a custom file type.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Quote Character</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Quote character for a custom file type.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Root Field Type <a class="xref" href="../Data_Formats/DelimitedDataRootFieldTypes.html">
                                            <img class="image" id="task_hgl_vgn_vs__d62e1529" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Root field type to use:<ul class="ul" id="task_hgl_vgn_vs__d62e1533">
                                            <li class="li">List-Map - Generates an indexed list of data.
                                                Enables you to use standard functions to process
                                                data. Use for new pipelines.</li>

                                            <li class="li">List - Generates a record with an indexed list with
                                                a map for header and value. Requires the use of
                                                delimited data functions to process data. Use only
                                                to maintain pipelines created before 1.1.0.</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Lines to Skip</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Lines to skip before reading data. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">Parse NULLs</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">Replaces the specified string constant with null
                                        values.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1306 ">NULL Constant</td>

                                    <td class="entry cellrowborder" headers="d268396e1309 ">String constant to replace with null values.</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d268396e1306 ">Charset</td>

       <td class="entry cellrowborder" headers="d268396e1309 ">Character encoding of the files to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d268396e1306 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_hgl_vgn_vs__d38e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d268396e1309 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For text data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__d62e2290" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d268396e1559">Text Property</th>

                                    <th class="entry cellrowborder" id="d268396e1562">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1559 ">Max Line Length</td>

                                    <td class="entry cellrowborder" headers="d268396e1562 ">Maximum number of characters allowed for a line. Longer
                                        lines are truncated.<p class="p">Adds a boolean field to the record to
                                            indicate if it was truncated. The field name is
                                            Truncated. </p>
<p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1559 ">Use Custom Delimiter <a class="xref" href="../Data_Formats/TextCDelim.html#concept_lg2_gcg_jx">
                                            <img class="image" id="task_hgl_vgn_vs__d62e2331" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d268396e1562 ">Uses custom delimiters to define records instead of line
                                        breaks. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1559 ">Custom Delimiter</td>

                                    <td class="entry cellrowborder" headers="d268396e1562 ">One or more characters to use to define records. </td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d268396e1559 ">Charset</td>

       <td class="entry cellrowborder" headers="d268396e1562 ">Character encoding of the files to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d268396e1559 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_hgl_vgn_vs__d38e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d268396e1562 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">If using the origin in a cluster EMR batch or cluster batch mode pipeline to
                    read data from Amazon S3, configure the following properties on the
                        <span class="ph uicontrol">S3</span> tab:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_hgl_vgn_vs__table_l2m_cz1_h2b" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d268396e1664">S3 Property</th>

                                    <th class="entry cellrowborder" id="d268396e1667">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1664 ">Access Key ID</td>

                                    <td class="entry cellrowborder" headers="d268396e1667 ">AWS access key ID.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d268396e1664 ">Secret Access Key</td>

                                    <td class="entry cellrowborder" headers="d268396e1667 ">AWS secret access key.<p class="p">The origin uses the access key
                                            pair to pass credentials to Amazon Web Services to read
                                            from Amazon S3. </p>
<p class="p">If using the origin in a cluster
                                            EMR batch pipeline, enter the same access key pair that
                                            you entered on the EMR tab of the pipeline. For more
                                            information, see <a class="xref" href="../Cluster_Mode/AmazonS3Requirements.html#task_o3s_kb5_g2b" title="Cluster EMR batch mode pipelines run on an Amazon EMR cluster to process data from Amazon S3.">Configuring Cluster EMR Batch Mode for Amazon S3</a>.</p>
<div class="note tip"><span class="tiptitle">Tip:</span> To secure sensitive information such as
                  access key pairs, you can use <a class="xref" href="../Pipeline_Configuration/RuntimeValues.html#concept_bs4_5nm_2s" title="Similar to runtime properties, runtime resources are values that you define in a file local to the Data Collector and call from within a pipeline. But with runtime resources, you can restrict the permissions for the files to secure sensitive information. Use runtime resources to load sensitive information from files at runtime.">runtime resources</a> or <span class="ph"><a class="xref" href="../Configuration/CredentialStores.html#concept_bt1_bpj_r1b" title="Data Collector pipeline stages communicate with external systems to read and write data. Many of these external systems require credentials - user names or passwords - to access the data. When you configure pipeline stages for these external systems, you define the credentials that the stage uses to connect to the system.">credential stores.</a></span></div>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
</ol>

    </div>

</article>
</article>
</article></main></div>
                        
                        
                        
                    </div>
                    
                </div>
            </div>
        </div> <nav class="navbar navbar-default wh_footer">
  <div class=" footer-container text-center ">
    <!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script>
  </div>
</nav>

        
        <div id="go2top">
            <span class="glyphicon glyphicon-chevron-up"></span>
        </div>
        
        <!-- The modal container for images -->
        <div id="modal_img_large" class="modal">
            <span class="close glyphicon glyphicon-remove"></span>
            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="modal-img" />
            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>
        
        <script src="../../../oxygen-webhelp/lib/bootstrap/js/bootstrap.min.js" type="text/javascript"></script>
         Apache License, Version 2.0.
    </body>
</html>