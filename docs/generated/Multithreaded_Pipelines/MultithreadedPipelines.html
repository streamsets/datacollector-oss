
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="description" content="A multithreaded pipeline is a pipeline with an origin that supports parallel execution, enabling one pipeline to run in multiple threads. Multithreaded pipelines enable processing high volumes of data ..." /><meta name="copyright" content="(C) Copyright 2005" /><meta name="DC.rights.owner" content="(C) Copyright 2005" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Multithreaded Pipelines" /><meta name="DC.Relation" scheme="URI" content="../Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w" /><meta name="DC.Relation" scheme="URI" content="../Edge_Mode/EdgePipelines_title.html#concept_fyf_gkq_4bb" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_wwq_gxc_py" /><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Multithreaded Pipelines</title><!--  Generated with Oxygen version 18.1, build number 2016112217.  --><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css" /><link rel="stylesheet" type="text/css" href="../skin.css" /><script type="text/javascript"><!--
            
            var prefix = "../index.html";
            
            --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.11.3.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script>
<!--
    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
-->
</head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"></span></td><td><span id="topic_navigation_links" class="navheader">
<span class="navprev"><a class="link" href="../Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w" title="Drift Synchronization Solution (a.k.a. Hive Drift Solution)"><span class="navheader_label">Previous topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Drift Synchronization Solution (a.k.a. Hive Drift Solution)</span></a></span>  
<span class="navnext"><a class="link" href="../Edge_Mode/EdgePipelines_title.html#concept_fyf_gkq_4bb" title="Edge Pipelines"><span class="navheader_label">Next topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Edge Pipelines</span></a></span>  </span></td></tr></tbody></table>
<div class="nested0" id="concept_wwq_gxc_py">
 <h1 class="title topictitle1">Multithreaded Pipelines</h1>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_zpp_2xc_py">
 <h2 class="title topictitle2">Multithreaded Pipeline Overview</h2>

 <div class="body conbody">
        <p class="p">A
                <dfn class="term">multithreaded pipeline</dfn> is a pipeline with an origin that supports
            parallel execution, enabling one pipeline to run in multiple threads. </p>

        <p class="p">Multithreaded pipelines enable processing high volumes of data in a single pipeline on
            one <span class="ph">Data
                  Collector</span>, thus taking full advantage of all available CPUs on the <span class="ph">Data
                  Collector</span>
            machine. When using multithreaded pipelines, make sure to allocate sufficient resources
            to the pipeline and <span class="ph">Data
                  Collector</span>.</p>

        <p class="p">A multithreaded pipeline honors the configured delivery guarantee for the pipeline, but
            does not guarantee the order in which batches of data are processed. </p>

 </div>

</div>
<div class="topic concept nested1" id="concept_xl3_ncd_py">
    <h2 class="title topictitle2">How It Works</h2>

    <div class="body conbody">
        <p class="p">When you
            configure a multithreaded pipeline, you specify the number of threads that the origin
            should use to generate batches of data. You can also configure the maximum number of
                <dfn class="term">pipeline runners</dfn> that <span class="ph">Data
                  Collector</span>
            uses to perform pipeline processing. </p>

        <p class="p"><span class="ph">A pipeline runner is a <dfn class="term">sourceless
                              pipeline instance</dfn> - an instance of the pipeline that includes
                        all of the processors and destinations in the pipeline and represents all
                        pipeline processing after the origin.</span></p>

        <p class="p">Origins perform multithreaded processing based on the origin systems they work with, but
            the following is true for all origins that generate multithreaded pipelines: </p>

        <p class="p">When you start the pipeline, the origin creates a number of threads based on the
            multithreaded property configured in the origin. <span class="ph">And <span class="ph">Data
                  Collector</span> creates a number of pipeline runners based on the pipeline Max Runners
                        property to perform pipeline processing. <span class="ph" id="concept_xl3_ncd_py__d42290e2217">Each
                              thread connects to the origin system and creates a batch of data, and
                              passes the batch to an available pipeline runner.</span></span></p>

        <p class="p"><span class="ph"> Each pipeline runner processes one batch at a time,
                        just like a pipeline that runs on a single thread. When the flow of data
                        slows, the pipeline runners wait idly until they are needed.</span></p>

        <p class="p"><span class="ph">Multithreaded pipelines preserve the order of
                        records within each batch, just like a single-threaded pipeline. But since
                        batches are processed by different pipeline instances, the order that
                        batches are written to destinations is not ensured.</span></p>

        <p class="p">For example, take the following multithreaded pipeline. The HTTP Server origin processes
            HTTP POST requests passed from HTTP clients. When you configure the origin, you specify
            the number of threads to use - in this case, the Max Concurrent Requests property:</p>

        <p class="p"><img class="image" id="concept_xl3_ncd_py__image_mxx_5sd_ry" src="../Graphics/Multithread-HTTPPipeline.png" height="263" width="470" /></p>

        <p class="p">Let's say you configure the pipeline to opt out of the Max Runners property. When you do
            this, <span class="ph">Data
                  Collector</span>
            generates a matching number of pipeline runners for the number of threads.</p>

        <p class="p">With Max Concurrent Requests set to 5, when you start the pipeline the origin creates
            five threads and <span class="ph">Data
                  Collector</span>
            creates five pipeline runners. Upon receiving data, the origin passes a batch to each of
            the pipeline runners for processing.</p>

        <p class="p">Conceptually, the multithreaded pipeline looks like this:</p>

        <p class="p"><img class="image" id="concept_xl3_ncd_py__image_r5x_532_ry" src="../Graphics/Multithread-HTTPThreads.png" height="487" width="585" /></p>

        <p class="p">Each pipeline runner performs the processing associated with the rest of the pipeline.
            After a batch is written to pipeline destinations - in this case, Azure Data Lake Store
            1 and 2 - the pipeline runner becomes available for another batch of data. Each batch is
            processed and written as quickly as possible, independently from batches processed by
            other pipeline runners, so the write-order of the batches can differ from the
            read-order.</p>

        <p class="p">At any given moment, the five pipeline runners can each
                  process a batch, so this multithreaded pipeline processes up to five batches at a
                  time. When incoming data slows, the pipeline runners sit idle, available for use
                  as soon as the data flow increases.</p>

    </div>

<div class="topic concept nested2" id="concept_wcz_tpd_py">
    <h3 class="title topictitle3">Origins for Multithreaded Pipelines</h3>

    <div class="body conbody">
        <div class="p">You can use the following origins
            to create multithreaded pipelines:<ul class="ul" id="concept_wcz_tpd_py__ul_djp_zvk_tz">
                        <li class="li"><a class="xref" href="../Origins/AmazonSQS.html#concept_xsh_knm_5bb" title="When Data Collector reads data from an Amazon SQS Consumer origin, it must pass credentials to Amazon Simple Queue Services.">Amazon SQS
                                    Consumer</a> - Reads data from queues in Amazon Simple Queue
                              Services (SQS).</li>

                        <li class="li"><a class="xref" href="../Origins/AzureEventHub.html#concept_c1z_15q_1bb">Azure
                                    IoT/Event Hub Consumer</a> - Reads data from Microsoft Azure
                              Event Hub.</li>

                        <li class="li"><a class="xref" href="../Origins/CoAPServer.html#concept_wfy_ghn_sz" title="Constrained Application Protocol (CoAP) is a web transfer protocol designed for machine-to-machine devices. The CoAP Server origin is a multithreaded origin that listens on a CoAP endpoint and processes the contents of all authorized CoAP requests.">CoAP
                                    Server</a> - Listens on a CoAP endpoint and processes the
                              contents of all authorized CoAP requests.</li>

                        <li class="li"><a class="xref" href="../Origins/Directory.html#concept_qcq_54n_jq" title="Configure a first file for processing when you want Directory to ignore one or more existing files in the directory.You can configure Directory to read files in a late directory - a directory that appears after the pipeline starts. The Directory origin passes each record to a buffer. The size of the buffer determines the maximum size of the record that can be processed. Decrease the buffer limit when memory on the Data Collector machine is limited. Increase the buffer limit to process larger records when memory is available. When you use an origin to read log data, you define the format of the log files to be read. Configure a Directory origin to read data from files in a directory.">Directory</a> - Reads fully written files from a
                              directory.</li>

                        <li class="li"><a class="xref" href="../Origins/Elasticsearch.html#concept_f1q_vpm_2z" title="The Elasticsearch origin is a multithreaded origin that reads data from an Elasticsearch cluster, including Elastic Cloud clusters (formerly Found clusters). The origin generates a record for each Elasticsearch document.">Elasticsearch</a> - Reads data from an Elasticsearch
                              cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/PubSub.html#concept_pjw_qtl_r1b" title="The Google Pub/Sub Subscriber origin consumes messages from a Google Pub/Sub subscription.">Google Pub/Sub
                                    Subscriber</a> - Consumes messages from a Google Pub/Sub
                              subscription.</li>

                        <li class="li"><a class="xref" href="../Origins/HTTPServer.html#concept_s2p_5hb_4y" title="The HTTP Server origin is a multithreaded origin that listens on an HTTP endpoint and processes the contents of all authorized HTTP POST requests. Use the HTTP Server origin to read high volumes of HTTP POST requests using multiple threads.">HTTP
                                    Server</a> - Listens on a HTTP endpoint and processes the
                              contents of all authorized HTTP POST requests. </li>

                        <li class="li"><a class="xref" href="../Origins/MultiTableJDBCConsumer.html#concept_zp3_wnw_4y" title="You define the group of tables that the JDBC Multitable Consumer origin reads by defining a table name pattern for the table configuration. The origin reads all tables whose names match the pattern. The JDBC Multitable Consumer origin uses an offset column and initial offset value to determine where to start reading data within tables and partitions.The JDBC Multitable Consumer origin can read from views in addition to tables. You can define the initial order that the origin uses to read the tables.">JDBC Multitable Consumer</a> - Reads database data from
                              multiple tables through a JDBC connection.</li>

                        <li class="li"><a class="xref" href="../Origins/KafkaMultiConsumer.html#concept_ccs_fn4_x1b" title="You can add custom Kafka configuration properties to the Kafka Multitopic Consumer.When you use an origin to read log data, you define the format of the log files to be read.">Kafka Multitopic Consumer</a> - Reads data from multiple
                              topics in a Kafka cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/KinConsumer.html#concept_anh_4y3_yr" title="The Kinesis Consumer origin reads data from Amazon Kinesis Streams.">Kinesis
                                    Consumer</a> - Reads data from a Kinesis cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/MapRdbCDC.html#concept_qwj_5vm_pbb">MapR DB
                                    CDC</a> - Reads changed MapR DB data that has been written to
                              MapR Streams.</li>

                        <li class="li"><a class="xref" href="../Origins/MapRStreamsMultiConsumer.html#concept_hvd_hww_lbb" title="You can add custom configuration properties to the MapR Multitopic Streams Consumer. You can use any MapR or Kafka property supported by MapR Streams. For more information, see the MapR Streams documentation. When you use an origin to read log data, you define the format of the log files to be read.">MapR Multitopic Streams Consumer</a> - Reads data from
                              multiple topics in a MapR Streams cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/SQLServerCDC.html#concept_ut3_ywc_v1b" title="You can define the initial order that the origin uses to read the tables.">SQL Server
                                    CDC Client</a> - Reads data from Microsoft SQL Server CDC
                              tables.</li>

                        <li class="li"><a class="xref" href="../Origins/SQLServerChange.html#concept_ewq_b2s_r1b" title="You can define the initial order that the origin uses to read the tables.">SQL
                                    Server Change Tracking</a> - Processes data from Microsoft
                              SQL Server change tracking tables. </li>

                        <li class="li"><a class="xref" href="../Origins/TCPServer.html#concept_ppm_xb1_4z">TCP
                                    Server</a> - Listens at the specified ports and processes
                              incoming data over TCP/IP connections.</li>

                        <li class="li"><a class="xref" href="../Origins/UDPMulti.html#concept_wng_g5f_5bb">UDP
                                    Multithreaded Source</a> - Reads messages from one or more
                              UDP ports. </li>

                        <li class="li"><a class="xref" href="../Origins/WebSocketServer.html#concept_u2r_gpc_3z" title="The WebSocket Server origin is a multithreaded origin that listens on a WebSocket endpoint and processes the contents of all authorized WebSocket client requests. Use the WebSocket Server origin to read high volumes of WebSocket client requests using multiple threads.">WebSocket Server</a> - Listens on a WebSocket endpoint and
                              processes the contents of all authorized WebSocket requests. </li>

                        <li class="li"><a class="xref" href="../Pipeline_Design/DevStages.html#concept_czx_ktn_ht">Dev
                                    Data Generator</a> - Generates random data for development
                              and testing.</li>

                  </ul>
</div>

        <p class="p">The origins use different properties and perform processing differently based on the
            origin systems they work with. For details on how an origin performs multithreaded
            processing, see "Multithreaded Processing" in the origin documentation.</p>

        <p class="p">Note that <span class="ph">Data
                  Collector</span>
            provides several "to Kafka" multithreaded origins: <a class="xref" href="../Origins/HTTPtoKafka.html#concept_izh_mqd_dy">HTTP to Kafka</a>, <a class="xref" href="../Origins/SDCRPCtoKafka.html#concept_tdk_slk_pw" title="The SDC RPC to Kafka origin reads data from one or more SDC RPC destinations and writes it immediately to Kafka. Use the SDC RPC to Kafka origin in an SDC RPC destination pipeline.">SDC RPC to Kafka</a>, and
                <a class="xref" href="../Origins/UDPtoKafka.html#concept_jzq_jcz_pw" title="When you use a UDP to Kafka origin in a pipeline, connect the origin to a Trash destination.">UDP to Kafka</a>.
            These origins write incoming data directly to Kafka with no additional processing. They
            do not create full multithreaded pipelines. </p>

    </div>

</div>
<div class="topic concept nested2" id="concept_np1_pkz_ry">
 <h3 class="title topictitle3">Processor Caching</h3>

 <div class="body conbody">
  <p class="p">Since multithreaded pipelines use multiple
            pipeline runners to run multiple sourceless pipeline instances, processor caching in a
            multithreaded pipeline can differ from a pipeline that runs on a single thread.</p>

        <p class="p">Generally, when a processor caches data, each instance of the processor can only cache
            the data that passes through that particular pipeline runner. Be sure to consider this
            behavior when configuring multithreaded pipelines. </p>

        <p class="p">For example, if you configure a lookup processor to create a local cache, each instance
            of the lookup processor creates its own local cache. This should not be a problem since
            the cache is generally used to improve pipeline performance. </p>

        <p class="p">The exception is the Record Deduplicator processor. The Record Deduplicator caches
            records for comparison for up to a specified number of records or amount of time. When
            used in a multithreaded pipeline, the records in the cache are shared across pipeline
            runners. </p>

 </div>

</div>
</div>
<div class="topic concept nested1" id="concept_tdn_vwy_ry">
 <h2 class="title topictitle2">Monitoring</h2>

 <div class="body conbody">
        <p class="p">When you monitor a multithreaded pipeline, the
            pipeline and stage statistics that display are for the entire pipeline, aggregated
            across all pipeline runners.</p>

        <p class="p">Monitor mode provides the following Available Pipeline Runners Histogram: </p>

        <p class="p"><img class="image" id="concept_tdn_vwy_ry__image_bzb_yxf_sy" src="../Graphics/Multithreaded-Stats.png" height="270" width="284" /></p>

        <p class="p">The histogram shows a changing snapshot of the frequency of available pipeline runners and
            the number of runners that are currently available. If you are uncertain of the number
            that a column displays, hover over it to view the column detail.</p>

        <p class="p">For example, the histogram above indicates that the mean is 1.4 available runners, and
            the standard deviation is one runner.</p>

    </div>

</div>
<div class="topic concept nested1" id="concept_fmg_pjd_mz">
 <h2 class="title topictitle2">Tuning Threads and Runners</h2>

 <div class="body conbody">
  <div class="p">To optimize pipeline performance and resource usage,
            you can tune the number of threads and pipeline runners that a multithreaded pipeline
            uses. <dl class="dl">
                
                    <dt class="dt dlterm">threads</dt>

                    <dd class="dd">Configure the maximum number of threads or concurrency in the origin.</dd>

                    <dd class="dd">Before specifying a number of threads, consider how the origin uses threads.
                        All origins use threads to connect to the origin system and create batches
                        of data, but they can perform this task differently. </dd>

                    <dd class="dd">For example, the JDBC Multitable Consumer origin uses one thread for each
                        table, so there's little point in configuring the origin to use more threads
                        than the number of tables being queried. </dd>

                    <dd class="dd">In contrast, the HTTP Server origin listens at an HTTP endpoint. When you
                        configure the number of threads to use, you should consider the maximum
                        number of threads you might feasibly use in relationship to the peak spikes
                        and the number of available pipeline runners.</dd>

                    <dd class="dd">Note that idle threads consume few resources, so little harm can come from
                        configuring extra.</dd>

                
                
                    <dt class="dt dlterm">pipeline runners</dt>

                    <dd class="dd">Configure the maximum number of pipeline runners using the Max Runners
                        pipeline property. </dd>

                    <dd class="dd">Pipeline runners consume resources even when idle. So when considering the
                        number of runners to use, you should decide if you want to optimize for
                        performance, resource usage, or both.</dd>

                    <dd class="dd">Pipeline runners process batches created by the origin threads. The speed of
                        processing might differ based on the complexity of the pipeline logic, batch
                        size, etc. </dd>

                    <dd class="dd">So to determine the number of pipeline runners that you want to use, monitor
                        the number of available runners when you run the pipeline. If you find that
                        you have an abundance of available runners, you might reduce the number of
                        runners that you allow. Conversely, if the pipeline runners are generally
                        unavailable, increasing the number of pipeline runners can improve
                        performance. </dd>

                
            </dl>
</div>

        <p class="p">For example, say you have a pipeline with the Kinesis Consumer reading from 4 shards. In
            the origin, you set the number of threads to 4. You also leave the pipeline Max Runners
            property with the default of 0, which creates a matching number of pipeline runners for
            the threads - in this case, 4. After you start the pipeline and let it run for a while,
            you check back and find the following histogram: </p>

        <p class="p"><img class="image" id="concept_fmg_pjd_mz__image_av3_3rk_mz" src="../Graphics/Multithreaded-Stats.png" height="270" width="284" /></p>

        <p class="p">The histogram shows that the mean is 1.4, which means at any time, it's likely that there
            are 1.4 available runners.</p>

        <p class="p">If this is the peak load for the pipeline, this means you can reduce the number of
            pipeline runners used in the pipeline to 3 without sacrificing much performance. If <span class="ph">Data
                  Collector</span>
            resources are needed elsewhere and you don't mind a minor hit to pipeline performance,
            you might reduce the number of pipeline runners to 2. </p>

 </div>

</div>
<div class="topic concept nested1" id="concept_z25_ltd_ry">
 <h2 class="title topictitle2">Resource Usage</h2>

 <div class="body conbody">
        <p class="p">Since each pipeline runner performs all
            processing associated with the pipeline after the origin, each thread in a multithreaded
            pipeline requires roughly the same resources as the same pipeline running on a single
            thread. </p>

        <p class="p">When working with multithreaded pipelines, review the resource usage of the pipeline and
            increase the Max Pipeline Memory pipeline property as needed. </p>

        <p class="p">You should also monitor the <span class="ph">Data
                  Collector</span>
            resource usage and increase the <span class="ph">Data
                  Collector</span>
            Java heap size when appropriate. </p>

        <p class="p"> </p>

    </div>

</div>
<div class="topic concept nested1" id="concept_sfp_1nd_py">
 <h2 class="title topictitle2">Multithreaded Pipeline Summary</h2>

 <div class="body conbody">
        <p class="p">The following
            points attempt to summarize the key details about multithreaded pipelines: </p>

  <div class="p">
            <ul class="ul" id="concept_sfp_1nd_py__ul_igl_q4d_py">
                <li class="li">Use multithreaded origins to create a multithreaded pipeline. You can use the
                    following origins at this time:<ul class="ul" id="concept_sfp_1nd_py__ul_llv_cwk_tz">
                        <li class="li"><a class="xref" href="../Origins/AmazonSQS.html#concept_xsh_knm_5bb" title="When Data Collector reads data from an Amazon SQS Consumer origin, it must pass credentials to Amazon Simple Queue Services.">Amazon SQS
                                    Consumer</a> - Reads data from queues in Amazon Simple Queue
                              Services (SQS).</li>

                        <li class="li"><a class="xref" href="../Origins/AzureEventHub.html#concept_c1z_15q_1bb">Azure
                                    IoT/Event Hub Consumer</a> - Reads data from Microsoft Azure
                              Event Hub.</li>

                        <li class="li"><a class="xref" href="../Origins/CoAPServer.html#concept_wfy_ghn_sz" title="Constrained Application Protocol (CoAP) is a web transfer protocol designed for machine-to-machine devices. The CoAP Server origin is a multithreaded origin that listens on a CoAP endpoint and processes the contents of all authorized CoAP requests.">CoAP
                                    Server</a> - Listens on a CoAP endpoint and processes the
                              contents of all authorized CoAP requests.</li>

                        <li class="li"><a class="xref" href="../Origins/Directory.html#concept_qcq_54n_jq" title="Configure a first file for processing when you want Directory to ignore one or more existing files in the directory.You can configure Directory to read files in a late directory - a directory that appears after the pipeline starts. The Directory origin passes each record to a buffer. The size of the buffer determines the maximum size of the record that can be processed. Decrease the buffer limit when memory on the Data Collector machine is limited. Increase the buffer limit to process larger records when memory is available. When you use an origin to read log data, you define the format of the log files to be read. Configure a Directory origin to read data from files in a directory.">Directory</a> - Reads fully written files from a
                              directory.</li>

                        <li class="li"><a class="xref" href="../Origins/Elasticsearch.html#concept_f1q_vpm_2z" title="The Elasticsearch origin is a multithreaded origin that reads data from an Elasticsearch cluster, including Elastic Cloud clusters (formerly Found clusters). The origin generates a record for each Elasticsearch document.">Elasticsearch</a> - Reads data from an Elasticsearch
                              cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/PubSub.html#concept_pjw_qtl_r1b" title="The Google Pub/Sub Subscriber origin consumes messages from a Google Pub/Sub subscription.">Google Pub/Sub
                                    Subscriber</a> - Consumes messages from a Google Pub/Sub
                              subscription.</li>

                        <li class="li"><a class="xref" href="../Origins/HTTPServer.html#concept_s2p_5hb_4y" title="The HTTP Server origin is a multithreaded origin that listens on an HTTP endpoint and processes the contents of all authorized HTTP POST requests. Use the HTTP Server origin to read high volumes of HTTP POST requests using multiple threads.">HTTP
                                    Server</a> - Listens on a HTTP endpoint and processes the
                              contents of all authorized HTTP POST requests. </li>

                        <li class="li"><a class="xref" href="../Origins/MultiTableJDBCConsumer.html#concept_zp3_wnw_4y" title="You define the group of tables that the JDBC Multitable Consumer origin reads by defining a table name pattern for the table configuration. The origin reads all tables whose names match the pattern. The JDBC Multitable Consumer origin uses an offset column and initial offset value to determine where to start reading data within tables and partitions.The JDBC Multitable Consumer origin can read from views in addition to tables. You can define the initial order that the origin uses to read the tables.">JDBC Multitable Consumer</a> - Reads database data from
                              multiple tables through a JDBC connection.</li>

                        <li class="li"><a class="xref" href="../Origins/KafkaMultiConsumer.html#concept_ccs_fn4_x1b" title="You can add custom Kafka configuration properties to the Kafka Multitopic Consumer.When you use an origin to read log data, you define the format of the log files to be read.">Kafka Multitopic Consumer</a> - Reads data from multiple
                              topics in a Kafka cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/KinConsumer.html#concept_anh_4y3_yr" title="The Kinesis Consumer origin reads data from Amazon Kinesis Streams.">Kinesis
                                    Consumer</a> - Reads data from a Kinesis cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/MapRdbCDC.html#concept_qwj_5vm_pbb">MapR DB
                                    CDC</a> - Reads changed MapR DB data that has been written to
                              MapR Streams.</li>

                        <li class="li"><a class="xref" href="../Origins/MapRStreamsMultiConsumer.html#concept_hvd_hww_lbb" title="You can add custom configuration properties to the MapR Multitopic Streams Consumer. You can use any MapR or Kafka property supported by MapR Streams. For more information, see the MapR Streams documentation. When you use an origin to read log data, you define the format of the log files to be read.">MapR Multitopic Streams Consumer</a> - Reads data from
                              multiple topics in a MapR Streams cluster.</li>

                        <li class="li"><a class="xref" href="../Origins/SQLServerCDC.html#concept_ut3_ywc_v1b" title="You can define the initial order that the origin uses to read the tables.">SQL Server
                                    CDC Client</a> - Reads data from Microsoft SQL Server CDC
                              tables.</li>

                        <li class="li"><a class="xref" href="../Origins/SQLServerChange.html#concept_ewq_b2s_r1b" title="You can define the initial order that the origin uses to read the tables.">SQL
                                    Server Change Tracking</a> - Processes data from Microsoft
                              SQL Server change tracking tables. </li>

                        <li class="li"><a class="xref" href="../Origins/TCPServer.html#concept_ppm_xb1_4z">TCP
                                    Server</a> - Listens at the specified ports and processes
                              incoming data over TCP/IP connections.</li>

                        <li class="li"><a class="xref" href="../Origins/UDPMulti.html#concept_wng_g5f_5bb">UDP
                                    Multithreaded Source</a> - Reads messages from one or more
                              UDP ports. </li>

                        <li class="li"><a class="xref" href="../Origins/WebSocketServer.html#concept_u2r_gpc_3z" title="The WebSocket Server origin is a multithreaded origin that listens on a WebSocket endpoint and processes the contents of all authorized WebSocket client requests. Use the WebSocket Server origin to read high volumes of WebSocket client requests using multiple threads.">WebSocket Server</a> - Listens on a WebSocket endpoint and
                              processes the contents of all authorized WebSocket requests. </li>

                        <li class="li"><a class="xref" href="../Pipeline_Design/DevStages.html#concept_czx_ktn_ht">Dev
                                    Data Generator</a> - Generates random data for development
                              and testing.</li>

                  </ul>
</li>

                <li class="li">Unlike a basic, single-threaded pipeline, a multithreaded pipeline cannot
                    guarantee the order of data. <p class="p">Data within a batch is processed in order, but
                        since batches are created quickly and passed to different threads, the order
                        of batches can change as they are written to pipeline destinations.
                    </p>
</li>

                <li class="li">Processors that cache information generally have a separate cache for each
                    instance of the pipeline. The exception is the Record Deduplicator, which can
                    identify duplicate records across all pipeline runners. </li>

                <li class="li">The pipeline and stage statistics that display during monitoring
                    are aggregated across all threads. </li>

                <li class="li">To optimize performance and resource usage, check the Available Pipeline Runners
                    histogram to see if pipeline runners are being used effectively.</li>

                <li class="li">We recommend monitoring the resource usage of the pipeline and the <span class="ph">Data
                  Collector</span> heap usage, increasing them as needed.</li>

            </ul>

        </div>

 </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navprev"><a class="link" href="../Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w" title="Drift Synchronization Solution (a.k.a. Hive Drift Solution)"><span class="navheader_label">Previous topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Drift Synchronization Solution (a.k.a. Hive Drift Solution)</span></a></span>  
<span class="navnext"><a class="link" href="../Edge_Mode/EdgePipelines_title.html#concept_fyf_gkq_4bb" title="Edge Pipelines"><span class="navheader_label">Next topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Edge Pipelines</span></a></span>  </div><div class="footer" id="webhelp_copyright_information"><!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

--><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>